<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="https://dpalmasan.github.io/website/feed.xml" rel="self" type="application/atom+xml" /><link href="https://dpalmasan.github.io/website/" rel="alternate" type="text/html" /><updated>2025-02-27T05:04:23+00:00</updated><id>https://dpalmasan.github.io/website/feed.xml</id><title type="html">Mr Dipalma‚Äôs Pub üç∫</title><subtitle>Este es un blog donde compartir√© un poco sobre m√≠ y mis experiencias en el mundo tecnol√≥gico...</subtitle><author><name>dpalmasan</name></author><entry><title type="html">Mi Tercer Ciclo</title><link href="https://dpalmasan.github.io/website/swe/dev/2025/02/25/tercer-ciclo.html" rel="alternate" type="text/html" title="Mi Tercer Ciclo" /><published>2025-02-25T18:30:00+00:00</published><updated>2025-02-25T18:30:00+00:00</updated><id>https://dpalmasan.github.io/website/swe/dev/2025/02/25/tercer-ciclo</id><content type="html" xml:base="https://dpalmasan.github.io/website/swe/dev/2025/02/25/tercer-ciclo.html"><![CDATA[<div align="center">
<p><img src="http://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/6ce5ad83ead7e76414a35ffffe14aa79f1082fa9/fl-genai.jpeg" alt="fl-genai" /></p>
</div>
<h1 id="introduccin">Introducci√≥n</h1>
<p>Como muchos sabr√°n llevo un poco m√°s de dos a√±os trabajando en Meta. En este post comparto algunas experiencias √∫ltimo fragmento en estos 2.8 a√±os que llevo ac√°. Adelanto que no ser√° un post tan largo ni con mucho detalle, y tendr√° dos secciones principales:</p>
<ol>
<li>Mi experiencia en este 3er ciclo (2024)</li>
<li>Algunas reflexiones/opiniones</li>
</ol>
<p>Vale la pena leer el post completo para llegar a lo jugoso/sabroso.</p>
<h2 id="contexto">Contexto</h2>
<p>En <a href="/website/swe/dev/2024/09/06/diferentes-experiencias.html">otro post habl√© sobre mis experiencias en Meta</a>, b√°sicamente sobre los primeros dos a√±os que tuve. En este post hablar√© de mi tercer ciclo, de c√≥mo me cambi√© de equipo, las diferencias.</p>
<h1 id="mi-tercer-ao-en-usa">Mi tercer a√±o en USA</h1>
<p>Primero lo m√°s importante, sobreviv√≠ 3 rondas de despidos: 2022 y 2023 hubo recortes de presupuesto y el m√°s reciente (Febrero 10, 2025) fue por desempe√±o. No me referir√© mucho a estos temas, ya que en mi post <a href="/website/swe/dev/2024/09/06/diferentes-experiencias.html"><em>Diferentes Experiencias</em></a> mencion√© c√≥mo es el tema de la evaluaci√≥n de desempe√±o en Meta (que vale la pena recordar, es muy intensa, m√°s intensa que en cualquier experiencia previa que haya tenido).</p>
<p>Mi <em>performance rating</em> de este tercer ciclo (2024) fue <strong>Exceeded Expectations</strong>. He ido a la baja jaja, mi primer a√±o saqu√© redefined, el segundo greatly exceeded y ahora exceeded‚Ä¶ En fin, significa que hay espacio para mejorar üòä</p>
<h2 id="algunas-memorias-personales">Algunas Memorias Personales</h2>
<p>Para destacar este a√±o:</p>
<ul>
<li>Trabaj√© en problemas interesantes, en particular en el espacio de <em>Federated Learning</em>.</li>
<li>Me toc√≥ tocar e implementar bibliotecas nativas (<code>jni</code>) (android y otros dispositivos), tuve que hacer implementaciones en <code>java</code> y <code>kotlin</code>. Este √∫ltimo nunca lo hab√≠a tocado, fue una experiencia interesante.</li>
<li>He sido mentor 4 veces en Meta. Un@ de ell@s logr√≥ el rating Exceeds Expectations habiendo entrado en la segunda mitad del a√±o. Originalmente se iba a ir por saltarse la evaluaci√≥n al ser nuev@ pero le di soporte y logr√≥ algo mucho mejor. Pecho inflado cuando me agradeci√≥ mi apoyo üòä.</li>
<li>Voy a empezar a ser entrevistador para posiciones de SWE/ML.</li>
<li>Tuve excelente feedback de ingenieros que admiro (y tengo en un pedestal). Palabras como <em>top engineer in the problem space</em>, <em>standout engineer</em>, <em>great engineer</em>, <em>best in class XFN</em>, etc.</li>
<li>Baj√© m√°s de 11 kg, estoy en mi aventura de ser influencer <em>fitness</em> üòÇ.</li>
<li>Romp√≠ mi record de pull ups y estoy haciendo pull ups con +50kg (extras).</li>
<li>Logr√© sacar el muscle up üòä. Tambi√©n de a poco mejorando mi press de banca.</li>
</ul>
<div align="center">
<p><img src="https://gist.github.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/66a60e26abc012301ce7a15e98481eb0f0d53d77/muscle-up.gif" alt="muscle-up" /></p>
<p><em>Fig 1: Yo haciendo un muscle up, anduve por Santiago en Enero.</em></p>
</div>
<h2 id="tiempo-para-una-historia">Tiempo para una Historia</h2>
<p>A fines del 2023 me cambi√© de equipo, rechazando una posible promoci√≥n a E6, y tir√°ndome hacia lo desconocido. Me transfer√≠ de un equipo de producto, a un equipo de infraestructura. Qu√© significa ello, en un equipo de producto los proyectos est√°n orientados a resolver problemas con objetivos claros y espec√≠ficos, por ejemplo <em>implementar X para aumentar el revenue en un Y%</em>. En este tipo de ambiente el <strong>impacto</strong> est√° alineado a objetivos globales directos. Lo que he notado, es que las iteraciones son r√°pidas, ya que hay que mover los gradientes en direcci√≥n a un mejoramiento de m√©tricas que impacten el <em>revenue</em> y los proyectos son en general cortoplacistas. Por otro lado, en un equipo de infraestructura, las iteraciones son lentas. Los proyectos son m√°s a largo plazo y el objetivo principal es implementar infraestructura que sea escalable, confiable, f√°cil de usar, y con buen desempe√±o en medidas de eficiencia (uso de memoria, latencia, etc.). En este tipo de proyecto el <strong>impacto</strong> por lo general es indirecto y m√°s complicado de medir en comparaci√≥n a un equipo de producto. Cabe destacar que la direcci√≥n es a largo plazo.</p>
<h2 id="aprendizaje-federado">Aprendizaje Federado</h2>
<p>En particular, mi equipo actual provee una infraestructura para el aprendizaje federado (<em>Federated Learning</em>, <em>FL</em>), el cual expliqu√© en mi post <a href="/website/probability/algorithms/ai/2024/04/11/federated-learning.html"><em>Introducci√≥n al Aprendizaje Federado</em></a>. Debo admitir que inicialmente sufr√≠ en mi fase de <em>ramp up</em>, ya que el stack era completamente diferente a lo que estaba acostumbrado. En mi equipo previo el stack era principalmente <a href="https://www.haskell.org/">Haskell</a>, <a href="https://hacklang.org/">Hack</a> y <a href="https://www.python.org/">python</a>. Tuve que aprender y meterme en una base de c√≥digo gigante donde el 90% del c√≥digo est√° escrito en <a href="https://cplusplus.com/">C++</a>. Las √∫nicas experiencias que hab√≠a tenido en C++ fueron m√°s bien acad√©micas, y nada comparables a programar en este lenguaje en un sistema a nivel de industria. Mucho menos lidiar con una base de c√≥digo con cientos de archivos, l√≠neas de c√≥digo, m√∫ltiples servicios, y un problema nuevo (FL) en el que no ten√≠a experiencia.</p>
<p>Primeros meses, tengo la tarea de entender los diferentes ejecutores de c√≥digo nativo en pytorch. No voy a discutir el stack en detalle, pero para ejecutar pytorch en multi-plataformas se puede usar <a href="https://pytorch.org/docs/main/jit.html">JIT</a>, b√°sicamete scriptear los modelos y hacer tracing de todos los componentes necesarios para su ejecuci√≥n. Debiese ser obvio, pero para aclarar, hay ciertas restricciones a la hora de scriptear, como por ejemplo no se pueden tener todas las directivas de <code>python</code> y s√≥lo se puede scriptear un subconjunto de tipos/objetos. Por otro lado, el tama√±o del binario importa, por lo que no podemos llegar y scriptear el modelo utilizando todos los operadores de pytorch. La ingenier√≠a de esto no la mencionar√©, pero es un tema complicado, dado que en federated learning se debe poder ejecutar el modelo de ML en m√∫ltiples dispositivos, que pueden tener diferentes APIs a nivel de OS, y tambi√©n otras restricciones como uso de memoria y CPU. No se puede llegar y matar la bater√≠a del dispositivo ejecutando un proceso alto en el uso de CPU (como lo es entrenar un modelo), por ejemplo.</p>
<p>Por otro lado, existen otras restricciones ¬øc√≥mo se deben estandarizar las entradas al modelo (batches) para poder tener soporte en m√∫ltiples tipos de modelos que pueden tener diferentes tipos de entrada? (ej. im√°genes, textos, features). Un sub-proyecto que propuse, consisti√≥ en traer claridad en estas restricciones y ambiente. Luego de m√∫ltiples desarrollos, logr√© implementar diferentes tipos de modelos (modelos basados en features simples, visi√≥n computacional, NLP, clasificadores, auto-codificadores variacionales <em>VAE</em>, etc) que se pod√≠an ejecutar en una arquitectura homog√©nea. En la implementaci√≥n, para lograr esta estandarizaci√≥n, se requiere incrustar metadata al modelo (qu√© tipo de feature es, entre otras cosas). Mis XFN estaban implementando un modelo de visi√≥n computacional bastante complejo (no quiero ni recordar lo complejo que era ese c√≥digo y esa red neuronal üòÖ). En la implementaci√≥n existente del sistema que estaba en nuestro lado (c√≥digo viejo), para poder normalizar los datos y ejecutarlos en este motor, se deb√≠a leer la imagen y cada pixel era una feature.</p>
<p>Para modelos con entradas peque√±as como <a href="https://paperswithcode.com/dataset/femnist">FEMNIST</a>, esto funcionaba perfecto. Sin embargo, para el modelo que se estaba desarrollando, las imagenes a procesar eran mucho m√°s grandes, por lo que hab√≠a problemas de escalabilidad. No entrar√© en detalle, pero se me ocurri√≥ implementar un algoritmo que redujo la cabtidad de escrituras de $O(C\cdot H \cdot W)$ a $O(C)$ (donde $C$ es el n√∫mero de canales, $H$ la altura y $W$ la anchura de la imagen). Esto solucion√≥ el problema de escalabilidad y permiti√≥ a los XFN a continuar explorando FL. Como el lector se dar√° cuenta esto era un <em>launch blocker</em>.</p>
<p>En fin, hubo una pl√©tora de <em>launch blockers</em> durante el a√±o (encriptaci√≥n, problemas con <em>backpropagation</em>, observabilidad, exportaci√≥n de operadores, <em>model authoring</em>, <em>you name it</em>), que afortunadamente como logr√© familarizarme r√°pido con el c√≥digo, solucion√© de forma satisfactoria. Lo curioso es que me toc√≥ meter mano en base de c√≥digo ajena, lo que fue una experiencia enriquecedora, que a√±adi√≥ m√°s cicatrices a mis a√±os de circo lidiando con b√°ses de c√≥digo gigantes, desconocidas y de forma r√°pida. El impacto, logramos poner en producci√≥n el primer modelo de visi√≥n computacional utilizando FL, un logro nada menor.</p>
<h2 id="un-poco-ms-de-on-device-training">Un poco m√°s de on-device training</h2>
<p>Otro proyecto interesante en el que trabaj√© fue hacer fine-tuning <em>on device</em> de LLMs usando <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>. Los resultados fueron presentados en la <a href="https://pytorch2024.sched.com/event/1fHln/executorch-beta-and-on-device-generative-ai-support-mergen-nachin-mengtao-martin-yuan-meta">Pytoch Conference 2024</a> (minuto 16:24). Esto fue un gran desaf√≠o y tiene un impacto a nivel de industria, lo que hace que me sienta orgulloso del trabajo y los proyectos que he escogido. Por supuesto, hay consideraciones t√©cnicas importantes, y hay que ser muy orientado al detalle: Tener benchmarks, asegurarse de una correcta implementaci√≥n a bajo nivel, tener claro c√≥mo delegar instrucciones y que el backend tenga soporte de las distintas operaciones a nivel de OS. Por ejemplo, es una mala idea usar <code>malloc</code> en <em>embedded systems</em>. Dejo al lector investigar por qu√©‚Ä¶</p>
<h2 id="simulaciones-fl">Simulaciones FL</h2>
<p>Otro proyecto interesante fue escalar un simulador de FL, proyecto OSS <a href="https://github.com/facebookresearch/FLSim">flsim</a>. Sin embargo, para uso interno, hab√≠a problemas de escalabilidad entre otros detalles. Escalar el sistema no fue simple. Adem√°s de la l√≥gica de serializaci√≥n y deserializaci√≥n de los modelos, para simular dispositivos el servidor, hay otros detalles, como el hacer la transferencia por red de forma eficiente. En este caso utilizamos APIs de bajo nivel <code>isend</code> e <code>irecv</code> (provistas por <code>pytoch</code> distributed). Despu√©s de una fase experimental de benchmarks, probamos distintos tipos de tareas (SFT, clasificaci√≥n, procesamiento de im√°genes). Finalmente, en temas de <em>throughput</em> nos decantamos por una soluci√≥n usando el protocolo <code>RPC</code> (hab√≠an otros temas de uso de memoria, por ejemplo entrenando LLMs que fueron un gran desaf√≠o t√©cnico). Para hacer escalar la carga de datos, y la ejecuci√≥n, hubo que dise√±ar un sistema como el mostrado en la figura 2. Hubo otros desaf√≠os como por ejemplo no agregar todos los modelos de los clientes en el servidor (cuello de botella), si no que distribuir la carga de forma inteligente para aprovechar de mejor manera la concurrencia.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/fcb3d8cdcdf5fbcfdcf4a4699e9d48dd42a4d4f9/sys-design-dist-fl.png" alt="fl-dist-design" /></p>
<p><em>Fig 2: Dise√±o de sistema distribuido para simulaciones FL.</em></p>
</div>
<p>El dise√±o est√° muy simplificado, hay muchos detalles t√©cnicos que no mencionar√©. Sin embargo, para un caso de uso importante, logramos superar la meta y throughput de <code>100k users/min</code> a <code>250k users/min</code>, que es bastante bueno para simulaciones a gran escala. Tambi√©n logramos mejorar la carga de datos para soportar billones de entradas. Yo dise√±√© el sistema y los sub-sistemas, hice algunas implementaciones m√°s complejas y el <em>boilerplate</em>. Luego otros ingenieros y researchers tomaron mi dise√±o y lo completaron. B√°sicamente lider√© m√∫ltiples proyectos.</p>
<h1 id="reflexiones">Reflexiones</h1>
<p>No tengo mucho m√°s que contar. S√≥lo para agregar, yo tambi√©n me estreso y no tengo la respuesta para todo. Sin embargo, en situaciones extremas se activa mi <em>modo de supervivencia</em>. Muchas veces estuve a contra-reloj con problemas que parec√≠an no tener soluci√≥n y de alguna forma logr√© <strong>hackear el universo y hacer aparecer una soluci√≥n</strong>. Lo que he podido notar, y que me han comentado algunas personas, es que no toda la gente tiene ese <em>modo</em> (aunque para mi sea algo natural).</p>
<p>Por otro lado, vi muchos casos de ingenieros que fueron etiquetados como NRA (<em>Non-Regrettable Attrition</em>). Algunos se memorizaron mucho el proceso de entrevistas, quedaron en niveles m√°s altos del que deber√≠an haber estado y lamentablemente <em>los dejaron ir</em>. Otros, nunca fueron promovidos en los l√≠mites de tiempo establecidos y despu√©s de un par de semestres, tambi√©n <em>los dejaron ir</em>. En fin, no todos son un buen ajuste para todos lados. Incluso yo no he sido buen ajuste en algunas empresas (por suerte no he quedado en dichos procesos). Sin embargo, tambi√©n presenci√© casos en que el ingeniero tuvo muy buen desempe√±o, pero una mala mitad. Siempre hay externalidades como: problemas familiares, enfermedades, etc.</p>
<p>Nadie <em>est√° a salvo</em>, definitivamente <strong>nadie es imprescindible</strong>. Me tiene con dolor de est√≥mago pensar en el futuro, en el sentido de que yo igual podr√≠a tener un <em>mal periodo en la chamba</em>. Sin embargo, el hecho de que <strong>existe una alta probabilidad de ser despedido</strong> en la vida laboral, me deja menos amargura y tampoco es el fin del mundo. Creo que lo m√°s importante es cuidar la salud y las relaciones personales. Lamentablemente, por ahora yo soy un trabaj√≥lico üòÖ, pero estoy intentando definir un l√≠mite entre lo laboral y lo personal‚Ä¶</p>
<h1 id="cierre">Cierre</h1>
<p>Casos anecd√≥ticos, he recibido comentarios como: ‚Äúse presenta como experto en ML‚Äù o ‚Äúc√≥mo te contrataron en Meta‚Äù, etc. Yo <strong>nunca me he autoproclamado experto</strong>, pueden revisar mi LinkedIn de pies a cabeza y no van a encontrar ese adjetivo (lo uso muy rara vez).</p>
<p>Creo de todas maneras que hago cosas que no son tan comunes:</p>
<ul>
<li>He contribuido al open-source en proyectos grandes</li>
<li>he contribuido al estado del arte en la literatura (en ML y ling√º√≠stica computacional), en la figura 3 muestro un pantallazo a mi google scholar. Puedo ser un pelagato, pero el hecho de haber publicado en revistas donde la revisi√≥n es rigurosa, me imagino que me da algunos puntos.</li>
</ul>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/0431d1bb37ebb4690d5bf8571646104b0d4b48fa/citations.png" alt="dpalma-google-scholar" /></p>
<p><em>Fig 3: Citas en google scholar.</em></p>
</div>
<ul>
<li>Nunca he tomado el <em>atajo</em> de ir a copiar y pegar tutoriales, o revisar art√≠culos que no hayan sido revisados y contrastados.</li>
</ul>
<p>Para el mito <em>los ingenieros de FAANG no saben tal tecnolog√≠a, o memorizan leetcode, blah blah</em>. Existe una <strong>bi-direccionalidad</strong>. Me ha tocado ver ingenieros considerados <em>senior</em> en algunas empresas (con todo el stack + cloud, etc.) que han echado a los 6 meses porque no cumplieron con las expectativas.</p>
<p>En mi opini√≥n se cumplen 3 axiomas:</p>
<p>$$\text{Saber } N \text{ ‚Äútecnolog√≠as‚Äù}\nRightarrow \text{ser buen ingeniero} \quad (1)$$</p>
<p>Hace unos a√±os se salpicoteaban bastante los t√©rminos ‚Äúdata pipeline‚Äù <em>‚Äúbig data‚Äù ‚Äúspark‚Äù ‚Äúcloud‚Äù</em>. Ahora es <em>‚ÄúDB vectoriales‚Äù ‚Äúagentes‚Äù ‚ÄúLLM‚Äù</em> (generalmente autoproclamados expertos).</p>
<p>$$ \text{Llegar a una FAANG} \nRightarrow \text{ser buen ingeniero} \quad (2)$$</p>
<p>Lamentablemente he visto ingenieros que no tuvieron buen desempe√±o en sus primeros 6 meses - 2 a√±os.</p>
<p>$$\text{No trabajar en FAANGs} \nRightarrow \text{no ser bueno/top} \quad (3)$$</p>
<p>He conocido ingenieros <em>No FAANGs</em> excelentes a lo largo de mi carrera.</p>]]></content><author><name>dpalmasan</name></author><category term="swe" /><category term="dev" /><summary type="html"><![CDATA[Introducci√≥n Como muchos sabr√°n llevo un poco m√°s de dos a√±os trabajando en Meta. En este post comparto algunas experiencias √∫ltimo fragmento en estos 2.8 a√±os que llevo ac√°. Adelanto que no ser√° un post tan largo ni con mucho detalle, y tendr√° dos secciones principales: Mi experiencia en este 3er ciclo (2024) Algunas reflexiones/opiniones Vale la pena leer el post completo para llegar a lo jugoso/sabroso. Contexto En otro post habl√© sobre mis experiencias en Meta, b√°sicamente sobre los primeros dos a√±os que tuve. En este post hablar√© de mi tercer ciclo, de c√≥mo me cambi√© de equipo, las diferencias. Mi tercer a√±o en USA Primero lo m√°s importante, sobreviv√≠ 3 rondas de despidos: 2022 y 2023 hubo recortes de presupuesto y el m√°s reciente (Febrero 10, 2025) fue por desempe√±o. No me referir√© mucho a estos temas, ya que en mi post Diferentes Experiencias mencion√© c√≥mo es el tema de la evaluaci√≥n de desempe√±o en Meta (que vale la pena recordar, es muy intensa, m√°s intensa que en cualquier experiencia previa que haya tenido). Mi performance rating de este tercer ciclo (2024) fue Exceeded Expectations. He ido a la baja jaja, mi primer a√±o saqu√© redefined, el segundo greatly exceeded y ahora exceeded‚Ä¶ En fin, significa que hay espacio para mejorar üòä Algunas Memorias Personales Para destacar este a√±o: Trabaj√© en problemas interesantes, en particular en el espacio de Federated Learning. Me toc√≥ tocar e implementar bibliotecas nativas (jni) (android y otros dispositivos), tuve que hacer implementaciones en java y kotlin. Este √∫ltimo nunca lo hab√≠a tocado, fue una experiencia interesante. He sido mentor 4 veces en Meta. Un@ de ell@s logr√≥ el rating Exceeds Expectations habiendo entrado en la segunda mitad del a√±o. Originalmente se iba a ir por saltarse la evaluaci√≥n al ser nuev@ pero le di soporte y logr√≥ algo mucho mejor. Pecho inflado cuando me agradeci√≥ mi apoyo üòä. Voy a empezar a ser entrevistador para posiciones de SWE/ML. Tuve excelente feedback de ingenieros que admiro (y tengo en un pedestal). Palabras como top engineer in the problem space, standout engineer, great engineer, best in class XFN, etc. Baj√© m√°s de 11 kg, estoy en mi aventura de ser influencer fitness üòÇ. Romp√≠ mi record de pull ups y estoy haciendo pull ups con +50kg (extras). Logr√© sacar el muscle up üòä. Tambi√©n de a poco mejorando mi press de banca. Fig 1: Yo haciendo un muscle up, anduve por Santiago en Enero. Tiempo para una Historia A fines del 2023 me cambi√© de equipo, rechazando una posible promoci√≥n a E6, y tir√°ndome hacia lo desconocido. Me transfer√≠ de un equipo de producto, a un equipo de infraestructura. Qu√© significa ello, en un equipo de producto los proyectos est√°n orientados a resolver problemas con objetivos claros y espec√≠ficos, por ejemplo implementar X para aumentar el revenue en un Y%. En este tipo de ambiente el impacto est√° alineado a objetivos globales directos. Lo que he notado, es que las iteraciones son r√°pidas, ya que hay que mover los gradientes en direcci√≥n a un mejoramiento de m√©tricas que impacten el revenue y los proyectos son en general cortoplacistas. Por otro lado, en un equipo de infraestructura, las iteraciones son lentas. Los proyectos son m√°s a largo plazo y el objetivo principal es implementar infraestructura que sea escalable, confiable, f√°cil de usar, y con buen desempe√±o en medidas de eficiencia (uso de memoria, latencia, etc.). En este tipo de proyecto el impacto por lo general es indirecto y m√°s complicado de medir en comparaci√≥n a un equipo de producto. Cabe destacar que la direcci√≥n es a largo plazo. Aprendizaje Federado En particular, mi equipo actual provee una infraestructura para el aprendizaje federado (Federated Learning, FL), el cual expliqu√© en mi post Introducci√≥n al Aprendizaje Federado. Debo admitir que inicialmente sufr√≠ en mi fase de ramp up, ya que el stack era completamente diferente a lo que estaba acostumbrado. En mi equipo previo el stack era principalmente Haskell, Hack y python. Tuve que aprender y meterme en una base de c√≥digo gigante donde el 90% del c√≥digo est√° escrito en C++. Las √∫nicas experiencias que hab√≠a tenido en C++ fueron m√°s bien acad√©micas, y nada comparables a programar en este lenguaje en un sistema a nivel de industria. Mucho menos lidiar con una base de c√≥digo con cientos de archivos, l√≠neas de c√≥digo, m√∫ltiples servicios, y un problema nuevo (FL) en el que no ten√≠a experiencia. Primeros meses, tengo la tarea de entender los diferentes ejecutores de c√≥digo nativo en pytorch. No voy a discutir el stack en detalle, pero para ejecutar pytorch en multi-plataformas se puede usar JIT, b√°sicamete scriptear los modelos y hacer tracing de todos los componentes necesarios para su ejecuci√≥n. Debiese ser obvio, pero para aclarar, hay ciertas restricciones a la hora de scriptear, como por ejemplo no se pueden tener todas las directivas de python y s√≥lo se puede scriptear un subconjunto de tipos/objetos. Por otro lado, el tama√±o del binario importa, por lo que no podemos llegar y scriptear el modelo utilizando todos los operadores de pytorch. La ingenier√≠a de esto no la mencionar√©, pero es un tema complicado, dado que en federated learning se debe poder ejecutar el modelo de ML en m√∫ltiples dispositivos, que pueden tener diferentes APIs a nivel de OS, y tambi√©n otras restricciones como uso de memoria y CPU. No se puede llegar y matar la bater√≠a del dispositivo ejecutando un proceso alto en el uso de CPU (como lo es entrenar un modelo), por ejemplo. Por otro lado, existen otras restricciones ¬øc√≥mo se deben estandarizar las entradas al modelo (batches) para poder tener soporte en m√∫ltiples tipos de modelos que pueden tener diferentes tipos de entrada? (ej. im√°genes, textos, features). Un sub-proyecto que propuse, consisti√≥ en traer claridad en estas restricciones y ambiente. Luego de m√∫ltiples desarrollos, logr√© implementar diferentes tipos de modelos (modelos basados en features simples, visi√≥n computacional, NLP, clasificadores, auto-codificadores variacionales VAE, etc) que se pod√≠an ejecutar en una arquitectura homog√©nea. En la implementaci√≥n, para lograr esta estandarizaci√≥n, se requiere incrustar metadata al modelo (qu√© tipo de feature es, entre otras cosas). Mis XFN estaban implementando un modelo de visi√≥n computacional bastante complejo (no quiero ni recordar lo complejo que era ese c√≥digo y esa red neuronal üòÖ). En la implementaci√≥n existente del sistema que estaba en nuestro lado (c√≥digo viejo), para poder normalizar los datos y ejecutarlos en este motor, se deb√≠a leer la imagen y cada pixel era una feature. Para modelos con entradas peque√±as como FEMNIST, esto funcionaba perfecto. Sin embargo, para el modelo que se estaba desarrollando, las imagenes a procesar eran mucho m√°s grandes, por lo que hab√≠a problemas de escalabilidad. No entrar√© en detalle, pero se me ocurri√≥ implementar un algoritmo que redujo la cabtidad de escrituras de $O(C\cdot H \cdot W)$ a $O(C)$ (donde $C$ es el n√∫mero de canales, $H$ la altura y $W$ la anchura de la imagen). Esto solucion√≥ el problema de escalabilidad y permiti√≥ a los XFN a continuar explorando FL. Como el lector se dar√° cuenta esto era un launch blocker. En fin, hubo una pl√©tora de launch blockers durante el a√±o (encriptaci√≥n, problemas con backpropagation, observabilidad, exportaci√≥n de operadores, model authoring, you name it), que afortunadamente como logr√© familarizarme r√°pido con el c√≥digo, solucion√© de forma satisfactoria. Lo curioso es que me toc√≥ meter mano en base de c√≥digo ajena, lo que fue una experiencia enriquecedora, que a√±adi√≥ m√°s cicatrices a mis a√±os de circo lidiando con b√°ses de c√≥digo gigantes, desconocidas y de forma r√°pida. El impacto, logramos poner en producci√≥n el primer modelo de visi√≥n computacional utilizando FL, un logro nada menor. Un poco m√°s de on-device training Otro proyecto interesante en el que trabaj√© fue hacer fine-tuning on device de LLMs usando ExecuTorch. Los resultados fueron presentados en la Pytoch Conference 2024 (minuto 16:24). Esto fue un gran desaf√≠o y tiene un impacto a nivel de industria, lo que hace que me sienta orgulloso del trabajo y los proyectos que he escogido. Por supuesto, hay consideraciones t√©cnicas importantes, y hay que ser muy orientado al detalle: Tener benchmarks, asegurarse de una correcta implementaci√≥n a bajo nivel, tener claro c√≥mo delegar instrucciones y que el backend tenga soporte de las distintas operaciones a nivel de OS. Por ejemplo, es una mala idea usar malloc en embedded systems. Dejo al lector investigar por qu√©‚Ä¶ Simulaciones FL Otro proyecto interesante fue escalar un simulador de FL, proyecto OSS flsim. Sin embargo, para uso interno, hab√≠a problemas de escalabilidad entre otros detalles. Escalar el sistema no fue simple. Adem√°s de la l√≥gica de serializaci√≥n y deserializaci√≥n de los modelos, para simular dispositivos el servidor, hay otros detalles, como el hacer la transferencia por red de forma eficiente. En este caso utilizamos APIs de bajo nivel isend e irecv (provistas por pytoch distributed). Despu√©s de una fase experimental de benchmarks, probamos distintos tipos de tareas (SFT, clasificaci√≥n, procesamiento de im√°genes). Finalmente, en temas de throughput nos decantamos por una soluci√≥n usando el protocolo RPC (hab√≠an otros temas de uso de memoria, por ejemplo entrenando LLMs que fueron un gran desaf√≠o t√©cnico). Para hacer escalar la carga de datos, y la ejecuci√≥n, hubo que dise√±ar un sistema como el mostrado en la figura 2. Hubo otros desaf√≠os como por ejemplo no agregar todos los modelos de los clientes en el servidor (cuello de botella), si no que distribuir la carga de forma inteligente para aprovechar de mejor manera la concurrencia. Fig 2: Dise√±o de sistema distribuido para simulaciones FL. El dise√±o est√° muy simplificado, hay muchos detalles t√©cnicos que no mencionar√©. Sin embargo, para un caso de uso importante, logramos superar la meta y throughput de 100k users/min a 250k users/min, que es bastante bueno para simulaciones a gran escala. Tambi√©n logramos mejorar la carga de datos para soportar billones de entradas. Yo dise√±√© el sistema y los sub-sistemas, hice algunas implementaciones m√°s complejas y el boilerplate. Luego otros ingenieros y researchers tomaron mi dise√±o y lo completaron. B√°sicamente lider√© m√∫ltiples proyectos. Reflexiones No tengo mucho m√°s que contar. S√≥lo para agregar, yo tambi√©n me estreso y no tengo la respuesta para todo. Sin embargo, en situaciones extremas se activa mi modo de supervivencia. Muchas veces estuve a contra-reloj con problemas que parec√≠an no tener soluci√≥n y de alguna forma logr√© hackear el universo y hacer aparecer una soluci√≥n. Lo que he podido notar, y que me han comentado algunas personas, es que no toda la gente tiene ese modo (aunque para mi sea algo natural). Por otro lado, vi muchos casos de ingenieros que fueron etiquetados como NRA (Non-Regrettable Attrition). Algunos se memorizaron mucho el proceso de entrevistas, quedaron en niveles m√°s altos del que deber√≠an haber estado y lamentablemente los dejaron ir. Otros, nunca fueron promovidos en los l√≠mites de tiempo establecidos y despu√©s de un par de semestres, tambi√©n los dejaron ir. En fin, no todos son un buen ajuste para todos lados. Incluso yo no he sido buen ajuste en algunas empresas (por suerte no he quedado en dichos procesos). Sin embargo, tambi√©n presenci√© casos en que el ingeniero tuvo muy buen desempe√±o, pero una mala mitad. Siempre hay externalidades como: problemas familiares, enfermedades, etc. Nadie est√° a salvo, definitivamente nadie es imprescindible. Me tiene con dolor de est√≥mago pensar en el futuro, en el sentido de que yo igual podr√≠a tener un mal periodo en la chamba. Sin embargo, el hecho de que existe una alta probabilidad de ser despedido en la vida laboral, me deja menos amargura y tampoco es el fin del mundo. Creo que lo m√°s importante es cuidar la salud y las relaciones personales. Lamentablemente, por ahora yo soy un trabaj√≥lico üòÖ, pero estoy intentando definir un l√≠mite entre lo laboral y lo personal‚Ä¶ Cierre Casos anecd√≥ticos, he recibido comentarios como: ‚Äúse presenta como experto en ML‚Äù o ‚Äúc√≥mo te contrataron en Meta‚Äù, etc. Yo nunca me he autoproclamado experto, pueden revisar mi LinkedIn de pies a cabeza y no van a encontrar ese adjetivo (lo uso muy rara vez). Creo de todas maneras que hago cosas que no son tan comunes: He contribuido al open-source en proyectos grandes he contribuido al estado del arte en la literatura (en ML y ling√º√≠stica computacional), en la figura 3 muestro un pantallazo a mi google scholar. Puedo ser un pelagato, pero el hecho de haber publicado en revistas donde la revisi√≥n es rigurosa, me imagino que me da algunos puntos. Fig 3: Citas en google scholar. Nunca he tomado el atajo de ir a copiar y pegar tutoriales, o revisar art√≠culos que no hayan sido revisados y contrastados. Para el mito los ingenieros de FAANG no saben tal tecnolog√≠a, o memorizan leetcode, blah blah. Existe una bi-direccionalidad. Me ha tocado ver ingenieros considerados senior en algunas empresas (con todo el stack + cloud, etc.) que han echado a los 6 meses porque no cumplieron con las expectativas. En mi opini√≥n se cumplen 3 axiomas: $$\text{Saber } N \text{ ‚Äútecnolog√≠as‚Äù}\nRightarrow \text{ser buen ingeniero} \quad (1)$$ Hace unos a√±os se salpicoteaban bastante los t√©rminos ‚Äúdata pipeline‚Äù ‚Äúbig data‚Äù ‚Äúspark‚Äù ‚Äúcloud‚Äù. Ahora es ‚ÄúDB vectoriales‚Äù ‚Äúagentes‚Äù ‚ÄúLLM‚Äù (generalmente autoproclamados expertos). $$ \text{Llegar a una FAANG} \nRightarrow \text{ser buen ingeniero} \quad (2)$$ Lamentablemente he visto ingenieros que no tuvieron buen desempe√±o en sus primeros 6 meses - 2 a√±os. $$\text{No trabajar en FAANGs} \nRightarrow \text{no ser bueno/top} \quad (3)$$ He conocido ingenieros No FAANGs excelentes a lo largo de mi carrera.]]></summary></entry><entry><title type="html">Manejando emociones ¬øEstr√©s, burnout, falta de confianza?</title><link href="https://dpalmasan.github.io/website/swe/dev/2024/11/19/estres-burnout.html" rel="alternate" type="text/html" title="Manejando emociones ¬øEstr√©s, burnout, falta de confianza?" /><published>2024-11-19T15:23:00+00:00</published><updated>2024-11-19T15:23:00+00:00</updated><id>https://dpalmasan.github.io/website/swe/dev/2024/11/19/estres-burnout</id><content type="html" xml:base="https://dpalmasan.github.io/website/swe/dev/2024/11/19/estres-burnout.html"><![CDATA[<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/de83556bfd2586d497e80a014d356e0ba1d00a4a/polarbear.jpeg" alt="art" /></p>
</div>
<h1 id="introduccin">Introducci√≥n</h1>
<p>En este post hablo un poco de las emociones/pensamientos negativos que pueden surgir al trabajar en la industria tech. Tambi√©n menciono algunas de las estrategias que he seguido, y comparto tambi√©n problemas que he tenido, para que no crean que soy super-humano en base a mis otros posts. Aclaro al lector, que todo esto es en base a mi experiencia personal, son m√°s que nada opiniones.</p>
<h1 id="diferentes-estados">Diferentes estados</h1>
<p>Un t√≥pico muy com√∫n que me he topado en la industria, es el <em>s√≠ndrome del impostor</em>. En simples palabras este s√≠ndrome un patr√≥n psicol√≥gico en el que personas capaces y competentes dudan de sus habilidades y logros, sintiendo que son ‚Äúimpostores‚Äù que pronto ser√°n descubiertos. Me imagino que esto nace de una falta de confianza, o el hecho de ver ‚Äúal resto‚Äù o ‚Äúlo que hace el resto‚Äù exitoso y compararse con ellos. Sea cual sea la fuente, este causa varios problemas, como por ejemplo:</p>
<ul>
<li>Ansidedad</li>
<li>Estr√©s</li>
<li>Evitar nuevos desaf√≠os (estancarse)</li>
<li>Problemas de autoestima</li>
<li>Dificultad en relaciones laborales, como por ejemplo evitar pedir ayuda</li>
</ul>
<p>Otro elemento frecuente es el <em>burnout</em>. Este basicamente consiste en agotamiento ya sea f√≠sico, mental, emocional debido a un estr√©s prolongado. Algunos problemas que pueden surgir:</p>
<ul>
<li>Problemas de salud mental</li>
<li>Rendimiento laboral disminuye</li>
<li>Autoestima por los suelos</li>
<li>Deterioro de relaciones personales/laborales.</li>
</ul>
<h2 id="fuentes-de-problemas">Fuentes de problemas</h2>
<p>Existe una gran gama de fuentes que pueden llegar a producir los problemas mencionados anteriormente. Cada uno en su contexto, tendr√° algunas causas que impacten m√°s que otras. S√≥lo por compartir, los elementos que me hacen ruido y me producen algunos de los s√≠ntomas previos a los estados problem√°ticos que mencione anteriormente:</p>
<ul>
<li>
<p>Expectativas muy altas: Supongamos que tenemos una meta a largo plazo, pero que generalmente es alcanzable haciendo un esfuerzo $w_l$. Por otro lado tenemos el esfuerzo para cumplir las tareas diarias, digamos $w_d$, tenemos un delta $\Delta = |w_l - w_d|$. Ahora demos $\tau$ como el umbral necesario para cumplir con las expectativas personales a largo plazo. En el caso en que $\Delta \gg \tau$ entonces podemos tener problemas. El pensamiento de no poder llegar a las metas personales (por ejemplo tener un buen desempe√±o), ya que la distancia entre las expectativas y exceder expectativas es muy grande, hace que nos sintamos menos capaces, lo que puede llevar al s√≠ndrome del impostor o al burnout.</p>
</li>
<li>
<p>Malos l√≠deres: Los malos l√≠deres yo los llamo <em>l√≠deres wannabe</em>. Este tipo de l√≠deres no tienen habilidades de liderazgo natural (lamentablemente no fueron bendecidos con los genes), y en lugar de intentar comenzar paso a paso a desarrollar estas habilidades, intentan imponer autoridad o ponerse un escal√≥n m√°s arriba, sin tener las credenciales y provocando conflictos/amargura entre las personas del equipo. Este en realidad no lo considero un l√≠der, si no que es alguien que forzadamente toma el papel de l√≠der, en lo que yo considero una proactividad negativa. El camino ideal en mi opini√≥n es, primero ganarse la confianza del equipo y luego intentar escalar. Este tipo de personas hace que la competencia por subir de nivel no sea sana.</p>
</li>
<li>
<p>Lame-culos: Con este tipo de personas te vas a topar en cualquier lado. Al menos ha sido mi experiencia. En algunos casos, los ponen en su lugar, en otros les hacen el camino m√°s f√°cil en t√©rminos de expectativas reducidas. Esto produce conflictos y un mal ambiente laboral.</p>
</li>
</ul>
<h2 id="cul-es-mi-estrategia">Cu√°l es mi estrategia</h2>
<p>Aclaro que no tengo la respuesta, ya que las emociones son emociones y van a aparecer siempre. Es parte de existir, y no se pueden remover. Lo que llevo un tiempo haciendo y me hace poder manejar mejor los efectos de estos estados:</p>
<h3 id="mantenerse-saludable">1. Mantenerse saludable</h3>
<p>No es s√≥lo matarse en el gimnasio o trotando. No se puede escapar de una mala alimentaci√≥n. Por otro lado la vida sedentaria tiene sus consecuencias a largo plazo en el cuerpo como p√©rdida de movilidad, fuerza, entre otras cosas. Lo que hice fue invertir en mi, por ejemplo:</p>
<ul>
<li>Contrat√© coaching de alimentaci√≥n</li>
<li>Contrat√© <em>personal trainer</em></li>
<li>Empec√© a trotar. Como meta me propus√© ganarle a <em>MZ</em> corriendo los 5km üòÇ. Hasta ahora puedo hacer 3.2 km en 16 minutos. Mi meta es hacer los 5 en menos de 24. Esto es otro punto, tener metas alcanzables pero no simples me ha ayudado a mantenerme motivado. Hace un a√±o por temas mentales entre otras cosas, gan√© mucho peso y apenas pod√≠a trotar 5 minutos a 6.0 millas/hora. Ahora puedo durar &gt;16 mins a 7.5 millas por hora. No es nada de otro mundo, pero mejorar siempre es algo interesante.</li>
<li>En entrenamiento de fuerza, aclaro que ya pod√≠a hacer 10 dominadas (pull ups) antes de empezar con mis cambios. Ahora puedo hacer 5 con +40kg y ya cumpl√≠ mi primera meta de poder hacer <em>muscle ups</em>. Ahora quiero lograr 5 reps de estos, voy en 2.</li>
<li>Mi otra meta es bajar 10% de grasa, ya he avanzado me falta s√≥lo 6% desde que empec√© (ha sido lento)</li>
</ul>
<h3 id="buscar-ayuda-profesional">2. Buscar ayuda profesional</h3>
<p>Esto es siempre un tema delicado, pero la salud mental es importante. En algunos casos, podemos padecer de ciertas enfermedades/trastornos que es muy dif√≠cil si no imposible superarlos sin el monitoreo adecuado. Algunos dicen que hay que practicar <em>mindfulness</em>, meditaci√≥n, etc. Si bien estas son estrategias para manejar el tema mental, en algunos casos no es suficiente y el problema de ra√≠z es peor. Al no haber resultados las personas se pueden sentir frustradas y renunciar. No hay nada de malo en tener ayuda profesional.</p>
<h3 id="tener-un-lmite-claro-entre-la-vida-personal-y-la-laboral">3. Tener un l√≠mite claro entre la vida personal y la laboral</h3>
<p>Esto es lo m√°s complicado para mi y muy pocas veces logro pasar un fin de semana sin revisar el computador de la pega (trabajo). Mi problema personal es que en el trabajo tengo ‚Äúcomplejo de h√©roe‚Äù y quiero resolver todos los problemas, en especial los complicados para ser visto como imprescindible. Sin embargo, nadie es indispensable, no deber√≠a preocuparme mucho de mi rating final‚Ä¶ pero me desmotiva no exceder expectativas. Ahora estoy intentando soltar en esto y no darle mucha importancia. Al final del d√≠a, si hay despidos, recortes; nadie es inmune.</p>
<h1 id="cierre">Cierre</h1>
<p>En este post compart√≠ un poco de mis experiencias. Me disculpo si no es t√©cnico, pero a veces es bueno mostrar un poco el lado m√°s humano. Espero que no haya sido latero, y que pueda ayudar a uno que otro samaritano.</p>]]></content><author><name>dpalmasan</name></author><category term="swe" /><category term="dev" /><summary type="html"><![CDATA[Introducci√≥n En este post hablo un poco de las emociones/pensamientos negativos que pueden surgir al trabajar en la industria tech. Tambi√©n menciono algunas de las estrategias que he seguido, y comparto tambi√©n problemas que he tenido, para que no crean que soy super-humano en base a mis otros posts. Aclaro al lector, que todo esto es en base a mi experiencia personal, son m√°s que nada opiniones. Diferentes estados Un t√≥pico muy com√∫n que me he topado en la industria, es el s√≠ndrome del impostor. En simples palabras este s√≠ndrome un patr√≥n psicol√≥gico en el que personas capaces y competentes dudan de sus habilidades y logros, sintiendo que son ‚Äúimpostores‚Äù que pronto ser√°n descubiertos. Me imagino que esto nace de una falta de confianza, o el hecho de ver ‚Äúal resto‚Äù o ‚Äúlo que hace el resto‚Äù exitoso y compararse con ellos. Sea cual sea la fuente, este causa varios problemas, como por ejemplo: Ansidedad Estr√©s Evitar nuevos desaf√≠os (estancarse) Problemas de autoestima Dificultad en relaciones laborales, como por ejemplo evitar pedir ayuda Otro elemento frecuente es el burnout. Este basicamente consiste en agotamiento ya sea f√≠sico, mental, emocional debido a un estr√©s prolongado. Algunos problemas que pueden surgir: Problemas de salud mental Rendimiento laboral disminuye Autoestima por los suelos Deterioro de relaciones personales/laborales. Fuentes de problemas Existe una gran gama de fuentes que pueden llegar a producir los problemas mencionados anteriormente. Cada uno en su contexto, tendr√° algunas causas que impacten m√°s que otras. S√≥lo por compartir, los elementos que me hacen ruido y me producen algunos de los s√≠ntomas previos a los estados problem√°ticos que mencione anteriormente: Expectativas muy altas: Supongamos que tenemos una meta a largo plazo, pero que generalmente es alcanzable haciendo un esfuerzo $w_l$. Por otro lado tenemos el esfuerzo para cumplir las tareas diarias, digamos $w_d$, tenemos un delta $\Delta = |w_l - w_d|$. Ahora demos $\tau$ como el umbral necesario para cumplir con las expectativas personales a largo plazo. En el caso en que $\Delta \gg \tau$ entonces podemos tener problemas. El pensamiento de no poder llegar a las metas personales (por ejemplo tener un buen desempe√±o), ya que la distancia entre las expectativas y exceder expectativas es muy grande, hace que nos sintamos menos capaces, lo que puede llevar al s√≠ndrome del impostor o al burnout. Malos l√≠deres: Los malos l√≠deres yo los llamo l√≠deres wannabe. Este tipo de l√≠deres no tienen habilidades de liderazgo natural (lamentablemente no fueron bendecidos con los genes), y en lugar de intentar comenzar paso a paso a desarrollar estas habilidades, intentan imponer autoridad o ponerse un escal√≥n m√°s arriba, sin tener las credenciales y provocando conflictos/amargura entre las personas del equipo. Este en realidad no lo considero un l√≠der, si no que es alguien que forzadamente toma el papel de l√≠der, en lo que yo considero una proactividad negativa. El camino ideal en mi opini√≥n es, primero ganarse la confianza del equipo y luego intentar escalar. Este tipo de personas hace que la competencia por subir de nivel no sea sana. Lame-culos: Con este tipo de personas te vas a topar en cualquier lado. Al menos ha sido mi experiencia. En algunos casos, los ponen en su lugar, en otros les hacen el camino m√°s f√°cil en t√©rminos de expectativas reducidas. Esto produce conflictos y un mal ambiente laboral. Cu√°l es mi estrategia Aclaro que no tengo la respuesta, ya que las emociones son emociones y van a aparecer siempre. Es parte de existir, y no se pueden remover. Lo que llevo un tiempo haciendo y me hace poder manejar mejor los efectos de estos estados: 1. Mantenerse saludable No es s√≥lo matarse en el gimnasio o trotando. No se puede escapar de una mala alimentaci√≥n. Por otro lado la vida sedentaria tiene sus consecuencias a largo plazo en el cuerpo como p√©rdida de movilidad, fuerza, entre otras cosas. Lo que hice fue invertir en mi, por ejemplo: Contrat√© coaching de alimentaci√≥n Contrat√© personal trainer Empec√© a trotar. Como meta me propus√© ganarle a MZ corriendo los 5km üòÇ. Hasta ahora puedo hacer 3.2 km en 16 minutos. Mi meta es hacer los 5 en menos de 24. Esto es otro punto, tener metas alcanzables pero no simples me ha ayudado a mantenerme motivado. Hace un a√±o por temas mentales entre otras cosas, gan√© mucho peso y apenas pod√≠a trotar 5 minutos a 6.0 millas/hora. Ahora puedo durar &gt;16 mins a 7.5 millas por hora. No es nada de otro mundo, pero mejorar siempre es algo interesante. En entrenamiento de fuerza, aclaro que ya pod√≠a hacer 10 dominadas (pull ups) antes de empezar con mis cambios. Ahora puedo hacer 5 con +40kg y ya cumpl√≠ mi primera meta de poder hacer muscle ups. Ahora quiero lograr 5 reps de estos, voy en 2. Mi otra meta es bajar 10% de grasa, ya he avanzado me falta s√≥lo 6% desde que empec√© (ha sido lento) 2. Buscar ayuda profesional Esto es siempre un tema delicado, pero la salud mental es importante. En algunos casos, podemos padecer de ciertas enfermedades/trastornos que es muy dif√≠cil si no imposible superarlos sin el monitoreo adecuado. Algunos dicen que hay que practicar mindfulness, meditaci√≥n, etc. Si bien estas son estrategias para manejar el tema mental, en algunos casos no es suficiente y el problema de ra√≠z es peor. Al no haber resultados las personas se pueden sentir frustradas y renunciar. No hay nada de malo en tener ayuda profesional. 3. Tener un l√≠mite claro entre la vida personal y la laboral Esto es lo m√°s complicado para mi y muy pocas veces logro pasar un fin de semana sin revisar el computador de la pega (trabajo). Mi problema personal es que en el trabajo tengo ‚Äúcomplejo de h√©roe‚Äù y quiero resolver todos los problemas, en especial los complicados para ser visto como imprescindible. Sin embargo, nadie es indispensable, no deber√≠a preocuparme mucho de mi rating final‚Ä¶ pero me desmotiva no exceder expectativas. Ahora estoy intentando soltar en esto y no darle mucha importancia. Al final del d√≠a, si hay despidos, recortes; nadie es inmune. Cierre En este post compart√≠ un poco de mis experiencias. Me disculpo si no es t√©cnico, pero a veces es bueno mostrar un poco el lado m√°s humano. Espero que no haya sido latero, y que pueda ayudar a uno que otro samaritano.]]></summary></entry><entry><title type="html">Diferentes Experiencias</title><link href="https://dpalmasan.github.io/website/swe/dev/2024/09/06/diferentes-experiencias.html" rel="alternate" type="text/html" title="Diferentes Experiencias" /><published>2024-09-06T15:23:00+00:00</published><updated>2024-09-06T15:23:00+00:00</updated><id>https://dpalmasan.github.io/website/swe/dev/2024/09/06/diferentes-experiencias</id><content type="html" xml:base="https://dpalmasan.github.io/website/swe/dev/2024/09/06/diferentes-experiencias.html"><![CDATA[<h1 id="introduccin">Introducci√≥n</h1>
<p>Como muchos sabr√°n llevo un poco m√°s de dos a√±os trabajando en Meta. En este post comparto algunas experiencias en estos 2.4 a√±os que llevo ac√°.</p>
<h2 id="contexto">Contexto</h2>
<p>Dadas mis experiencias previas (nunca llegu√© al titulo ‚Äúsenior‚Äù, excepto en un lugar cuyos t√≠tulos estaban inflad√≠simos). Luego de pasar por el proceso de selecci√≥n que consisti√≥ en 4 entrevistas de c√≥digo y dos de dise√±o de sistemas y una de ‚Äúcomportamiento‚Äù (t√©cnica STAR), qued√© como ingeniero de ML E4 (o Semi-Senior). Debo admitir que cuando di las entrevistas para Meta estaba relajado y me daba lo mismo el resultado, ya que ten√≠a dos ofertas en empresas ‚Äúprestigiosas‚Äù, una como <em>Tech Lead</em> (MeLI) y en otra como SWE 2 (Microsoft); procesos de selcci√≥n similares. Sin embargo, se dio la casualidad de que recib√≠ una oferta de Meta, donde me reubicar√≠a en USA, y como vivir en el extranjero era uno de los logros que quer√≠a en mi vida, acept√© (adem√°s los beneficios eran buenos).</p>
<h2 id="primer-ao">Primer A√±o</h2>
<p>Todo complicado, al no saber nada. Al principio un poco estresado, ten√≠a que sacar el SSN (similar al RUT en Chile), abrir cuenta en el banco y buscar departamento. En esto me demor√© aproximadamente 1 mes, y con el tema del arriendo, estuve apretando el c*lo como dicen en Chilito ya que tuve un problema de √∫ltimo minuto jaja.</p>
<p>Comienza mi aventura en Meta, en ese tiempo ten√≠an el proceso de <em>bootcamp</em>, donde uno pasar por una suerte de inducci√≥n en c√≥mo funciona Meta, uno tiene un mentor de bootcamp, y se van haciendo tareas simples para distintos equipos (arreglar errores de lint, agregar tests, etc.). Entre eso hay que hacer cosas administrativas (sacar badge, registrarse en distintos temas y grupos etc.), cosas que no ten√≠a idea jaja, ni siquiera ten√≠a escritorio asignado (porque no era miembro de ning√∫n equipo a√∫n). Luego de estar un par de semanas en el bootcamp, toc√≥ buscar equipo. Tuve varias conversaciones, me ‚Äúsent√©‚Äù con distintos equipos, esto involucra ir a reuniones, tomar alguna tarea espec√≠fica para dicho equipo, etc. Al final, me convenci√≥ el equipo de integridad del negocio, el manager me convenci√≥ jaja ten√≠a un buen discurso.</p>
<p>Primer a√±o en el equipo, involucra conocer a la gente: XFN, el equipo en s√≠, los proyectos, etc. Al principio, me asignaron tareas como ‚Äúonboarding‚Äù y completar algunos proyectos. La verdad hice todo y pensaba que iba bien encaminado, hasta que en una conversaci√≥n de almuerzo se toc√≥ el tema de la evaluaci√≥n de desempe√±o (o en Meta el PSC: Performance Summary Cycle). En dicha conversaci√≥n se tiraron an√©cdotas, entre otros temas los cuales me hicieron entender dos cosas:</p>
<ol>
<li>PSC es estresante</li>
<li>PSC es algo serio</li>
</ol>
<p>De curioso me puse a investigar los distintos ratings de la evaluaci√≥n de desempe√±o:</p>
<ul>
<li>Below Expectations</li>
<li>Meets Most</li>
<li>Meets All</li>
<li>Exceeds Expectations</li>
<li>Greatly Exceeded Expectations</li>
<li>Redefined Expectations</li>
</ul>
<p>En ese momento se activ√≥ mi sentido de supervivencia, y empec√© a buscar problemas a resolver, para hacer m√°s de lo ‚Äúque me ped√≠an‚Äù, ya que entend√≠ que s√≥lo hacer lo justo <strong>no</strong> era suficiente. Lo primero que hice fue intentar interactuar m√°s con los XFN y encontr√© un problema interesante a resolver. Todo esto mientras resolv√≠a lo que ya se me hab√≠a asignado. Luego lleg√≥ el ‚Äútouchpoint‚Äù que es una previa al PSC final, este ocurre a mitad de a√±o, y recib√≠ feedback de pares. En general excelente feedback, excepto del tech lead. Este feedback no era negativo, pero en resumen: No estaba resolviendo problemas con gran impacto. Impacto es una palabra que se escucha casi todos los d√≠as en Meta. Debo admitir que esto me dej√≥ con dolor de estomago y diarrea jaja.</p>
<p>En la segunda mitad, me dediqu√© a entender qu√© era el impacto y empec√© a resolver problemas que lo tuvieran. Generalmente eran problemas que se esperaba tomaran meses y probablemente no se completar√≠an en dicha mitad; sin embargo me propuse a completarlos. Cabe destacar que existen cuatro ejes que se eval√∫an en el PSC:</p>
<ul>
<li>Impacto: Qu√© impacto tuviste durante el a√±o (e.g. generaste revenue, mejoraste alguna m√©trica que posiblemente mejore este, etc)</li>
<li>Better Engineering: C√≥digo escalable, tolerante a fallas, buen coverage de testing, manejo de incidentes, etc.</li>
<li>Direcci√≥n: Ser capaz de darte direcci√≥n y dar direcci√≥n a otros</li>
<li>People: Mentorear, entrevistas, organizar eventos, etc.</li>
</ul>
<p>En la segunda mitad logr√© completar proyectos con mayor impacto que el esperado (2x), adem√°s de terminar mis propios proyectos personales, que s√≠ tuvieron impacto. Para los curiosos, implement√© una lib para an√°lisis de anuncios, implement√© un modelo de detecci√≥n de malos actores basado en NLP, invent√© un modelo basado en grafos de negocios con LSA (Latent Semantic Analysis) para detecci√≥n de cuentas comprometidas, anomal√≠a de presupuestos en actividad de cuentas de anuncios para detecci√≥n de malos actores, entre otros proyectos m√°s peque√±os.</p>
<p>En la segunda mitad tuve feedback perfecto de un E6, m√°s excelente feedback de los XFN. Mi manager en varios 1:1 me dijo que a mi probablemente me hab√≠an hecho <em>low balling</em> (que me contrataron en un nivel m√°s bajo del que realmente era), y el √∫ltimo feedback que me dio era que yo estaba haciendo trabajo de E5 que tendr√≠a un rating <em>greatly exceeded</em>, al ser E4, saqu√© <em>redefined expectations</em> y me promovieron a E5 en un a√±o (que fue bastante r√°pido).</p>
<h3 id="extras">Extras</h3>
<p>Como nota aparte, m√°s cosas me dejaron con diarrea, como por ejemplo presenciar recortes de presupuestos y dos despidos masivos. Digamos que en varios segmentos del a√±o no lo pas√© bien.</p>
<h2 id="segundo-ao">Segundo A√±o</h2>
<p>Este a√±o me cambiaron de manager, ya que hubo una re-estructuraci√≥n (posterior a los despidos), la cual involucraba ‚Äúestrategia de achatamiento‚Äù cuyo objetivo era reducir las jerarqu√≠as y tener m√°s SWEs que managers. Mi nuevo manager me dijo que ahora como E5 las expectativas eran m√°s altas, pero que estaba entusiasmado con trabajar conmigo dado mi trabajo y mi rating del a√±o previo. Nuevamente, la gente esperando mucho de mi, otra vez dolor de est√≥mago, ansiedad, etc.</p>
<p>Este a√±o ya pas√© de ser un NN a ser alguien m√°s o menos ‚Äúfamoso‚Äù, por las contribuciones y los proyectos originales que hab√≠a presentado (en especial por el impacto). Entre varias conversaciones, conoc√≠ a un ‚Äúpartner‚Äù con el cual tomamos un proyecto gigante que ten√≠a m√∫ltiples sub-proyectos. No me quiero alargar mucho, pero resolvimos todo tipo de problemas y logramos mejorar la precisi√≥n de nuestros sistemas de 10% a 40% reduciendo el costo humano y agilizando la reacci√≥n a incidencias (lo que se traduce en m√°s millones para la empresa), creamos m√∫ltiples sistemas:</p>
<ol>
<li>Detecci√≥n de anomal√≠as en la publicaci√≥n de anuncios basada en heur√≠sticas</li>
<li>Detecci√≥n de cuentas comprometidas en base a im√°genes y v√≠deos</li>
<li>Detecci√≥n de cuentas comprometidas basadas en NLP + heur√≠sticas</li>
<li>Reducci√≥n de TAT en revisiones manuales de cuentas comprometidas</li>
<li>Priorizaci√≥n de revisiones humanas basadas en un modelo de NLP + similitud de im√°genes</li>
<li>Detecci√≥n de cl√∫sters de redes y dominios para ‚Äúbanear‚Äù sitios de actividad ilegal</li>
<li>Contra-estrategia de malos actores basada en ‚Äúvelocidad de campa√±as‚Äù</li>
<li>Fricci√≥n en publicaci√≥n de anuncios sospechosos para habilitar revenue</li>
</ol>
<p>Hasta ese punto y en conversaciones con este nuevo manager (que durante el a√±o fue bastante exigente y me dej√≥ con dolor de guata), me dio la ‚Äúse√±al‚Äù de que mi rating ser√≠a EE (exceeded expectations), sin embargo yo quer√≠a m√°s, estaba obsesionado y con mucha ambici√≥n y le mencion√© que quer√≠a al menos GE. GE es equivalente a ser un E6 que saca EE, me respondi√≥. Hab√≠a un proyecto que nadie quer√≠a hacer, migraci√≥n de un sistema gigante, b√°sicamente un motor que estaba hecho en Haskell al lenguaje Hack (PHP con esteroides). Ese proyecto se estimaba que tomar√≠a un a√±o. Me dijo, si logras hacerlo antes de que termine el a√±o, voy a pelear en el stack ranking para que tengas GE. As√≠ que manos a la obra, cuento corto lo logr√© en aproximadamente 4 meses (tuve que ser una m√°quina).</p>
<p>Al momento de peer review, mucho feedback positivo. Le ped√≠ nuevamente al tech lead que me diera feedback y esta vez me dijo que no se esperaba que yo fuera un ‚Äúmonstruo‚Äù y el feedback fue extremadamente positivo.</p>
<p>Finalmente me dieron el rating prometido (GE) y un jugoso bono jaja.</p>
<h2 id="tercer-ao">Tercer A√±o</h2>
<p>A fines del segundo a√±o, le hice saber a mi manager que me cambiar√≠a de equipo. Ahora estoy trabajando en <code>Pytorch</code> (biblioteca de deep learning), en un equipo de infra (distinto a mi equipo anterior que era de producto). Comenc√© con un manager, que se cambi√≥ de equipo y ahora tengo otro manager. Este nuevo manager es como un <em>coach</em>, pero muy exigente. Hasta ahora me trata de mover para que act√∫e como un E6, lo que, nuevamente me deja con dolor de est√≥mago. No voy a dar detalle de lo que estoy trabajando ahora, pero quiz√°s en un post el pr√≥ximo a√±o cuento como me fue. Por ahora, veo todo en una nebulosa y no tengo claro qu√© rating tendr√©. Mientras no sea MM, todo bien.</p>
<p>Como spoiler, ser un tech lead no es s√≥lo liderar, sino que es hacer que otros lideren. Y liderar en Meta, tiene otro significado; no es s√≥lo saber el stack, proponer dise√±os y participar en reuniones. Va mucho m√°s all√° de eso, un ejemplo es proponer una visi√≥n y roadmap para los siguientes $T$ periodos de tiempo, lo cual para mi no es claro a√∫n. Sin embargo, algo de eso voy haciendo; pero intento reducir el estr√©s.</p>
<h2 id="cierre">Cierre</h2>
<p>En definitiva, muchos pueden pensar que trabajar en Meta es flores y arcoiris, pero voy a dar el spoiler: No es as√≠. Estar en otro pa√≠s dependiendo de una visa, ya suma puntos base de ansiedad. Por otro lado, se valora y se espera mucha proactividad, y tener claro el impacto. El tener claro el impacto, como dec√≠a mi tech lead previo, es un m√∫sculo que hay que desarrollar, y al menos para mi, no fue f√°cil. De hecho ahora estoy intentando visualizar el impacto de los proyectos que me estoy inventando y que voy trabajando. Por otro lado, el PSC es un juego dif√≠cil de jugar. Lamentablemente ‚Äúhacer lo que te piden‚Äù te llevar√° a lo mucho a un rating MM o MA, dependiendo de las ambiciones de la persona, puede estar ok. Algunos otros queremos m√°s.</p>
<p>Finalmente, a pesar de lo estresante, la ansiedad que produce, los proyectos son muy divertidos y desafiantes. Adem√°s, es la empresa que m√°s he disfrutado para trabajar (y la que m√°s he durado hasta ahora)‚Ä¶</p>]]></content><author><name>dpalmasan</name></author><category term="swe" /><category term="dev" /><summary type="html"><![CDATA[Introducci√≥n Como muchos sabr√°n llevo un poco m√°s de dos a√±os trabajando en Meta. En este post comparto algunas experiencias en estos 2.4 a√±os que llevo ac√°. Contexto Dadas mis experiencias previas (nunca llegu√© al titulo ‚Äúsenior‚Äù, excepto en un lugar cuyos t√≠tulos estaban inflad√≠simos). Luego de pasar por el proceso de selecci√≥n que consisti√≥ en 4 entrevistas de c√≥digo y dos de dise√±o de sistemas y una de ‚Äúcomportamiento‚Äù (t√©cnica STAR), qued√© como ingeniero de ML E4 (o Semi-Senior). Debo admitir que cuando di las entrevistas para Meta estaba relajado y me daba lo mismo el resultado, ya que ten√≠a dos ofertas en empresas ‚Äúprestigiosas‚Äù, una como Tech Lead (MeLI) y en otra como SWE 2 (Microsoft); procesos de selcci√≥n similares. Sin embargo, se dio la casualidad de que recib√≠ una oferta de Meta, donde me reubicar√≠a en USA, y como vivir en el extranjero era uno de los logros que quer√≠a en mi vida, acept√© (adem√°s los beneficios eran buenos). Primer A√±o Todo complicado, al no saber nada. Al principio un poco estresado, ten√≠a que sacar el SSN (similar al RUT en Chile), abrir cuenta en el banco y buscar departamento. En esto me demor√© aproximadamente 1 mes, y con el tema del arriendo, estuve apretando el c*lo como dicen en Chilito ya que tuve un problema de √∫ltimo minuto jaja. Comienza mi aventura en Meta, en ese tiempo ten√≠an el proceso de bootcamp, donde uno pasar por una suerte de inducci√≥n en c√≥mo funciona Meta, uno tiene un mentor de bootcamp, y se van haciendo tareas simples para distintos equipos (arreglar errores de lint, agregar tests, etc.). Entre eso hay que hacer cosas administrativas (sacar badge, registrarse en distintos temas y grupos etc.), cosas que no ten√≠a idea jaja, ni siquiera ten√≠a escritorio asignado (porque no era miembro de ning√∫n equipo a√∫n). Luego de estar un par de semanas en el bootcamp, toc√≥ buscar equipo. Tuve varias conversaciones, me ‚Äúsent√©‚Äù con distintos equipos, esto involucra ir a reuniones, tomar alguna tarea espec√≠fica para dicho equipo, etc. Al final, me convenci√≥ el equipo de integridad del negocio, el manager me convenci√≥ jaja ten√≠a un buen discurso. Primer a√±o en el equipo, involucra conocer a la gente: XFN, el equipo en s√≠, los proyectos, etc. Al principio, me asignaron tareas como ‚Äúonboarding‚Äù y completar algunos proyectos. La verdad hice todo y pensaba que iba bien encaminado, hasta que en una conversaci√≥n de almuerzo se toc√≥ el tema de la evaluaci√≥n de desempe√±o (o en Meta el PSC: Performance Summary Cycle). En dicha conversaci√≥n se tiraron an√©cdotas, entre otros temas los cuales me hicieron entender dos cosas: PSC es estresante PSC es algo serio De curioso me puse a investigar los distintos ratings de la evaluaci√≥n de desempe√±o: Below Expectations Meets Most Meets All Exceeds Expectations Greatly Exceeded Expectations Redefined Expectations En ese momento se activ√≥ mi sentido de supervivencia, y empec√© a buscar problemas a resolver, para hacer m√°s de lo ‚Äúque me ped√≠an‚Äù, ya que entend√≠ que s√≥lo hacer lo justo no era suficiente. Lo primero que hice fue intentar interactuar m√°s con los XFN y encontr√© un problema interesante a resolver. Todo esto mientras resolv√≠a lo que ya se me hab√≠a asignado. Luego lleg√≥ el ‚Äútouchpoint‚Äù que es una previa al PSC final, este ocurre a mitad de a√±o, y recib√≠ feedback de pares. En general excelente feedback, excepto del tech lead. Este feedback no era negativo, pero en resumen: No estaba resolviendo problemas con gran impacto. Impacto es una palabra que se escucha casi todos los d√≠as en Meta. Debo admitir que esto me dej√≥ con dolor de estomago y diarrea jaja. En la segunda mitad, me dediqu√© a entender qu√© era el impacto y empec√© a resolver problemas que lo tuvieran. Generalmente eran problemas que se esperaba tomaran meses y probablemente no se completar√≠an en dicha mitad; sin embargo me propuse a completarlos. Cabe destacar que existen cuatro ejes que se eval√∫an en el PSC: Impacto: Qu√© impacto tuviste durante el a√±o (e.g. generaste revenue, mejoraste alguna m√©trica que posiblemente mejore este, etc) Better Engineering: C√≥digo escalable, tolerante a fallas, buen coverage de testing, manejo de incidentes, etc. Direcci√≥n: Ser capaz de darte direcci√≥n y dar direcci√≥n a otros People: Mentorear, entrevistas, organizar eventos, etc. En la segunda mitad logr√© completar proyectos con mayor impacto que el esperado (2x), adem√°s de terminar mis propios proyectos personales, que s√≠ tuvieron impacto. Para los curiosos, implement√© una lib para an√°lisis de anuncios, implement√© un modelo de detecci√≥n de malos actores basado en NLP, invent√© un modelo basado en grafos de negocios con LSA (Latent Semantic Analysis) para detecci√≥n de cuentas comprometidas, anomal√≠a de presupuestos en actividad de cuentas de anuncios para detecci√≥n de malos actores, entre otros proyectos m√°s peque√±os. En la segunda mitad tuve feedback perfecto de un E6, m√°s excelente feedback de los XFN. Mi manager en varios 1:1 me dijo que a mi probablemente me hab√≠an hecho low balling (que me contrataron en un nivel m√°s bajo del que realmente era), y el √∫ltimo feedback que me dio era que yo estaba haciendo trabajo de E5 que tendr√≠a un rating greatly exceeded, al ser E4, saqu√© redefined expectations y me promovieron a E5 en un a√±o (que fue bastante r√°pido). Extras Como nota aparte, m√°s cosas me dejaron con diarrea, como por ejemplo presenciar recortes de presupuestos y dos despidos masivos. Digamos que en varios segmentos del a√±o no lo pas√© bien. Segundo A√±o Este a√±o me cambiaron de manager, ya que hubo una re-estructuraci√≥n (posterior a los despidos), la cual involucraba ‚Äúestrategia de achatamiento‚Äù cuyo objetivo era reducir las jerarqu√≠as y tener m√°s SWEs que managers. Mi nuevo manager me dijo que ahora como E5 las expectativas eran m√°s altas, pero que estaba entusiasmado con trabajar conmigo dado mi trabajo y mi rating del a√±o previo. Nuevamente, la gente esperando mucho de mi, otra vez dolor de est√≥mago, ansiedad, etc. Este a√±o ya pas√© de ser un NN a ser alguien m√°s o menos ‚Äúfamoso‚Äù, por las contribuciones y los proyectos originales que hab√≠a presentado (en especial por el impacto). Entre varias conversaciones, conoc√≠ a un ‚Äúpartner‚Äù con el cual tomamos un proyecto gigante que ten√≠a m√∫ltiples sub-proyectos. No me quiero alargar mucho, pero resolvimos todo tipo de problemas y logramos mejorar la precisi√≥n de nuestros sistemas de 10% a 40% reduciendo el costo humano y agilizando la reacci√≥n a incidencias (lo que se traduce en m√°s millones para la empresa), creamos m√∫ltiples sistemas: Detecci√≥n de anomal√≠as en la publicaci√≥n de anuncios basada en heur√≠sticas Detecci√≥n de cuentas comprometidas en base a im√°genes y v√≠deos Detecci√≥n de cuentas comprometidas basadas en NLP + heur√≠sticas Reducci√≥n de TAT en revisiones manuales de cuentas comprometidas Priorizaci√≥n de revisiones humanas basadas en un modelo de NLP + similitud de im√°genes Detecci√≥n de cl√∫sters de redes y dominios para ‚Äúbanear‚Äù sitios de actividad ilegal Contra-estrategia de malos actores basada en ‚Äúvelocidad de campa√±as‚Äù Fricci√≥n en publicaci√≥n de anuncios sospechosos para habilitar revenue Hasta ese punto y en conversaciones con este nuevo manager (que durante el a√±o fue bastante exigente y me dej√≥ con dolor de guata), me dio la ‚Äúse√±al‚Äù de que mi rating ser√≠a EE (exceeded expectations), sin embargo yo quer√≠a m√°s, estaba obsesionado y con mucha ambici√≥n y le mencion√© que quer√≠a al menos GE. GE es equivalente a ser un E6 que saca EE, me respondi√≥. Hab√≠a un proyecto que nadie quer√≠a hacer, migraci√≥n de un sistema gigante, b√°sicamente un motor que estaba hecho en Haskell al lenguaje Hack (PHP con esteroides). Ese proyecto se estimaba que tomar√≠a un a√±o. Me dijo, si logras hacerlo antes de que termine el a√±o, voy a pelear en el stack ranking para que tengas GE. As√≠ que manos a la obra, cuento corto lo logr√© en aproximadamente 4 meses (tuve que ser una m√°quina). Al momento de peer review, mucho feedback positivo. Le ped√≠ nuevamente al tech lead que me diera feedback y esta vez me dijo que no se esperaba que yo fuera un ‚Äúmonstruo‚Äù y el feedback fue extremadamente positivo. Finalmente me dieron el rating prometido (GE) y un jugoso bono jaja. Tercer A√±o A fines del segundo a√±o, le hice saber a mi manager que me cambiar√≠a de equipo. Ahora estoy trabajando en Pytorch (biblioteca de deep learning), en un equipo de infra (distinto a mi equipo anterior que era de producto). Comenc√© con un manager, que se cambi√≥ de equipo y ahora tengo otro manager. Este nuevo manager es como un coach, pero muy exigente. Hasta ahora me trata de mover para que act√∫e como un E6, lo que, nuevamente me deja con dolor de est√≥mago. No voy a dar detalle de lo que estoy trabajando ahora, pero quiz√°s en un post el pr√≥ximo a√±o cuento como me fue. Por ahora, veo todo en una nebulosa y no tengo claro qu√© rating tendr√©. Mientras no sea MM, todo bien. Como spoiler, ser un tech lead no es s√≥lo liderar, sino que es hacer que otros lideren. Y liderar en Meta, tiene otro significado; no es s√≥lo saber el stack, proponer dise√±os y participar en reuniones. Va mucho m√°s all√° de eso, un ejemplo es proponer una visi√≥n y roadmap para los siguientes $T$ periodos de tiempo, lo cual para mi no es claro a√∫n. Sin embargo, algo de eso voy haciendo; pero intento reducir el estr√©s. Cierre En definitiva, muchos pueden pensar que trabajar en Meta es flores y arcoiris, pero voy a dar el spoiler: No es as√≠. Estar en otro pa√≠s dependiendo de una visa, ya suma puntos base de ansiedad. Por otro lado, se valora y se espera mucha proactividad, y tener claro el impacto. El tener claro el impacto, como dec√≠a mi tech lead previo, es un m√∫sculo que hay que desarrollar, y al menos para mi, no fue f√°cil. De hecho ahora estoy intentando visualizar el impacto de los proyectos que me estoy inventando y que voy trabajando. Por otro lado, el PSC es un juego dif√≠cil de jugar. Lamentablemente ‚Äúhacer lo que te piden‚Äù te llevar√° a lo mucho a un rating MM o MA, dependiendo de las ambiciones de la persona, puede estar ok. Algunos otros queremos m√°s. Finalmente, a pesar de lo estresante, la ansiedad que produce, los proyectos son muy divertidos y desafiantes. Adem√°s, es la empresa que m√°s he disfrutado para trabajar (y la que m√°s he durado hasta ahora)‚Ä¶]]></summary></entry><entry><title type="html">Reinforcement Learning: Multi-Armed Bandits</title><link href="https://dpalmasan.github.io/website/algorithms/ai/2024/07/05/multi-armed-bandits.html" rel="alternate" type="text/html" title="Reinforcement Learning: Multi-Armed Bandits" /><published>2024-07-05T00:37:00+00:00</published><updated>2024-07-05T00:37:00+00:00</updated><id>https://dpalmasan.github.io/website/algorithms/ai/2024/07/05/multi-armed-bandits</id><content type="html" xml:base="https://dpalmasan.github.io/website/algorithms/ai/2024/07/05/multi-armed-bandits.html"><![CDATA[<h1 id="introduccin">Introducci√≥n</h1>
<p>En este post hablo sobre un algoritmo cl√°sico de aprendizaje por refuerzo (o en ingl√©s <em>Reinforcement Learning</em>), y el que m√°s he visto en la pr√°ctica (experiencia personal). El algoritmo al cual hago referencia es el <strong>bandido multibrazo</strong>, o su nombre en ingl√©s <em>Multi-Armed bandits</em> (al cu√°l nos referiremos como MAB).</p>
<h1 id="multi-armed-bandits-mab">Multi-Armed Bandits (MAB)</h1>
<p>Tengamos la siguiente situaci√≥n en la que estamos en un casino jugando la m√°quina traga-monedas y tenemos $k$ palancas para mover. Cada acci√≥n a tomar es mover una palanca y esta tendr√° alguna probabilidad de ganar el premio. Idealmente queremos mover m√°s la ‚Äúmejor‚Äù palanca, es decir, la que m√°s frecuentemente nos permita ganar (recompensa). Otra posible situaci√≥n similar es tener una suite de pruebas (integraci√≥n continua en software) y un conjunto de m√°quinas para ejecutar dichas pruebas. Queremos distribuir los tests de manera que la suite termine de ejecutarse en la menor cantidad de tiempo.</p>
<p>En un MAB tenemos $k$ acciones, y cada una de dichas acciones tiene una recompensa esperada, dada la acci√≥n a ejecutar. Llamemos a esta recompensa esperada el ‚Äúvalor‚Äù de una acci√≥n. Denotamos la acci√≥n escogida en el tiempo $t$ como $A_t$, y su recompensa correspondiente como $R_t$. El valor de una acci√≥n arbitraria $a$, se denota como $q_*(a)$, y la recompensa esperada si se elige dicha acci√≥n:</p>
<p>$$q_*(a) = \mathop{\mathbb{E}}\left[R_t|A_t=a\right]$$</p>
<p>Si supieramos el valor de cada acci√≥n, el problema ser√≠a trivial. Simplemente, elegiriamos siempre la acci√≥n con la mejor recompensa. Asumiremos que no conocemos los valores de cada acci√≥n, aunque podemos tener un valor estimado para la acci√≥n, $a$ en el tiempo $t$ que llamaremos $Q_t(a)$. Queremos que $Q_t(a)$ est√© lo m√°s cerca posible de $q_*(a)$.</p>
<p>Dado que tenemos un estimado del valor de cada acci√≥n en un momento dado, podr√≠amos preguntarnos ¬øQu√© estrategia seguir para elegir la siguiente acci√≥n? Lo m√°s <em>codicioso</em> ser√≠a elegir la acci√≥n que estimamos, tendr√° la mayor recompensa. En este caso, estamos <strong>explotando</strong> el conocimiento que tenemos, ya que escogemos la acci√≥n que con la informaci√≥n que tenemos, parece ser la mejor; a esta estrategia le llamaremos <em>greedy</em>. Por otro lado, si escogemos una acci√≥n de forma arbitraria, estar√≠amos <strong>explorando</strong>, ya que esto nos permitir√≠a mejorar nuestra estimaci√≥n del valor de dicha acci√≥n. Cuando queremos maximizar la recompensa esperada en un momento $t$, explotar la informaci√≥n es una buena estrategia. Sin embargo, esta es una estrategia corto-placista, ya que permiti√©ndonos escoger una acci√≥n no tan buena a primera vista, podr√≠amos incluso mejorar nuestra recompensa en el largo plazo. Esto es en esencia el conflicto que existe entre exploraci√≥n y explotaci√≥n.</p>
<h2 id="mtodos-de-accin-valor">M√©todos de Acci√≥n-Valor</h2>
<p>Supongamos por el momento que estamos frente a un problema <em>estacionario</em>, esto quiere decir que los valores $q_*(a)$ se mantienen en el tiempo. ¬øC√≥mo podemos tener una buena estimaci√≥n del valor de cada acci√≥n? Una forma natural de obtener esta estimaci√≥n, es promediando las recompensas obtenidas en el tiempo:</p>
<p>$$Q_t(a) = \frac{\text{Suma de recompensas para la acci√≥n } a \text{ previo al paso } t}{\text{N√∫mero de veces que tomamos } a \text{ previo al paso } t}$$</p>
<p>$$
Q_t(a) = \frac{\sum_{i=1}^{t-1}{R_i\cdot\mathbb{1}_{A_i=a}}}{\sum_{i=1}^{t-1}\mathbb{1}_{A_i=a}}
$$</p>
<p>Donde $\mathbb{1}$ denota una variable aleatoria que es 1 si la condici√≥n se cumple y 0 en caso contrario. Si el denominador es cero, entonces definimos $Q_t(a)$ a alg√∫n valor constante. Cuando el denominador tiende al infinito, debido a la ley de los grandes n√∫meros, $Q_t(a)$ converge a $q_*(a)$. Llamamos a este m√©todo <em>muestreo-promedio</em> porque cada estimado es un promedio de una muestra de recompensas. Claro que esta es s√≥lo una forma de calcular este valor estimado y no necesariamente la mejor.</p>
<p>La regla m√°s simple para escoger una acci√≥n es elegir la que tenga el mayor valor estimado, es decir:</p>
<p>$$A_t = \underset{a}{\mathrm{argmax}} \ Q_t(a)$$</p>
<p>Esta estrategia siempre aplicar√° explotaci√≥n, ya que no intentar√° tomar acciones que tengan menos recompensa. Sin embargo, como mencionamos anteriormente, en algunos casos la acci√≥n que parece ser la mejor no es la que en el largo plazo nos dar√° la mejor recompensa. Una alternativa es definir un valor de probabilidad $\varepsilon$ peque√±o de tal forma que con dicha probabilidad escogemos un valor aleatorio.</p>
<h1 id="arm-bandit">10-Arm Bandit</h1>
<p>Consideremos el caso de un MAB de 10 ‚Äúbrazos‚Äù. Supongamos que conocemos la funcion de valores para cada acci√≥n, cuya media fue obtenida muestreando una distribuci√≥n Gaussiana y que $q_*(a)$ sigue una distribuci√≥n Gaussiana, tal como se muestra en la figura 1. El c√≥digo para generar el bandido:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.dpi"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">n_actions</span> <span class="o">=</span> <span class="mi">10</span>


<span class="k">def</span> <span class="nf">create_multiarmed_bandit</span><span class="p">(</span><span class="n">n_actions</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">]:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">actions</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_actions</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
    <span class="n">q_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">actions</span><span class="p">,</span> <span class="n">q_a</span>
</code></pre></div></div>
<p>Para crear el gr√°fico de la figura 1:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">actions</span><span class="p">,</span> <span class="n">q_a</span> <span class="o">=</span> <span class="n">create_multiarmed_bandit</span><span class="p">(</span><span class="n">n_actions</span><span class="p">)</span>

<span class="n">rewards</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">q_a</span><span class="p">[</span><span class="n">a</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">actions</span>
<span class="p">]</span>


<span class="n">plt</span><span class="p">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Acci√≥n"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Recompensa"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"10-armed bandit"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/22b2f34c8fd05586ff71bde0437d74522e71feb2/mab1.png" alt="qa_mab" /></p>
<p><em>Fig 1: Funci√≥n de valor para cada acci√≥n del 10-arm bandit.</em></p>
</div>
<p>Ejecutemos un experimento en el cual tomamos 2000 ejecuciones de distintos MAB, considerando algoritmo descrito anteriormente para estimar $Q_t(a)$, y realizar esto para 1000 pasos de tiempo $t$. Consideremos tambi√©n utilizar distintos valores de probabilidad de exploraci√≥n $\varepsilon$.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">stationary_experiment</span><span class="p">(</span>
    <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">]:</span>
    <span class="n">average_rewards</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">actions</span><span class="p">,</span> <span class="n">q_a</span> <span class="o">=</span> <span class="n">create_multiarmed_bandit</span><span class="p">(</span><span class="n">n_actions</span><span class="p">)</span>
    <span class="n">optimal_action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">q_a</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">count_optimal_action</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">optimal_action_perc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Q_t(a): Estimated expected reward. Initial estimate is 0
</span>    <span class="n">q_t_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Cumulative sum of rewards
</span>    <span class="n">reward_cum_sum</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_actions</span><span class="p">)</span>

    <span class="c1"># Number of steps the action a was taken
</span>    <span class="n">n_steps_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_actions</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_actions</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Take greedy action
</span>            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">q_t_a</span><span class="p">[:,</span> <span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">reward_cum_sum</span><span class="p">[</span><span class="n">action</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">q_a</span><span class="p">[</span><span class="n">action</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Estimating expected reward
</span>        <span class="n">q_t_a</span><span class="p">[:,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_cum_sum</span> <span class="o">/</span> <span class="n">n_steps_a</span>

        <span class="c1"># The reward from the action taken
</span>        <span class="n">average_rewards</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">q_t_a</span><span class="p">[</span><span class="n">action</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span>
        <span class="n">count_optimal_action</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">action</span> <span class="o">==</span> <span class="n">optimal_action</span><span class="p">)</span>
        <span class="n">optimal_action_perc</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">count_optimal_action</span> <span class="o">/</span> <span class="n">t</span>
        <span class="n">n_steps_a</span><span class="p">[</span><span class="n">action</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">average_rewards</span><span class="p">,</span> <span class="n">optimal_action_perc</span>


<span class="k">def</span> <span class="nf">mab_run_experiment</span><span class="p">(</span>
    <span class="n">n_experiments</span><span class="p">,</span> <span class="n">experiment_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">]],</span> <span class="o">*</span><span class="n">args</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">]:</span>
    <span class="n">average_rewards</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">optimal_action_perc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_experiments</span><span class="p">):</span>
        <span class="n">average_rewards_</span><span class="p">,</span> <span class="n">optimal_action_perc_</span> <span class="o">=</span> <span class="n">experiment_func</span><span class="p">(</span>
            <span class="o">*</span><span class="n">args</span>
        <span class="p">)</span>
        <span class="n">average_rewards</span> <span class="o">+=</span> <span class="n">average_rewards_</span>
        <span class="n">optimal_action_perc</span> <span class="o">+=</span> <span class="n">optimal_action_perc_</span>

    <span class="k">return</span> <span class="n">average_rewards</span> <span class="o">/</span> <span class="n">n_experiments</span><span class="p">,</span> <span class="n">optimal_action_perc</span> <span class="o">/</span> <span class="n">n_experiments</span>


<span class="n">n_experiments</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">rewards_e0</span><span class="p">,</span> <span class="n">optimal_action_perc_e0</span> <span class="o">=</span> <span class="n">mab_run_experiment</span><span class="p">(</span>
    <span class="n">n_experiments</span><span class="p">,</span> <span class="n">stationary_experiment</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">n_actions</span>
<span class="p">)</span>
<span class="n">rewards_e0_01</span><span class="p">,</span> <span class="n">optimal_action_perc_e0_01</span> <span class="o">=</span> <span class="n">mab_run_experiment</span><span class="p">(</span>
    <span class="n">n_experiments</span><span class="p">,</span> <span class="n">stationary_experiment</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">n_actions</span>
<span class="p">)</span>
<span class="n">rewards_e0_1</span><span class="p">,</span> <span class="n">optimal_action_perc_e0_1</span> <span class="o">=</span> <span class="n">mab_run_experiment</span><span class="p">(</span>
    <span class="n">n_experiments</span><span class="p">,</span> <span class="n">stationary_experiment</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/22b2f34c8fd05586ff71bde0437d74522e71feb2/mab2.png" alt="r_mab" /></p>
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/22b2f34c8fd05586ff71bde0437d74522e71feb2/mab3.png" alt="opt_mab" /></p>
<p><em>Fig 2: Medidas de desempe√±o para experimento de 10-arm bandit..</em></p>
</div>
<p>Podemos observar que siguiendo la estrategia <em>greedy</em>, sin exploraci√≥n, el algoritmo converge r√°pido, pero en el largo plazo la recompensa esperada es menor que en el caso donde permitimos la exploraci√≥n. Para $\varepsilon = 0.1$ observamos que su convergencia es m√°s r√°pida que el caso de $\varepsilon = 0.01$, pero pareciera ser que en este √∫ltimo caso se podr√° llegar a una recompensa esperada mayor. En fin, en ambos casos con exploraci√≥n, tomando a veces acciones que no se ve√≠an prometedoras, se mejor√≥ la recompensa en el largo plazo. Algo similar ocurre con la cantidad de veces que el agente (MAB) toma la acci√≥n √≥ptima. En el caso sin exploraci√≥n, el agente se queda estancado en un √≥ptimo local tomando s√≥lo ~1/3 de las veces la mejor acci√≥n. En los otros casos, con exploraci√≥n el agente es capaz de encontrar la acci√≥n √≥ptima un mayor porcentaje de las veces. Esto es porque a medida que obtenemos m√°s informaci√≥n de las otras acciones, podemos elegir la que es realmente mejor en el largo plazo.</p>
<h2 id="funcin-de-valor-no-estacionaria">¬øFunci√≥n de valor no estacionaria?</h2>
<p>En la simulaci√≥n de la secci√≥n previa, asumimos que la funci√≥n de valor para cada acci√≥n $q_*(a)$ se mantiene estacionaria a lo largo del tiempo. Sin embargo, la mayor√≠a de los problemas en aprendizaje por refuerzo tienen una funci√≥n de valor no estacionaria. Por completitud, simplifiquemos la ecuaci√≥n para estimar $Q_t(a)$. Para el an√°lisis, consideraremos una s√≥la acci√≥n:</p>
<p>Tenemos:</p>
<p>$$Q_n = \frac{R_1 + R_2 + \ldots + R_{n-1}}{n - 1}$$</p>
<p>Luego:</p>
<p>$$
\begin{align}
Q_{n + 1} &amp; = \frac{1}{n} \sum_{i=1}^n R_i \\
&amp; = \frac{1}{n} \left(R_n + \sum_{i=1}^n R_i\right) \\
&amp; = \frac{1}{n} \left(R_n + (n - 1)\frac{1}{n-1} \sum_{i=1}^n R_i\right) \\
&amp; = \frac{1}{n} \left(R_n + (n - 1)Q_n\right) \\
&amp; = Q_n + \frac{1}{n} \left[R_n - Q_n \right] \\
\end{align}
$$</p>
<p>Podemos observar en la ecuaci√≥n, que estamos siempre ponderando todas las recompensas desde el inicio hasta el paso de tiempo $n$, via $\alpha(n) = \frac{1}{n}$. El problema, es que si $q_*(a)$ cambia con el tiempo, entonces las recompensas observadas por ejemplo inicialmente, dejar√≠an de ser relevantes ya que la funci√≥n de valores para las acciones cambi√≥. Una forma de manejar esto es por ejemplo considerar un valor de $\alpha$ constante tal que $\alpha \in [0, 1)$.</p>
<p>La ecuaci√≥n quedar√≠a como:</p>
<p>$$
\begin{align}
Q_{n + 1} &amp; = \alpha \sum_{i=1}^n R_i \\
&amp; = \alpha R_n + (1 - \alpha) Q_n \\
&amp; = \alpha R_n + (1 - \alpha)[\alpha R_{n - 1} + (1 - \alpha) Q_{n - 1}] \\
&amp; = \alpha R_n + (1 - \alpha)\alpha R_{n - 1} + (1 - \alpha)^2 Q_{n - 1} \\
&amp; = \alpha R_n + (1 - \alpha)\alpha R_{n - 1} + (1 - \alpha)^2\alpha R_{n - 2} \\
&amp; \ldots + (1 - \alpha)^{n - 1}\alpha R_1 + (1 - \alpha)^n Q_1 \\
&amp; = (1 - \alpha)^n Q_1 + \sum_{i = 1}^{n} \alpha (1 - \alpha) ^ {n - i} R_i
\end{align}
$$</p>
<p>Se puede observar que hay un desconteo que aumenta con $n$, haciendo que la contribuci√≥n, por ejemplo, de acciones pasadas como $Q_1$ sean menores a medida que avanza $n$.</p>
<p>Consideremos ahora dos experimentos, uno en que consideramos la estrategia de muestra-media para estimar $Q_n$, es decir, considerando las contribuciones de todas las acciones pasadas pero en el caso en que $q_*(a)$ es no estacionaria. Tambi√©n consideraremos un experimento en el que utilizamos un peso $\alpha = 0.1$ que se mantendr√° constante. El c√≥digo para este experimento:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">non_stationary_experiment</span><span class="p">(</span>
    <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="bp">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">]:</span>
    <span class="n">average_rewards</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">actions</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_actions</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>

    <span class="c1"># Create the bandit with all q_a* equal
</span>    <span class="n">q_a_0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">q_a</span> <span class="o">=</span> <span class="p">[</span><span class="n">q_a_0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_actions</span>

    <span class="n">count_optimal_action</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">optimal_action_perc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Q_n(a): Estimated expected reward. Initial estimate is 0
</span>    <span class="n">q_n</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_actions</span><span class="p">)</span>
    <span class="n">n_actions_step</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_actions</span><span class="p">)</span>

    <span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_actions</span><span class="p">)</span>


    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Update the real action values
</span>        <span class="n">q_a</span> <span class="o">=</span> <span class="p">[</span><span class="n">q</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">q_a</span><span class="p">]</span>
        <span class="n">optimal_action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">q_a</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_actions</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Take greedy action
</span>            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">q_n</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">rewards</span><span class="p">[</span><span class="n">action</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">q_a</span><span class="p">[</span><span class="n">action</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">alpha</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">q_n</span> <span class="o">=</span> <span class="n">q_n</span> <span class="o">+</span> <span class="p">(</span><span class="n">rewards</span> <span class="o">-</span> <span class="n">q_n</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_actions_step</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">q_n</span> <span class="o">=</span> <span class="n">q_n</span> <span class="o">+</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">rewards</span> <span class="o">-</span> <span class="n">q_n</span><span class="p">)</span>

        <span class="c1"># The reward from the action taken
</span>        <span class="n">average_rewards</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">q_n</span><span class="p">[</span><span class="n">action</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">count_optimal_action</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">action</span> <span class="o">==</span> <span class="n">optimal_action</span><span class="p">)</span>
        <span class="n">optimal_action_perc</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">count_optimal_action</span> <span class="o">/</span> <span class="n">t</span>
        <span class="n">n_actions_step</span><span class="p">[</span><span class="n">action</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">average_rewards</span><span class="p">,</span> <span class="n">optimal_action_perc</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/2ed125da3e01259ce109bab7d577a759b45d0ffd/mab4.png" alt="r_mab" /></p>
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/2ed125da3e01259ce109bab7d577a759b45d0ffd/mab5.png" alt="opt_mab" /></p>
<p><em>Fig 3: Medidas de desempe√±o para experimento de 10-arm bandit, caso no estacionario y estrategia de muestreo-media</em></p>
</div>
<p>En este caso se observa que el agente tom√≥ muchos m√°s pasos de tiempo para lograr una recompensa esperada similar a la del caso estacionario; tom√≥ alrededor de <code>10x</code> m√°s de tiempo e incluso inicialmente tom√≥ peores acciones. Para el caso <em>greedy</em> se observa que la recompensa esperada qued√≥ estancada en alrededor de <code>0.1</code> en los otros casos fue mayor teniendo recompensas hasta <code>10x</code> mejores que el caso sin exploraci√≥n. Se observa que para $\varepsilon = 0.01$ se obtuvo una mejor recompensa esperada. En este caso es porque toma mayor cantidad de veces la acci√≥n √≥ptima debido a que explora con menor probabilidad. Por otro lado, para el caso de $\varepsilon = 0.1$, nuevamente encontr√≥ las acciones √≥ptimas antes que los otros casos, pues explora m√°s frecuentemente el espacio de b√∫squeda de acciones.</p>
<p>En la figura 4 se muestran los resultados para la ponderaci√≥n $\alpha = 0.1$.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/884f0b501bb7a1456ed54c853d75d778ce16d7f1/mab6.png" alt="r_mab" /></p>
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/884f0b501bb7a1456ed54c853d75d778ce16d7f1/mab7.png" alt="opt_mab" /></p>
<p><em>Fig 4: Medidas de desempe√±o para experimento de 10-arm bandit, caso no estacionario y estrategia de ponderaci√≥n con $\alpha = 0.1$</em></p>
</div>
<p>Para este caso se puede observar que la explotaci√≥n de informaci√≥n es m√°s efectiva, pues para el caso <em>greedy</em> con $\varepsilon = 0$, observamos que puede obtener mejores casos en el largo plazo que su contraparte con la estrategia muestreo-medio. Por otro lado, la recompensa al largo plazo es mayor para todos los agentes con respecto al caso previo.</p>
<h1 id="conclusiones">Conclusiones</h1>
<p>En este art√≠culo vimos una pincelada de <em>Reinforcement Learning</em>, discutimos sobre <em>Multi-Armed Bandits</em> y revisamos algunas simulaciones. Algunas conclusiones:</p>
<ul>
<li>Existe un conflicto entre exploraci√≥n y explotaci√≥n. Explotando la informaci√≥n podemos escoger la mejor acci√≥n en el momento de manera de maximizar la recompensa en el corto plazo. Sin embargo, si se explora, puede encontrarse que existen acciones que inicialmente no se ven prometedoras pero en el largo plazo obtienen una mejor recompensa.</li>
<li>C√≥mo se estima $q_*(a)$ es crucial para el desempe√±o del agente que aplique esta estrategia de <em>greedy</em>. Observamos que la convergencia es lenta en el caso no estacionario, respecto del estacionario y adem√°s que dependiendo de la estimaci√≥n la explotaci√≥n puede dar buenos resultados o converger en un √≥ptimo local.</li>
</ul>
<p>Algunas aplicaciones de MAB:</p>
<ol>
<li>Sistemas de recomendaci√≥n: MAB se pueden utilizar para hacer recomendaciones a los usuarios bas√°ndose en sus preferencias pasadas.</li>
<li>Anuncios Online: Optimizaci√≥n de anuncios a mostrar a los usuarios, eligiendo los m√°s relevantes para cada usuario.</li>
<li>Administraci√≥n de portafolios: MAB pueden usarse para optimizar la distribuci√≥n de activos en un portafolio, eligiendo las inversiones m√°s rentables.</li>
<li>Distribuci√≥n de recursos: MAB pueden usarse para optimizar la distribuci√≥n de recursos, por ejemplo recursos computacionales o ancho de banda, entre diferentes tareas/usuarios.</li>
<li>Precios din√°micos: MAB pueden utilizarse para optimizar el precio de productos o servicios en tiempo real, bas√°ndose en la demanda y otros factores.</li>
</ol>
<p>Existen otras aplicaciones. Yo personalmente, lo he visto en dos casos de uso de los que menciono: anuncios y distribuci√≥n de recursos computacionales.</p>
<p>Espero lector, que te haya gustado el art√≠culo. Un saludo‚Ä¶</p>]]></content><author><name>dpalmasan</name></author><category term="algorithms" /><category term="ai" /><summary type="html"><![CDATA[Introducci√≥n En este post hablo sobre un algoritmo cl√°sico de aprendizaje por refuerzo (o en ingl√©s Reinforcement Learning), y el que m√°s he visto en la pr√°ctica (experiencia personal). El algoritmo al cual hago referencia es el bandido multibrazo, o su nombre en ingl√©s Multi-Armed bandits (al cu√°l nos referiremos como MAB). Multi-Armed Bandits (MAB) Tengamos la siguiente situaci√≥n en la que estamos en un casino jugando la m√°quina traga-monedas y tenemos $k$ palancas para mover. Cada acci√≥n a tomar es mover una palanca y esta tendr√° alguna probabilidad de ganar el premio. Idealmente queremos mover m√°s la ‚Äúmejor‚Äù palanca, es decir, la que m√°s frecuentemente nos permita ganar (recompensa). Otra posible situaci√≥n similar es tener una suite de pruebas (integraci√≥n continua en software) y un conjunto de m√°quinas para ejecutar dichas pruebas. Queremos distribuir los tests de manera que la suite termine de ejecutarse en la menor cantidad de tiempo. En un MAB tenemos $k$ acciones, y cada una de dichas acciones tiene una recompensa esperada, dada la acci√≥n a ejecutar. Llamemos a esta recompensa esperada el ‚Äúvalor‚Äù de una acci√≥n. Denotamos la acci√≥n escogida en el tiempo $t$ como $A_t$, y su recompensa correspondiente como $R_t$. El valor de una acci√≥n arbitraria $a$, se denota como $q_*(a)$, y la recompensa esperada si se elige dicha acci√≥n: $$q_*(a) = \mathop{\mathbb{E}}\left[R_t|A_t=a\right]$$ Si supieramos el valor de cada acci√≥n, el problema ser√≠a trivial. Simplemente, elegiriamos siempre la acci√≥n con la mejor recompensa. Asumiremos que no conocemos los valores de cada acci√≥n, aunque podemos tener un valor estimado para la acci√≥n, $a$ en el tiempo $t$ que llamaremos $Q_t(a)$. Queremos que $Q_t(a)$ est√© lo m√°s cerca posible de $q_*(a)$. Dado que tenemos un estimado del valor de cada acci√≥n en un momento dado, podr√≠amos preguntarnos ¬øQu√© estrategia seguir para elegir la siguiente acci√≥n? Lo m√°s codicioso ser√≠a elegir la acci√≥n que estimamos, tendr√° la mayor recompensa. En este caso, estamos explotando el conocimiento que tenemos, ya que escogemos la acci√≥n que con la informaci√≥n que tenemos, parece ser la mejor; a esta estrategia le llamaremos greedy. Por otro lado, si escogemos una acci√≥n de forma arbitraria, estar√≠amos explorando, ya que esto nos permitir√≠a mejorar nuestra estimaci√≥n del valor de dicha acci√≥n. Cuando queremos maximizar la recompensa esperada en un momento $t$, explotar la informaci√≥n es una buena estrategia. Sin embargo, esta es una estrategia corto-placista, ya que permiti√©ndonos escoger una acci√≥n no tan buena a primera vista, podr√≠amos incluso mejorar nuestra recompensa en el largo plazo. Esto es en esencia el conflicto que existe entre exploraci√≥n y explotaci√≥n. M√©todos de Acci√≥n-Valor Supongamos por el momento que estamos frente a un problema estacionario, esto quiere decir que los valores $q_*(a)$ se mantienen en el tiempo. ¬øC√≥mo podemos tener una buena estimaci√≥n del valor de cada acci√≥n? Una forma natural de obtener esta estimaci√≥n, es promediando las recompensas obtenidas en el tiempo: $$Q_t(a) = \frac{\text{Suma de recompensas para la acci√≥n } a \text{ previo al paso } t}{\text{N√∫mero de veces que tomamos } a \text{ previo al paso } t}$$ $$ Q_t(a) = \frac{\sum_{i=1}^{t-1}{R_i\cdot\mathbb{1}_{A_i=a}}}{\sum_{i=1}^{t-1}\mathbb{1}_{A_i=a}} $$ Donde $\mathbb{1}$ denota una variable aleatoria que es 1 si la condici√≥n se cumple y 0 en caso contrario. Si el denominador es cero, entonces definimos $Q_t(a)$ a alg√∫n valor constante. Cuando el denominador tiende al infinito, debido a la ley de los grandes n√∫meros, $Q_t(a)$ converge a $q_*(a)$. Llamamos a este m√©todo muestreo-promedio porque cada estimado es un promedio de una muestra de recompensas. Claro que esta es s√≥lo una forma de calcular este valor estimado y no necesariamente la mejor. La regla m√°s simple para escoger una acci√≥n es elegir la que tenga el mayor valor estimado, es decir: $$A_t = \underset{a}{\mathrm{argmax}} \ Q_t(a)$$ Esta estrategia siempre aplicar√° explotaci√≥n, ya que no intentar√° tomar acciones que tengan menos recompensa. Sin embargo, como mencionamos anteriormente, en algunos casos la acci√≥n que parece ser la mejor no es la que en el largo plazo nos dar√° la mejor recompensa. Una alternativa es definir un valor de probabilidad $\varepsilon$ peque√±o de tal forma que con dicha probabilidad escogemos un valor aleatorio. 10-Arm Bandit Consideremos el caso de un MAB de 10 ‚Äúbrazos‚Äù. Supongamos que conocemos la funcion de valores para cada acci√≥n, cuya media fue obtenida muestreando una distribuci√≥n Gaussiana y que $q_*(a)$ sigue una distribuci√≥n Gaussiana, tal como se muestra en la figura 1. El c√≥digo para generar el bandido: from typing import Callable, Tuple import numpy as np import matplotlib.pyplot as plt]]></summary></entry><entry><title type="html">Resolviendo puzzles con algoritmos</title><link href="https://dpalmasan.github.io/website/algorithms/ai/2024/06/29/sliding-puzzle.html" rel="alternate" type="text/html" title="Resolviendo puzzles con algoritmos" /><published>2024-06-29T22:00:00+00:00</published><updated>2024-06-29T22:00:00+00:00</updated><id>https://dpalmasan.github.io/website/algorithms/ai/2024/06/29/sliding-puzzle</id><content type="html" xml:base="https://dpalmasan.github.io/website/algorithms/ai/2024/06/29/sliding-puzzle.html"><![CDATA[<h1 id="introduccin">Introducci√≥n</h1>
<p>Era el a√±o 2014, y me hab√≠a titulado de ingenier√≠a civil el√©ctrica en la Universidad de Concepci√≥n (¬°grande mi alma mater!). Tambi√©n estaba en conflicto pues ven√≠a saliendo de una pr√°ctica profesional que no me gust√≥ para nada (√°rea de mantenci√≥n de una planta papelera). No fue una buena experiencia y estaba dudando si era eso a lo que quer√≠a dedicarme en mi vida profesional. Por otro lado, siempre me gustaron las clases te√≥ricas en ingenier√≠a, las simulaciones y meter algo de c√≥digo; debo confesar que mi √∫nica experiencia programando fue un curso de un semestre en el lenguaje <code>C</code>, y el resto <code>MATLAB</code>.</p>
<p>En ese mismo a√±o alguien publica en facebook que dar√°n un curso ‚Äúgratis‚Äù de electromagnetismo en la plataforma edX (que yo desconoc√≠a), as√≠ que me inscrib√≠; lamentablemente dicho curso ya no est√° disponible, era el curso <em>8.02x - MIT Physics II: Electricity and Magnetism</em> (pero si no saben la historia <strong>funaron</strong> al profesor Walter Lewin; por lo que el curso ya no est√° dispnible en edX; hay que reconocer que las clases eran espectaculares). Debo decir que disfrut√© bastante el curso y hasta me un√≠ a grupos de facebook y participaba activamente en los foros de edX ayudando y respondiendo dudas de los problemas; ¬øqu√© pas√≥? Me volv√≠ adicto a los cursos en l√≠nea y me puse a tomar varios cursos (m√°s relacionados a la ingenier√≠a el√©ctrica). Luego, gracias a una de las personas que estaba en uno de esos cursos de f√≠sica donde yo participaba, encontr√© el m√≠tico curso <a href="https://www.edx.org/learn/computer-science/harvard-university-cs50-s-introduction-to-computer-science">CS50x: Introduction to Computer Science de Harvard</a>. Fue dicho curso en donde aprend√≠ lo introductorio de las Ciencias de la Computaci√≥n y varios temas de programaci√≥n (en especial en C) que desconoc√≠a. Con mi ‚Äúexperiencia‚Äù programando, no pens√© que ser√≠a un curso desafiante, pero lo fue. Lo interesante es que cada tarea, ten√≠a dos versiones: La tarea para aprobar y la versi√≥n ‚Äúhacker‚Äù. Yo logr√© resolver las versiones ‚Äúhacker‚Äù de todos los problemas, excepto de uno: <a href="https://docs.cs50.net/problems/fifteen/fifteen.html">The game of fifteen</a>. No entrar√© en detalles, pero en esencia es un puzzle, la tarea era implementar el puzzle como un juego de terminal y la versi√≥n hacker era implementar un comando ‚ÄúGOD‚Äù que resolviera el puzzle de forma autom√°tica. Este post es mi redenci√≥n e intento de soluci√≥n de este problema.</p>
<h1 id="tldr">TL;DR</h1>
<p>El repositorio github del c√≥digo: <a href="https://github.com/dpalmasan/n2_1_puzzle">N^2 Puzzle Solver</a></p>
<h1 id="n2---1-puzzle">¬ø$N^2 - 1$ Puzzle?</h1>
<p>El puzzle de $N^2 - 1$ es una grilla de $N\times N$ que consiste en $N^2 - 1$ piezas que deben moverse a una configuraci√≥n objetivo, que consiste en tener todas las piezas ordenadas de forma ascendente, como se muestra en la figura 1.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/1c42887ede70e37523fb601075a0e8cbf2d8a892/8puzzle-def.png" alt="puzzle-def" /></p>
<p><em>Fig 1: Ejemplo de puzzle de 8-piezas y su configuraci√≥n objetivo.</em></p>
</div>
<p>Para mover las piezas, hay una restricci√≥n, estas deben deslizarse, por ello es que la grilla tiene un espacio libre como se muestra en la figura. Cabe destacar que no todas las configuraciones posibles tienen soluci√≥n (no vamos a demostrar esto hoy jeje), por lo tanto, para lo que sigue del art√≠culo, asumiremos que existe soluci√≥n para la configuraci√≥n inicial.</p>
<p>¬øC√≥mo buscar una soluci√≥n? Pensando que cada puzzle representa un <strong>estado</strong>, entonces al realizar cualquier <strong>acci√≥n</strong> habr√° un cambio de estado. Considerando m√∫ltiples posibles acciones, constru√≠mos lo que es un <strong>espacio de estados</strong> que se muestra en la figura 2.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/1c42887ede70e37523fb601075a0e8cbf2d8a892/8puzzle-search.png" alt="puzzle-search" /></p>
<p><em>Fig 2: Ejemplo de espacio de estados para puzzle de 8-piezas dada una configuraci√≥n inicial.</em></p>
</div>
<p>Y aqu√≠ viene la gran pregunta de todo problema de inteligencia artificial ¬øC√≥mo explorar el espacio de estados para encontrar una soluci√≥n? ¬øC√≥mo encontrar la ‚Äúmejor‚Äù soluci√≥n? Existen varios algoritmos de b√∫squeda, y para no alargar tanto este art√≠culo, prefiero no mencionar todos. Sin embargo, para tener una intuici√≥n, consideremos el problema de encontrar el camino menos costoso entre una ciudad y otra.</p>
<h2 id="problemas-de-bsqueda">Problemas de B√∫squeda</h2>
<p>En la figura 3, se muestra un diagrama de las ciudades <code>A</code>, <code>B</code>, <code>C</code>, <code>D</code>, <code>E</code>, <code>F</code>, <code>G</code>, <code>H</code>. Cada flecha indica la conexi√≥n entre las ciudades el valor en la flecha indica el costo de viajar entre dos ciudades. Si qusieramos encontrar el camino menos costoso entre <code>A</code> y <code>H</code>, tenemos que usar dicho costo para realizar la b√∫squeda.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/b8153a6577ac00558bcf42e2f9580e2c3f3b4820/city-example.png" alt="puzzle-sol" /></p>
<p><em>Fig 3: Ejemplo de camino menos costoso entre ciudades.</em></p>
</div>
<p>Comencemos:</p>
<ol>
<li>Estoy en la ciudad <code>A</code>, puedo hacer <code>(A-&gt;B, 1)</code>, <code>(A-&gt;C, 3)</code>, <code>(A-&gt;E, 3)</code></li>
<li>Me cuesta menos el primer camino, luego puedo hacer <code>(A-&gt;B-&gt;C, 2)</code>, <code>(A-&gt;B-&gt;H, 15)</code> <code>(A-&gt;C, 3)</code>, <code>(A-&gt;E, 3)</code></li>
<li>Ahora podr√≠a elegir <code>(A-&gt;B-&gt;C, 2)</code>, luego tengo las opciones: <code>(A-&gt;B-&gt;C-&gt;D, 8)</code>, <code>(A-&gt;B-&gt;H, 15)</code> <code>(A-&gt;C, 3)</code>, <code>(A-&gt;E, 3)</code></li>
<li>Ahora elijo <code>(A-&gt;C, 3)</code>, luego: <code>(A-&gt;C-&gt;D, 9)</code>, <code>(A-&gt;B-&gt;C-&gt;D, 8)</code>, <code>(A-&gt;B-&gt;H, 15)</code>, <code>(A-&gt;E, 3)</code></li>
<li>Ahora elijo <code>(A-&gt;E, 3)</code>, luego: <code>(A-&gt;E-&gt;F, 4)</code>, <code>(A-&gt;C-&gt;D, 9)</code>, <code>(A-&gt;B-&gt;C-&gt;D, 8)</code>, <code>(A-&gt;B-&gt;H, 15)</code></li>
<li>Elijo <code>(A-&gt;E-&gt;F, 4)</code>, luego: <code>(A-&gt;E-&gt;F-&gt;G, 5)</code>, <code>(A-&gt;C-&gt;D, 9)</code>, <code>(A-&gt;B-&gt;C-&gt;D, 8)</code>, <code>(A-&gt;B-&gt;H, 15)</code></li>
<li>Elijo <code>(A-&gt;E-&gt;F-&gt;G, 5)</code>, luego: <code>(A-&gt;E-&gt;F-&gt;G-&gt;H, 6)</code>, <code>(A-&gt;C-&gt;D, 9)</code>, <code>(A-&gt;B-&gt;C-&gt;D, 8)</code>, <code>(A-&gt;B-&gt;H, 15)</code></li>
<li>Finalmente llegu√© a <code>H</code> con el recorriendo el siguiente camino: <code>A-&gt;E-&gt;F-&gt;G-&gt;H</code>. Que es el menos costoso, cuyo coste es 6.</li>
</ol>
<p>Como podemos observar, este es un enfoque completamente automatizable. De hecho, el algoritmo que acabamos de hacer se conoce como <strong>b√∫squeda de costo uniforme</strong>. Como se pudo observar, esta b√∫squeda fue no informada, ya que reaccionabamos al costo de las acciones y s√≥lo utilizamos informaci√≥n vista (pasada). ¬øQu√© pasar√≠a si tuviesemos informaci√≥n adicional? Por ejemplo ¬øQu√© pasar√≠a si supieramos exactamente cu√°nto falta para llegar al destino? Supongamos que existe una funci√≥n $f$, tal que $f(s) = n$, donde $s$ es una ciudad y $n$ es el costo m√≠nimo que existe desde $s$ hasta <code>H</code>. Por ejemplo si $s = \text{B}$ entonces <code>f(B) = 15</code>. Intentemos nuevamente el algoritmo, con esta informaci√≥n:</p>
<ol>
<li>Estoy en la ciudad <code>A</code>, puedo hacer <code>(A-&gt;B, 1 + 15)</code>, <code>(A-&gt;C, 3 + 14)</code>, <code>(A-&gt;E, 3 + 3)</code></li>
<li>Tomo <code>(A-&gt;E, 3)</code>, puedo hacer: <code>(A-&gt;B, 1 + 15)</code>, <code>(A-&gt;C, 3 + 14)</code>, <code>(A-&gt;E-&gt;F, 4 + 2)</code></li>
<li>Tomo <code>(A-E-&gt;F, 4)</code>, puedo hacer: <code>(A-&gt;B, 1 + 15)</code>, <code>(A-&gt;C, 3 + 14)</code>, <code>(A-&gt;E-&gt;F-&gt;G, 5 + 1)</code></li>
<li>Tomo <code>(A-&gt;E-&gt;F-&gt;G, 5)</code> puedo hacer: <code>(A-&gt;B, 1 + 15)</code>, <code>(A-&gt;C, 3 + 14)</code>, <code>(A-&gt;E-&gt;F-&gt;G-&gt;H, 5)</code></li>
<li>Llego a <code>H</code> tomando <code>(A-&gt;E-&gt;F-&gt;G-&gt;H, 6)</code>, camino menos costoso: 6.</li>
</ol>
<p>La diferencia, es que teniendo informaci√≥n pude descartar soluciones y reducir el espacio de b√∫squeda. Este algoritmo se conoce como <code>A*</code> (o <em>A estrella</em>). Ahora, generalmente no conocemos esta funci√≥n $f$. Generalmente, podemos tener una aproximaci√≥n $h$. Si dicha aproximaci√≥n es tal que $h$ nunca sobre-estima $f$ (es decir, $h(s) \leq f(s)$) entonces se puede garantizar que la soluci√≥n a encontrar ser√° √≥ptima y la heur√≠stica se dice <strong>admisible</strong>. En caso contrario, no hay garant√≠as. Sin embargo, en la mayor√≠a de los casos en la pr√°ctica, un √≥ptimo local es suficiente y si $h$ ayuda a reducir el espacio de b√∫squeda entonces no es necesaria la admisibilidad.</p>
<p>Finalmente, cabe destacar que la heur√≠stica trivial $h(s) = 0$ es admisible, pero no entrega informaci√≥n, por lo que es equivalente a hacer b√∫squeda no informada. En general, m√°s cerca se encuentre $h$ de $f$, mayor es la cantidad de soluciones a descartar.</p>
<h2 id="definiendo-una-heurstica-admisible-para-el-problema-del-puzzle-de-8-piezas">Definiendo una heur√≠stica admisible para el problema del puzzle de 8 piezas</h2>
<p>Una estrategia para definir heur√≠sticas admisibles es ‚Äúrelajar‚Äù las restricciones del problema. Por ejemplo, en el caso del puzzle podemos considerar tomar cada pieza y ponerla en el lugar que le corresponda. En este caso, la heur√≠stica ser√≠a ‚Äún√∫mero de piezas fuera de lugar‚Äù, que ser√≠a equivalente a calcular la distancia Hamming. Otra heur√≠stica, podr√≠a ser deslizar las piezas por encima de las otras, en este caso la distancia ser√≠a el n√∫mero de ‚Äúdeslizamientos de cada pieza‚Äù, esta se conoce como distancia Manhattan, ya que dada una posici√≥n objetivo $(i_o, j_o)$ y una posici√≥n inicial $(i_i, j_i)$, entonces la distancia ser√≠a: $|i_o - i_i| + |j_o - j_i|$.</p>
<p>En este caso, la distancia Manhattan es una mejor Heur√≠stica que la distancia Hamming debido a que el costo estimado est√° m√°s cerca al costo real de la soluci√≥n, lo que permite podar m√°s el espacio de b√∫squeda. Asumiendo que tenemos una clase <code>State</code> que representa el estado del puzzle, una posible definici√≥n para la distancia Manhattan:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">manhattan_distance</span><span class="p">(</span><span class="n">s1</span><span class="p">:</span> <span class="n">State</span><span class="p">,</span> <span class="n">s2</span><span class="p">:</span> <span class="n">State</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="s">"""Manhattan distance heuristic.

    Given s1 and s2, return the Manhattan distance between them.
    In this case if i1, j1 are coordinates of s1 and i2, j2 are
    coordinates of s2, the manhattan distance is computed by
    `abs(i1 - i2) + abs(j1 - j2)`.
    """</span>
    <span class="n">distance</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">s1</span><span class="p">.</span><span class="n">puzzle</span><span class="p">.</span><span class="n">board</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">tile</span> <span class="ow">in</span> <span class="n">row</span><span class="p">:</span>
            <span class="n">i1</span><span class="p">,</span> <span class="n">j1</span> <span class="o">=</span> <span class="n">s1</span><span class="p">.</span><span class="n">puzzle</span><span class="p">.</span><span class="n">tile_pos</span><span class="p">[</span><span class="n">tile</span><span class="p">]</span>
            <span class="n">i2</span><span class="p">,</span> <span class="n">j2</span> <span class="o">=</span> <span class="n">s2</span><span class="p">.</span><span class="n">puzzle</span><span class="p">.</span><span class="n">tile_pos</span><span class="p">[</span><span class="n">tile</span><span class="p">]</span>
            <span class="n">distance</span> <span class="o">+=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">i1</span> <span class="o">-</span> <span class="n">i2</span><span class="p">)</span> <span class="o">+</span> <span class="nb">abs</span><span class="p">(</span><span class="n">j1</span> <span class="o">-</span> <span class="n">j2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">distance</span>
</code></pre></div></div>
<p>Y el algoritmo <code>A*</code> se ver√≠a como:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">a_star_puzzle</span><span class="p">(</span><span class="n">init_state</span><span class="p">,</span> <span class="n">goal_state</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Direction</span><span class="p">]:</span>
    <span class="s">"""A* search algorithm for the 8-puzzle problem.

    In theory it supports any size of the board,
    but in practice it only works for 3x3 boards. The reason
    being that the search space increases exponentially with the size
    of the board.
    """</span>
    <span class="n">queue</span> <span class="o">=</span> <span class="n">PriorityQueue</span><span class="p">()</span>
    <span class="n">queue</span><span class="p">.</span><span class="n">push</span><span class="p">(</span>
        <span class="n">init_state</span><span class="p">,</span> <span class="n">manhattan_distance</span><span class="p">(</span><span class="n">init_state</span><span class="p">,</span> <span class="n">goal_state</span><span class="p">)</span> <span class="o">+</span> <span class="n">init_state</span><span class="p">.</span><span class="n">depth</span>
    <span class="p">)</span>
    <span class="n">visited</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">plan</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Direction</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">queue</span><span class="p">.</span><span class="n">isEmpty</span><span class="p">():</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">queue</span><span class="p">.</span><span class="n">pop</span><span class="p">()</span>
        <span class="n">visited</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">state</span> <span class="o">==</span> <span class="n">goal_state</span><span class="p">:</span>
            <span class="k">while</span> <span class="n">state</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">state</span><span class="p">.</span><span class="n">action</span><span class="p">:</span>
                    <span class="n">plan</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">state</span><span class="p">.</span><span class="n">action</span><span class="p">)</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="n">parent</span>
            <span class="k">break</span>
        <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">state</span><span class="p">.</span><span class="n">neighbors</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">neighbor</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
                <span class="n">queue</span><span class="p">.</span><span class="n">push</span><span class="p">(</span>
                    <span class="n">neighbor</span><span class="p">,</span> <span class="n">manhattan_distance</span><span class="p">(</span><span class="n">neighbor</span><span class="p">,</span> <span class="n">goal_state</span><span class="p">)</span> <span class="o">+</span> <span class="n">neighbor</span><span class="p">.</span><span class="n">depth</span>
                <span class="p">)</span>
    <span class="k">return</span> <span class="n">plan</span>
</code></pre></div></div>
<p>La cola de prioridades o <em>Priority Queue</em> es una estructura de datos que en base a una funci√≥n de costo, permite obtener elementos de forma ordenada haciendo orden en las inserciones de forma eficiente. Esta estructura de datos est√° basada en un <a href="https://en.wikipedia.org/wiki/Binary_heap">Binary Heap</a>.</p>
<p>El plan de pasos para llegar a la soluci√≥n dado el estado inicial de ejemplo en la figura 2, se muestra a continuaci√≥n:</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/1c42887ede70e37523fb601075a0e8cbf2d8a892/8puzzle-sol.gif" alt="puzzle-sol" /></p>
<p><em>Fig 4: Soluci√≥n y pasos para ejemplo del puzzle de las 8 piezas.</em></p>
</div>
<h2 id="buscando-soluciones-para-puzzles-ms-grandes">Buscando soluciones para puzzles m√°s grandes</h2>
<p>Hasta ac√° todo bien, ¬øcu√°l es el problema? Al crecer $N$ el espacio de b√∫squeda crece en √≥rdenes de magnitudes. Por ejemplo el puzzle de las 8 piezas tiene $9! / 2 = 181440$ estados alcanzables. El puzzle de las 15 piezas tiene 1.3 trilliones de estados posibles, el puzzle de las 24 piezas ($5 \times 5$) tiene $10^25$ estados posibles‚Ä¶</p>
<p>Si no nos importa esperar unas cuantas horas, o cientos de a√±os para encontrar una soluci√≥n, entonces no hay problema (y eso, asumiendo que se tiene la RAM disponible para hacerlo). En caso contrario, hay que buscar otro tipo de soluciones, aunque sean sub-√≥ptimas. En algunos casos <em>tener una soluci√≥n es mejor que no tener ninguna</em>.</p>
<p>En estos casos, se puede aplicar el principio de <em>Divide y vencer√°s</em>, en el cual un problema se puede descomponer en sub-problemas, y la soluci√≥n de estos problemas se puede agregar de manera tal de resolver el problema inicial. El paper <a href="https://ianparberry.com/pubs/saml.pdf">A Real-Time Algorithm for the $(n^2 ‚àí 1)$-Puzzle</a> implementa un enfoque como el descrito. El algortimo es simple:</p>
<ol>
<li><strong>Procedimiento</strong> $\text{Resolver Puzzle}(n)$
<ol>
<li>Si $n = 3$ resolver por fuerza bruta
<ul>
<li>En caso contrario usar algoritmo voraz para poner las filas y columnas en su posici√≥n correcta</li>
</ul>
</li>
<li>$\text{Resolver Puzzle}(n - 1)$</li>
</ol>
</li>
</ol>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/649b07262fc51591de77f06b4c2aa561fe317496/greedy-n8-1.png" alt="puzzle-greedy-1" /></p>
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/649b07262fc51591de77f06b4c2aa561fe317496/greedy-n8-2.png" alt="puzzle-greedy-2" /></p>
<p><em>Fig 5: Muestra del algoritmo voraz para poner las filas y columnas en su lugar.</em></p>
</div>
<p>Esto se hace recursivamente hasta llegar al punto en que $n = 3$. Luego, aplicamos el algoritmo <code>A*</code> y resolvemos el resto del puzzle.</p>
<h2 id="repositorio-github">Repositorio GitHub</h2>
<p>El c√≥digo completo lo dejo en este repositorio github: <a href="https://github.com/dpalmasan/n2_1_puzzle">N^2 Puzzle Solver</a>.</p>
<h1 id="reflexiones-finales">Reflexiones Finales</h1>
<ul>
<li>Plantear un problema de b√∫squeda no es complicado, pero encontrar una soluci√≥n lo es. Encontrar una soluci√≥n √≥ptima lo es mucho m√°s, a veces imposible o impr√°ctico.</li>
<li>Una heur√≠stica es una aproximaci√≥n de una funci√≥n desconocida, que puede utilizarse para realizar <strong>b√∫squeda informada</strong> y de esta forma reducir el espacio de b√∫squeda</li>
<li>Resolvimos en problema del $N^2 - 1$ puzzle de manera sub-√≥ptima para $n &gt; 3$ y √≥ptima en el caso de $n = 3$.</li>
</ul>
<p>Como nota aparte, en su tiempo tom√© aproximadamente 60 <em>MOOCs</em> (<em>Massive Open Online Courses</em>); m√°s que todos los cursos que tom√© en ingenier√≠a‚Ä¶ Si me preguntan cu√°les fueron mis favoritos:</p>
<ol>
<li><a href="https://www.edx.org/learn/computer-science/harvard-university-cs50-s-introduction-to-computer-science">CS50‚Äôs Introduction to Computer Science</a></li>
<li><a href="https://work.caltech.edu/telecourse.html">Learning from Data</a></li>
<li><a href="https://www.edx.org/learn/magnetism/rice-university-electricity-and-magnetism-part-1">Electricity and Magnetism</a></li>
<li><a href="https://online.princeton.edu/algorithms-part-i">Algorithms Part 1</a></li>
</ol>
<p>No soy mucho de estudiar algo directamente como por ejemplo frameworks, etc‚Ä¶ prefiero los libros MIL veces para entender los fundamentos y leer la documentaci√≥n y papers para entender el uso. Por ello, no me gustan las plataformas como platzi, Udemy, etc‚Ä¶ Me gusta mucho m√°s la teor√≠a abierta y a veces la que al parecer no tiene mucho uso, hasta que realmente te toca resolver un problema que hay que pensar.</p>]]></content><author><name>dpalmasan</name></author><category term="algorithms" /><category term="ai" /><summary type="html"><![CDATA[Introducci√≥n Era el a√±o 2014, y me hab√≠a titulado de ingenier√≠a civil el√©ctrica en la Universidad de Concepci√≥n (¬°grande mi alma mater!). Tambi√©n estaba en conflicto pues ven√≠a saliendo de una pr√°ctica profesional que no me gust√≥ para nada (√°rea de mantenci√≥n de una planta papelera). No fue una buena experiencia y estaba dudando si era eso a lo que quer√≠a dedicarme en mi vida profesional. Por otro lado, siempre me gustaron las clases te√≥ricas en ingenier√≠a, las simulaciones y meter algo de c√≥digo; debo confesar que mi √∫nica experiencia programando fue un curso de un semestre en el lenguaje C, y el resto MATLAB. En ese mismo a√±o alguien publica en facebook que dar√°n un curso ‚Äúgratis‚Äù de electromagnetismo en la plataforma edX (que yo desconoc√≠a), as√≠ que me inscrib√≠; lamentablemente dicho curso ya no est√° disponible, era el curso 8.02x - MIT Physics II: Electricity and Magnetism (pero si no saben la historia funaron al profesor Walter Lewin; por lo que el curso ya no est√° dispnible en edX; hay que reconocer que las clases eran espectaculares). Debo decir que disfrut√© bastante el curso y hasta me un√≠ a grupos de facebook y participaba activamente en los foros de edX ayudando y respondiendo dudas de los problemas; ¬øqu√© pas√≥? Me volv√≠ adicto a los cursos en l√≠nea y me puse a tomar varios cursos (m√°s relacionados a la ingenier√≠a el√©ctrica). Luego, gracias a una de las personas que estaba en uno de esos cursos de f√≠sica donde yo participaba, encontr√© el m√≠tico curso CS50x: Introduction to Computer Science de Harvard. Fue dicho curso en donde aprend√≠ lo introductorio de las Ciencias de la Computaci√≥n y varios temas de programaci√≥n (en especial en C) que desconoc√≠a. Con mi ‚Äúexperiencia‚Äù programando, no pens√© que ser√≠a un curso desafiante, pero lo fue. Lo interesante es que cada tarea, ten√≠a dos versiones: La tarea para aprobar y la versi√≥n ‚Äúhacker‚Äù. Yo logr√© resolver las versiones ‚Äúhacker‚Äù de todos los problemas, excepto de uno: The game of fifteen. No entrar√© en detalles, pero en esencia es un puzzle, la tarea era implementar el puzzle como un juego de terminal y la versi√≥n hacker era implementar un comando ‚ÄúGOD‚Äù que resolviera el puzzle de forma autom√°tica. Este post es mi redenci√≥n e intento de soluci√≥n de este problema. TL;DR El repositorio github del c√≥digo: N^2 Puzzle Solver ¬ø$N^2 - 1$ Puzzle? El puzzle de $N^2 - 1$ es una grilla de $N\times N$ que consiste en $N^2 - 1$ piezas que deben moverse a una configuraci√≥n objetivo, que consiste en tener todas las piezas ordenadas de forma ascendente, como se muestra en la figura 1. Fig 1: Ejemplo de puzzle de 8-piezas y su configuraci√≥n objetivo. Para mover las piezas, hay una restricci√≥n, estas deben deslizarse, por ello es que la grilla tiene un espacio libre como se muestra en la figura. Cabe destacar que no todas las configuraciones posibles tienen soluci√≥n (no vamos a demostrar esto hoy jeje), por lo tanto, para lo que sigue del art√≠culo, asumiremos que existe soluci√≥n para la configuraci√≥n inicial. ¬øC√≥mo buscar una soluci√≥n? Pensando que cada puzzle representa un estado, entonces al realizar cualquier acci√≥n habr√° un cambio de estado. Considerando m√∫ltiples posibles acciones, constru√≠mos lo que es un espacio de estados que se muestra en la figura 2. Fig 2: Ejemplo de espacio de estados para puzzle de 8-piezas dada una configuraci√≥n inicial. Y aqu√≠ viene la gran pregunta de todo problema de inteligencia artificial ¬øC√≥mo explorar el espacio de estados para encontrar una soluci√≥n? ¬øC√≥mo encontrar la ‚Äúmejor‚Äù soluci√≥n? Existen varios algoritmos de b√∫squeda, y para no alargar tanto este art√≠culo, prefiero no mencionar todos. Sin embargo, para tener una intuici√≥n, consideremos el problema de encontrar el camino menos costoso entre una ciudad y otra. Problemas de B√∫squeda En la figura 3, se muestra un diagrama de las ciudades A, B, C, D, E, F, G, H. Cada flecha indica la conexi√≥n entre las ciudades el valor en la flecha indica el costo de viajar entre dos ciudades. Si qusieramos encontrar el camino menos costoso entre A y H, tenemos que usar dicho costo para realizar la b√∫squeda. Fig 3: Ejemplo de camino menos costoso entre ciudades. Comencemos: Estoy en la ciudad A, puedo hacer (A-&gt;B, 1), (A-&gt;C, 3), (A-&gt;E, 3) Me cuesta menos el primer camino, luego puedo hacer (A-&gt;B-&gt;C, 2), (A-&gt;B-&gt;H, 15) (A-&gt;C, 3), (A-&gt;E, 3) Ahora podr√≠a elegir (A-&gt;B-&gt;C, 2), luego tengo las opciones: (A-&gt;B-&gt;C-&gt;D, 8), (A-&gt;B-&gt;H, 15) (A-&gt;C, 3), (A-&gt;E, 3) Ahora elijo (A-&gt;C, 3), luego: (A-&gt;C-&gt;D, 9), (A-&gt;B-&gt;C-&gt;D, 8), (A-&gt;B-&gt;H, 15), (A-&gt;E, 3) Ahora elijo (A-&gt;E, 3), luego: (A-&gt;E-&gt;F, 4), (A-&gt;C-&gt;D, 9), (A-&gt;B-&gt;C-&gt;D, 8), (A-&gt;B-&gt;H, 15) Elijo (A-&gt;E-&gt;F, 4), luego: (A-&gt;E-&gt;F-&gt;G, 5), (A-&gt;C-&gt;D, 9), (A-&gt;B-&gt;C-&gt;D, 8), (A-&gt;B-&gt;H, 15) Elijo (A-&gt;E-&gt;F-&gt;G, 5), luego: (A-&gt;E-&gt;F-&gt;G-&gt;H, 6), (A-&gt;C-&gt;D, 9), (A-&gt;B-&gt;C-&gt;D, 8), (A-&gt;B-&gt;H, 15) Finalmente llegu√© a H con el recorriendo el siguiente camino: A-&gt;E-&gt;F-&gt;G-&gt;H. Que es el menos costoso, cuyo coste es 6. Como podemos observar, este es un enfoque completamente automatizable. De hecho, el algoritmo que acabamos de hacer se conoce como b√∫squeda de costo uniforme. Como se pudo observar, esta b√∫squeda fue no informada, ya que reaccionabamos al costo de las acciones y s√≥lo utilizamos informaci√≥n vista (pasada). ¬øQu√© pasar√≠a si tuviesemos informaci√≥n adicional? Por ejemplo ¬øQu√© pasar√≠a si supieramos exactamente cu√°nto falta para llegar al destino? Supongamos que existe una funci√≥n $f$, tal que $f(s) = n$, donde $s$ es una ciudad y $n$ es el costo m√≠nimo que existe desde $s$ hasta H. Por ejemplo si $s = \text{B}$ entonces f(B) = 15. Intentemos nuevamente el algoritmo, con esta informaci√≥n: Estoy en la ciudad A, puedo hacer (A-&gt;B, 1 + 15), (A-&gt;C, 3 + 14), (A-&gt;E, 3 + 3) Tomo (A-&gt;E, 3), puedo hacer: (A-&gt;B, 1 + 15), (A-&gt;C, 3 + 14), (A-&gt;E-&gt;F, 4 + 2) Tomo (A-E-&gt;F, 4), puedo hacer: (A-&gt;B, 1 + 15), (A-&gt;C, 3 + 14), (A-&gt;E-&gt;F-&gt;G, 5 + 1) Tomo (A-&gt;E-&gt;F-&gt;G, 5) puedo hacer: (A-&gt;B, 1 + 15), (A-&gt;C, 3 + 14), (A-&gt;E-&gt;F-&gt;G-&gt;H, 5) Llego a H tomando (A-&gt;E-&gt;F-&gt;G-&gt;H, 6), camino menos costoso: 6. La diferencia, es que teniendo informaci√≥n pude descartar soluciones y reducir el espacio de b√∫squeda. Este algoritmo se conoce como A* (o A estrella). Ahora, generalmente no conocemos esta funci√≥n $f$. Generalmente, podemos tener una aproximaci√≥n $h$. Si dicha aproximaci√≥n es tal que $h$ nunca sobre-estima $f$ (es decir, $h(s) \leq f(s)$) entonces se puede garantizar que la soluci√≥n a encontrar ser√° √≥ptima y la heur√≠stica se dice admisible. En caso contrario, no hay garant√≠as. Sin embargo, en la mayor√≠a de los casos en la pr√°ctica, un √≥ptimo local es suficiente y si $h$ ayuda a reducir el espacio de b√∫squeda entonces no es necesaria la admisibilidad. Finalmente, cabe destacar que la heur√≠stica trivial $h(s) = 0$ es admisible, pero no entrega informaci√≥n, por lo que es equivalente a hacer b√∫squeda no informada. En general, m√°s cerca se encuentre $h$ de $f$, mayor es la cantidad de soluciones a descartar. Definiendo una heur√≠stica admisible para el problema del puzzle de 8 piezas Una estrategia para definir heur√≠sticas admisibles es ‚Äúrelajar‚Äù las restricciones del problema. Por ejemplo, en el caso del puzzle podemos considerar tomar cada pieza y ponerla en el lugar que le corresponda. En este caso, la heur√≠stica ser√≠a ‚Äún√∫mero de piezas fuera de lugar‚Äù, que ser√≠a equivalente a calcular la distancia Hamming. Otra heur√≠stica, podr√≠a ser deslizar las piezas por encima de las otras, en este caso la distancia ser√≠a el n√∫mero de ‚Äúdeslizamientos de cada pieza‚Äù, esta se conoce como distancia Manhattan, ya que dada una posici√≥n objetivo $(i_o, j_o)$ y una posici√≥n inicial $(i_i, j_i)$, entonces la distancia ser√≠a: $|i_o - i_i| + |j_o - j_i|$. En este caso, la distancia Manhattan es una mejor Heur√≠stica que la distancia Hamming debido a que el costo estimado est√° m√°s cerca al costo real de la soluci√≥n, lo que permite podar m√°s el espacio de b√∫squeda. Asumiendo que tenemos una clase State que representa el estado del puzzle, una posible definici√≥n para la distancia Manhattan: def manhattan_distance(s1: State, s2: State) -&gt; int: """Manhattan distance heuristic.]]></summary></entry><entry><title type="html">Inteligencia Artificial: Agentes y Conceptos B√°sicos</title><link href="https://dpalmasan.github.io/website/algorithms/ai/2024/06/20/agents-ai.html" rel="alternate" type="text/html" title="Inteligencia Artificial: Agentes y Conceptos B√°sicos" /><published>2024-06-20T23:22:00+00:00</published><updated>2024-06-20T23:22:00+00:00</updated><id>https://dpalmasan.github.io/website/algorithms/ai/2024/06/20/agents-ai</id><content type="html" xml:base="https://dpalmasan.github.io/website/algorithms/ai/2024/06/20/agents-ai.html"><![CDATA[<h1 id="introduccin">Introducci√≥n</h1>
<p>En estos momentos estoy en Suvarnabhumi Airport, en Bangkok, en el Sakura Lounge de Japan Airlines, esperando para tomar mi vuelo de vuelta a Seattle. ¬°Rayos! Las vacaciones pasan r√°pido. El art√≠culo de hoy ser√° sobre conceptos b√°sicos de inteligencia artificial, en particular ‚Äúagentes‚Äù, ya este t√©rmino est√° empezando a sonar bastante con la tendencia de utilizar LLMs en la actualidad. Mi art√≠culo, sin embargo, ser√° un poco m√°s simple e intentar√° introducir el concepto de manera intuitiva.</p>
<h1 id="conceptos-de-ia">Conceptos de IA</h1>
<p>Definir qu√© es la inteligencia artificial puede ser pol√©mico, por lo que no dar√© una definici√≥n directamente en esta ocasi√≥n. El libro de Peter Norvig Artificial Intelligence: A modern approach tiene un cap√≠tulo introductorio fascinante. El nombre de Inteligencia Artificial para este campo de estudio, fue dado en 1956, aunque anteriormente hubo investigaciones ligadas a lo que desde entonces se conoce como Inteligencia Artificial. Es m√°s, √©ste campo multidisciplinario toma conocimiento y teor√≠a de: filosof√≠a, lenguaje, psicolog√≠a, neurociencia, econom√≠a, etc (en teor√≠a podr√≠amos estar hablando que la teor√≠a asociada existe desde la √©poca de Arist√≥teles).</p>
<p>El nombre de IA ha perdurado en el tiempo, pero lo que estudia se asemeja con la racionalidad computacional. La raz√≥n de ello, es que en t√©rminos de ‚Äúinteligencia‚Äù, la inteligencia artificial considera agentes que toman decisiones de forma racional, idealmente, toma la mejor decisi√≥n dada una situaci√≥n.</p>
<h2 id="agentes-en-ia">Agentes en IA</h2>
<p>Primero deber√≠amos definir qu√© es un agente, para luego definir qu√© es un agente inteligente. Un agente, es cualquier ente que pueda percibir su entorno a trav√©s de sensores y ejecutar acciones dentro del entorno mediante actuadores, tal como muestra la figura 1. La caja con el signo de interrogaci√≥n, es qu√© razonamiento/inteligencia se le provee al agente para que tome acciones dada una percepci√≥n del entorno.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/e3206b8dbdc29f3a687960a72cdd682d5c6339a8/agents-act.png" alt="agent" /></p>
<p><em>Fig 1: Interacci√≥n entre agente y entorno en alto nivel.</em></p>
</div>
<p>Cabe destacar que esta noci√≥n de agente es una herramienta para analizar sistemas, no es una caracterizaci√≥n que define qu√© es y qu√© no es un agente.</p>
<h2 id="agente-racional">Agente Racional</h2>
<p>Ahora que definimos un agente, hay que definir qu√© es un agente racional. Un agente racional es un agente que toma la acci√≥n correcta, algunos ejemplos: El controlador de aire acondicionado, esperar√≠amos que manejara la temperatura acorde a la temperatura configurada (aunque en mi experiencia personal, esto a veces no resulta jeje); una aspiradora roomba, esperar√≠amos que limpiara satisfactoriamente una habitaci√≥n dada.</p>
<p>Pero, desde el punto de vista de IA ¬øQu√© podr√≠a definirse como racionalidad? En realidad, lo que es racional depende de cuatro factores:</p>
<ul>
<li>La m√©trica de rendimiento que define un criterio de √©xito.</li>
<li>El conocimiento previo del agente respecto al entorno donde opera.</li>
<li>Las acciones que el agente puede tomar</li>
<li>Las percepciones del agente en un momento dado.</li>
</ul>
<h2 id="omnipotencia">¬øOmnipotencia?</h2>
<p>Aqu√≠ tambi√©n hay que hacer una diferencia entre lo racional y el rendimiento perfecto. Esto es, porque en general, el agente no tiene conocimiento del resultado real de sus acciones, s√≥lo tiene conocimiento del resultado esperado. Si el agente fuese omnipotente (cosa imposible en la pr√°ctica), podr√≠a maximizar la m√©trica de rendimiento real, sin embargo, un agente racional busca maximizar la m√©trica de rendimiento esperada (dado a lo que el agente espera de los resultados de sus acciones). Por ejemplo, si me env√≠an un correo diciendo que gan√© un mill√≥n de d√≥lares, y en efecto no era spam, sin embargo el agente clasificador de correos lo clasific√≥ como SPAM, por lo tanto yo decid√≠ que era SPAM, pero en la realidad no era SPAM, es algo fortuito, que el agente no pudo haber esperado. Otro ejemplo, si no viene ning√∫n auto, el sem√°foro marca verde, cruzo la calle y me cae la turbina de un avi√≥n, no puedo decir que no es racional cruzar en verde; es simplemente mala suerte. Otro ejemplo m√°s actual que se me ocurre, mi instinto ar√°cnido me dice que muchos ‚Äúmodelos predictivos‚Äù de algunas empresas no ten√≠an contemplado el COVID-19.</p>
<p>Algunas propiedades de los entornos en que un agente operar√° son:</p>
<ul>
<li>Completamente observable / parcialmente observable (¬øTengo conocimiento total del mundo o s√≥lo parcial?)</li>
<li>Determin√≠stico / Estoc√°stico (¬øEl estado siguiente se determina completamente del estado actual?)</li>
<li>Epis√≥dico / secuencial (¬ødepende mi acci√≥n siguiente de mi acci√≥n previa?)</li>
<li>Est√°tico / Din√°mico</li>
<li>Discreto / Continuo</li>
<li>Un s√≥lo agente / Multiagente</li>
</ul>
<h1 id="inteligencia-en-ia">‚ÄúInteligencia‚Äù en IA</h1>
<p>Los tipos de inteligencia en IA se pueden clasificar de acuerdo al razonamiento que hacen sobre el entorno/mundo, como se muestra en la figura 2.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/c4d047d9403beada33098cf7e74d3d2a561e2964/line-intelligence.png" alt="intel" /></p>
<p><em>Fig 2: Distintos niveles de ‚Äúinteligencia‚Äù de un agente. <a href="https://stanford-cs221.github.io/spring2020/lectures/index.html#include=overview.js&amp;mode=print1pp">Fuente</a>.</em></p>
</div>
<h2 id="agentes-por-reflejo">Agentes por Reflejo</h2>
<p>En este tipo de inteligencia, se encuentran agentes que act√∫an por reflejo. Consideremos un caso hip√≥tetico de un gato robot, llam√©mosle <em>RoboCat</em>. A este gato artificial le gusta jugar a seguir un punto generado por un puntero laser.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">LaserDot</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_pos</span> <span class="o">=</span> <span class="n">pos</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">pos</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_pos</span>

    <span class="k">def</span> <span class="nf">randomize_pos</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_pos</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">RoboCat</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_next_action</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_pos</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">pos</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_pos</span>

    <span class="k">def</span> <span class="nf">perceive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">laser_dot</span><span class="p">:</span> <span class="n">LaserDot</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_next_action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sign</span><span class="p">(</span><span class="n">laser_dot</span><span class="p">.</span><span class="n">pos</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">_pos</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">action</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_pos</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_next_action</span>
</code></pre></div></div>
<p>Si hacemos una simulaci√≥n simple, por ejemplo en 100 episodios:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dot</span> <span class="o">=</span> <span class="n">LaserDot</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cat</span> <span class="o">=</span> <span class="n">RoboCat</span><span class="p">()</span>
<span class="n">dot_pos</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span>
<span class="n">cat_pos</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">cat</span><span class="p">.</span><span class="n">perceive</span><span class="p">(</span><span class="n">dot</span><span class="p">)</span>
    <span class="n">cat</span><span class="p">.</span><span class="n">action</span><span class="p">()</span>
    <span class="n">dot_pos</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">dot</span><span class="p">.</span><span class="n">pos</span><span class="p">)</span>
    <span class="n">cat_pos</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cat</span><span class="p">.</span><span class="n">pos</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cat</span><span class="p">.</span><span class="n">pos</span> <span class="o">==</span> <span class="n">dot</span><span class="p">.</span><span class="n">pos</span><span class="p">:</span>
        <span class="n">dot</span><span class="p">.</span><span class="n">randomize_pos</span><span class="p">()</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/6b79839da0b7e7eb6faa893d1a80d5d6dea0dfda/cat-laser.png" alt="intel" /></p>
<p><em>Fig 3: Agente reactivo ejemplo de RoboCat siguiendo un puntero laser.</em></p>
</div>
<p>En la figura 3 se muestra una simulaci√≥n en 100 episodios del gato robot siguiendo un puntero. El puntero cambia de posici√≥n aleatoriamente una vez el gato est√° en la misma posici√≥n que el puntero. Cuando el gato robot percive que el puntero est√° en otra posici√≥n intenta minimizar la distancia entre su posici√≥n y la posici√≥n del puntero.</p>
<p>En la figura 4 se muestra el controlador en alto nivel de un estanque, donde la variable controlada es la altura del estanque. En este caso, el agente tiene como referencia una altura deseada, y va sensando la altura del estanque en cada instante de tiempo. Si la altura es diferente de la deseada, el controlador la variar√° para acercarse a la altura deseada.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/fbf482cd323764f47494ab5243cce7ffeac94ca2/estanque.png" alt="intel" /></p>
<p><em>Fig 4: Ejemplo de un controlador de un estanque.</em></p>
</div>
<p>En general este tipo de inteligencia funciona muy bien para problemas donde se conocen los procesos (modelos matem√°ticos, f√≠sicos, etc), y donde el entorno no es tan cambiante.</p>
<h2 id="estados">Estados</h2>
<p>En este tipo de inteligencia, existe la noci√≥n de ‚Äúestados‚Äù, en donde el ‚Äúmundo‚Äù o ambiente en que vive el agente se representa por estados, y una acci√≥n del agente produce un cambio de estado (que puede determinista o no determinista). Luego, el agente razona sobre acciones futuras y cambios de estado y ejecuta una acci√≥n. Este proceso requiere una b√∫squeda en un espacio de estados, donde la soluci√≥n, es el camino (conjunto de acciones) que llevan desde un estado inicial hacia un estado objetivo. Cabe destacar, que un en esencia, todo problema puede ser planteado como un problema de b√∫squeda; Es m√°s, varios algoritmos requieren de alguna forma u otra, resolver problemas de b√∫squeda. Algunos ejemplos: ‚ÄúPath finding‚Äù, soluciones al puzzle de las N piezas, etc.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/37b5f28e91e17e8d9b82dc8680de3076a95e86bc/8-puzzle.png" alt="intel" /></p>
<p><em>Fig 5: Ejemplo de √°rbol de estados para el problema del 8-Puzzle</em></p>
</div>
<p>Un ejemplo cl√°sico de problema de b√∫squeda, es el puzzle de las <a href="https://en.wikipedia.org/wiki/15_puzzle">N-piezas</a> . Este ejemplo es generalmente mostrado en cursos de inteligencia artificial, para mostrar ejemplos de distintos algoritmos de b√∫squeda: Depth-First Search, Breadth first search, Iterative Deepening Search, Uniform Cost Search, A* Search, Iterative Deepening A* search, inserte cualquier otro algoritmo de b√∫squeda que tenga alguna optimizaci√≥n en memoria o en reducci√≥n del espacio de b√∫squeda. En la figura 5, se muestra como se va armando el √°rbol de b√∫squeda. Por otro lado, existen dos tipos de b√∫squeda, la b√∫squeda no informada y la informada. La b√∫squeda no informada es b√°sicamente hacer fuerza bruta y recorrer todo el √°rbol de b√∫squeda hasta encontrar la soluci√≥n (estado objetivo). Por otro lado, est√° la b√∫squeda informada, en la cual se proporciona informaci√≥n respecto a qu√© tan cerca (o lejos) el estado actual se encuentra del estado objetivo. Generalmente estas funciones son de la forma $h(s) = n$, donde $s$ es un estado y $n$ es una estimaci√≥n del costo que existe para ir del estado s al estado objetivo. Dependiendo de qu√© tan buena sea la heur√≠stica, se puede llegar m√°s r√°pido al estado objetivo (expandir menos nodos). En general existen dos propiedades deseables en las heur√≠sticas, admisibilidad y consistencia. La consistencia es s√≥lo importante si se explora el espacio de estados como una b√∫squeda en grafo (no repetir estados, manteniendo una agenda de estados visitados).</p>
<p>En el siguiente enlace pueden ver un demo de b√∫squeda por grafos para el puzzle de las 8 piezas: <a href="https://dpalmasan.github.io/blog-ia-dpalma/">Demo 8-puzzle A*</a></p>
<p>En general, para implementar estos algoritmos se requiere representar los estados, por ejemplo:</p>
<div class="language-ts highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">abstract</span> <span class="kd">class</span> <span class="nx">State</span> <span class="p">{</span>
    <span class="nl">prev</span><span class="p">:</span> <span class="nx">State</span>
    <span class="nx">action</span><span class="p">:</span> <span class="kr">string</span><span class="p">;</span>
    <span class="kd">constructor</span> <span class="p">(</span><span class="nx">prev</span><span class="p">:</span> <span class="nx">State</span><span class="p">,</span> <span class="nx">action</span><span class="p">:</span> <span class="kr">string</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">this</span><span class="p">.</span><span class="nx">prev</span> <span class="o">=</span> <span class="nx">prev</span><span class="p">;</span>
        <span class="k">this</span><span class="p">.</span><span class="nx">action</span> <span class="o">=</span> <span class="nx">action</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kd">abstract</span> <span class="nx">equals</span><span class="p">(</span><span class="nx">otherState</span><span class="p">:</span> <span class="nx">State</span><span class="p">):</span> <span class="nx">boolean</span><span class="p">;</span>
    <span class="kd">abstract</span> <span class="nx">hash</span><span class="p">():</span> <span class="kr">string</span><span class="p">;</span>
<span class="p">}</span>

<span class="kd">abstract</span> <span class="kd">class</span> <span class="nx">SearchProblem</span> <span class="p">{</span>
    <span class="kd">abstract</span> <span class="nx">getStartState</span><span class="p">()</span> <span class="p">:</span> <span class="nx">State</span><span class="p">;</span>
    <span class="kd">abstract</span> <span class="nx">isGoalState</span><span class="p">(</span><span class="nx">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">)</span> <span class="p">:</span> <span class="nx">boolean</span><span class="p">;</span>
    <span class="kd">abstract</span> <span class="nx">getSuccessors</span><span class="p">(</span><span class="nx">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">)</span> <span class="p">:</span> <span class="nx">State</span><span class="p">[];</span>
    <span class="kd">abstract</span> <span class="nx">getCostOfAction</span><span class="p">(</span><span class="nx">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">)</span> <span class="p">:</span> <span class="kr">number</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>
<p>El siguiente snippet muestra una implementaci√≥n simple del algoritmo A* para b√∫squeda en grafos:</p>
<div class="language-ts highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">function</span> <span class="nx">aStar</span><span class="p">(</span><span class="nx">problem</span><span class="p">:</span> <span class="nx">SearchProblem</span><span class="p">,</span> <span class="nx">heuristic</span><span class="p">:</span> <span class="p">(</span><span class="nx">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="kr">number</span> <span class="p">)</span> <span class="p">{</span>
    <span class="kd">let</span> <span class="nx">frontier</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">BinaryHeap</span><span class="o">&lt;</span><span class="nx">State</span><span class="o">&gt;</span><span class="p">(</span>
        <span class="p">(</span><span class="nx">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="nx">heuristic</span><span class="p">(</span><span class="nx">state</span><span class="p">)</span> <span class="o">+</span> <span class="nx">problem</span><span class="p">.</span><span class="nx">getCostOfAction</span><span class="p">(</span><span class="nx">state</span><span class="p">));</span>

    <span class="nx">frontier</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">problem</span><span class="p">.</span><span class="nx">getStartState</span><span class="p">());</span>
    <span class="kd">let</span> <span class="nx">explored</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">StateSet</span><span class="p">();</span>

    <span class="k">while</span> <span class="p">(</span><span class="nx">frontier</span><span class="p">.</span><span class="nx">size</span><span class="p">()</span> <span class="o">!==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="kd">let</span> <span class="nx">state</span><span class="p">:</span> <span class="nx">State</span> <span class="o">=</span> <span class="nx">frontier</span><span class="p">.</span><span class="nx">pop</span><span class="p">();</span>
        <span class="nx">explored</span><span class="p">.</span><span class="nx">add</span><span class="p">(</span><span class="nx">state</span><span class="p">);</span>

        <span class="k">if</span> <span class="p">(</span><span class="nx">problem</span><span class="p">.</span><span class="nx">isGoalState</span><span class="p">(</span><span class="nx">state</span><span class="p">))</span> <span class="p">{</span>
            <span class="kd">let</span> <span class="nx">curr</span><span class="p">:</span> <span class="nx">State</span> <span class="o">=</span> <span class="nx">state</span><span class="p">;</span>
            <span class="kd">let</span> <span class="nx">path</span> <span class="o">=</span> <span class="p">[];</span>
            <span class="k">while</span> <span class="p">(</span><span class="nx">curr</span><span class="p">.</span><span class="nx">prev</span> <span class="o">!==</span> <span class="kc">null</span><span class="p">)</span> <span class="p">{</span>
                <span class="nx">path</span><span class="p">.</span><span class="nx">unshift</span><span class="p">(</span><span class="nx">curr</span><span class="p">.</span><span class="nx">action</span><span class="p">);</span>
                <span class="nx">curr</span> <span class="o">=</span> <span class="nx">curr</span><span class="p">.</span><span class="nx">prev</span><span class="p">;</span>
            <span class="p">}</span>
            <span class="k">return</span> <span class="nx">path</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="kd">let</span> <span class="nx">neighbors</span><span class="p">:</span> <span class="nx">State</span><span class="p">[]</span> <span class="o">=</span> <span class="nx">problem</span><span class="p">.</span><span class="nx">getSuccessors</span><span class="p">(</span><span class="nx">state</span><span class="p">);</span>
        <span class="nx">neighbors</span><span class="p">.</span><span class="nx">forEach</span><span class="p">(</span> <span class="p">(</span><span class="nx">neighbor</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
            <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="nx">explored</span><span class="p">.</span><span class="nx">has</span><span class="p">(</span><span class="nx">neighbor</span><span class="p">))</span> <span class="p">{</span>
                <span class="nx">frontier</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">neighbor</span><span class="p">);</span>
            <span class="p">}</span>
        <span class="p">});</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="p">[];</span>
<span class="p">}</span>
</code></pre></div></div>
<p>Nota aparte: Para resolver instancias de puzzle m√°s grande, no es suficiente usar A* (ya que la RAM es limitada y el espacio de b√∫squeda crece exponencialmente). Para resolver instancias m√°s grandes del (N^2 - 1) puzzle, siempre se puede aplicar alg√∫n algoritmo, como en este paper (<a href="http://ianparberry.com/pubs/saml.pdf">Combinaci√≥n de algoritmo greedy + algoritmo de b√∫squeda</a>)</p>
<p>Solo por completitud, en el siguiente video hay una demo de algunos de los algoritmos de b√∫squeda cl√°sicos, para el problema de ‚Äúpath finding‚Äù, que probablemente hice hace mucho tiempo.</p>
<p><a href="https://www.youtube.com/watch?v=PMHBzSIFPPE"><img src="https://img.youtube.com/vi/PMHBzSIFPPE/0.jpg" alt="PathFinding" /></a></p>
<p>Otro ejemplo de problema de b√∫squeda (con teor√≠a de juegos aplicadas), es dise√±ar una IA que juegue el 2048 game. En el siguiente video se muestra un ejemplo (usa un algoritmo llamado MiniMax, basado en juegos ‚ÄúZero Sum‚Äù de teor√≠a de juegos), y el agente se pone en el peor caso (es decir siempre considera la peor situaci√≥n, lo que a veces lo lleva a hacer movidas muy conservadoras):</p>
<p><a href="https://www.youtube.com/watch?v=P1s3AyBB-j8"><img src="https://img.youtube.com/vi/P1s3AyBB-j8/0.jpg" alt="AdversarialSearch" /></a></p>
<h2 id="variables">Variables</h2>
<p>Este tipo de problemas utilizan representaciones un poco m√°s avanzadas del mundo y del entorno, en forma de variables. Algunos ejemplos: redes Bayesianas, problemas de satisfacci√≥n de restricciones, etc. (en teor√≠a Machine Learning estar√≠a un poco m√°s adelante en la ‚Äúl√≠nea de inteligencia‚Äù mostrada anteriormente).</p>
<p>Un ejemplo cl√°sico es resolver un Sudoku:</p>
<ol>
<li>No se pueden repetir n√∫meros en las filas.</li>
<li>No se pueden repetir n√∫meros en las columnas.</li>
<li>No se pueden repetir n√∫meros en cada cuadrado del sudoku.</li>
</ol>
<p>Si consideramos que cada celda del Sudoku es una variable, tenemos 9x9 variables. Por ejemplo si a cada fila le asignamos una letra y a cada columna un valor, podr√≠amos definir las variables como:</p>
<p>$$\{A, B, C, D, E, F, G, H, I\} \times \{1, 2, 3, 4, 5, 6, 7, 8, 9\}$$</p>
<p>En este caso, el dominio de cada variable ser√° el conjunto $\{1, 2, 3, 4, 5, 6, 7, 8, 9\}$ ya que cada celda puede tomar alguno de dichos valores.</p>
<p>En el siguiente c√≥digo, hay una humilde implementaci√≥n del <a href="https://github.com/dpalmasan/DiscreteOptimization/blob/master/Week2%20-%20Constraint%20Programming/ConstraintProgramming.py">algoritmo AC3 para problema de satisfacci√≥n de restricciones</a>.</p>
<p>Por ejemplo podemos representar el Sudoku como un problema de satisfacci√≥n de restricciones, siguiendo las restricciones descritas:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Sudoku</span><span class="p">(</span><span class="n">ConstraintProgrammingProblem</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sudoku</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_variables</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_domains</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_arcs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_constraints</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_unassigned_variables</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_alldifferent</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">rows</span> <span class="o">=</span> <span class="s">"ABCDEFGHI"</span>
        <span class="n">cols</span> <span class="o">=</span> <span class="s">"123456789"</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">_variables</span><span class="p">[</span><span class="n">row</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">None</span> <span class="k">if</span> <span class="n">sudoku</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s">"0"</span> <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="n">sudoku</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">_domains</span><span class="p">[</span><span class="n">row</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="k">if</span> <span class="n">sudoku</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s">"0"</span> <span class="k">else</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">sudoku</span><span class="p">[</span><span class="n">i</span><span class="p">])]</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">sudoku</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s">"0"</span><span class="p">:</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">_unassigned_variables</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span> <span class="o">+</span> <span class="n">col</span><span class="p">)</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
                <span class="n">tmp</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">j</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">j</span> <span class="o">!=</span> <span class="n">k</span><span class="p">:</span>
                        <span class="n">arc</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="n">k</span><span class="p">))</span>
                        <span class="k">if</span> <span class="n">arc</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_arcs</span><span class="p">:</span>
                            <span class="bp">self</span><span class="p">.</span><span class="n">_arcs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">arc</span><span class="p">)</span>
                            <span class="bp">self</span><span class="p">.</span><span class="n">_constraints</span><span class="p">[</span><span class="n">arc</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                                <span class="s">'variable["%s"] != variable["%s"]'</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="n">k</span><span class="p">)</span>
                            <span class="p">]</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">_alldifferent</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
                <span class="n">tmp</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">j</span> <span class="o">!=</span> <span class="n">k</span><span class="p">:</span>
                        <span class="n">arc</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">((</span><span class="n">j</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="n">i</span><span class="p">))</span>
                        <span class="k">if</span> <span class="n">arc</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_arcs</span><span class="p">:</span>
                            <span class="bp">self</span><span class="p">.</span><span class="n">_arcs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">arc</span><span class="p">)</span>
                            <span class="bp">self</span><span class="p">.</span><span class="n">_constraints</span><span class="p">[</span><span class="n">arc</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                                <span class="s">'variable["%s"] != variable["%s"]'</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>
                            <span class="p">]</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">_alldifferent</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">row</span> <span class="o">+</span> <span class="n">col</span>
                    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">3</span> <span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">3</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="mi">3</span> <span class="p">:</span> <span class="n">j</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">3</span><span class="p">]</span>
                <span class="p">]</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">_alldifferent</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">tmp</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">tmp</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">r</span> <span class="o">!=</span> <span class="n">c</span><span class="p">:</span>
                            <span class="n">arc</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">((</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
                            <span class="k">if</span> <span class="n">arc</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_arcs</span><span class="p">:</span>
                                <span class="bp">self</span><span class="p">.</span><span class="n">_arcs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">arc</span><span class="p">)</span>
                                <span class="bp">self</span><span class="p">.</span><span class="n">_constraints</span><span class="p">[</span><span class="n">arc</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                                    <span class="s">'variable["%s"] != variable["%s"]'</span> <span class="o">%</span> <span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
                                <span class="p">]</span>

    <span class="k">def</span> <span class="nf">arcs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_arcs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xi</span><span class="p">,</span> <span class="n">Xj</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_constraints</span><span class="p">[</span><span class="nb">frozenset</span><span class="p">((</span><span class="n">Xi</span><span class="p">,</span> <span class="n">Xj</span><span class="p">))]</span>

    <span class="k">def</span> <span class="nf">neighbors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">removable_neighbor</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">neighbors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">arc</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_arcs</span><span class="p">:</span>
            <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">arc</span>

            <span class="k">if</span> <span class="n">X1</span> <span class="o">==</span> <span class="n">X</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">removable_neighbor</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">removable_neighbor</span> <span class="o">!=</span> <span class="n">X2</span><span class="p">:</span>
                        <span class="n">neighbors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">neighbors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">X2</span> <span class="o">==</span> <span class="n">X</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">removable_neighbor</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">removable_neighbor</span> <span class="o">!=</span> <span class="n">X1</span><span class="p">:</span>
                        <span class="n">neighbors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">X1</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">neighbors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">X1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">neighbors</span>

    <span class="k">def</span> <span class="nf">domain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xi</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_domains</span><span class="p">[</span><span class="n">Xi</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">remove_from_domain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">Xi</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_domains</span><span class="p">[</span><span class="n">Xi</span><span class="p">].</span><span class="n">remove</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">unassigned_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_unassigned_variables</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">assign_variable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">remove</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="s">"""
        Asigna un valor a la variable X
        """</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_variables</span><span class="p">[</span><span class="n">X</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">if</span> <span class="n">remove</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">_unassigned_variables</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">check_consistency</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""
        Chequea que dada una asignaci√≥n de variables, todas las reglas del
        Sudoku se satisfacen
        """</span>
        <span class="k">for</span> <span class="n">variables</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_alldifferent</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">variables</span><span class="p">)):</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">variables</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">variables</span><span class="p">)):</span>
                    <span class="n">Y</span> <span class="o">=</span> <span class="n">variables</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="n">are_assigned</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">_variables</span><span class="p">[</span><span class="n">X</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span>
                        <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">_variables</span><span class="p">[</span><span class="n">Y</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="n">are_assigned</span> <span class="ow">and</span> <span class="bp">self</span><span class="p">.</span><span class="n">_variables</span><span class="p">[</span><span class="n">X</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="p">.</span><span class="n">_variables</span><span class="p">[</span><span class="n">Y</span><span class="p">]:</span>
                        <span class="k">return</span> <span class="bp">False</span>
        <span class="k">return</span> <span class="bp">True</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""
        Imprime en pantalla el Sudoku en su estado actual dadas las variables
        asignadas.
        """</span>
        <span class="n">s</span> <span class="o">=</span> <span class="s">""</span>
        <span class="n">line</span> <span class="o">=</span> <span class="s">"-------------------------------------</span><span class="se">\n</span><span class="s">"</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">line</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="s">"ABCDEFGHI"</span><span class="p">:</span>
            <span class="n">s</span> <span class="o">+=</span> <span class="s">"|"</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="s">"123456789"</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">_variables</span><span class="p">[</span><span class="n">row</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="n">s</span> <span class="o">+=</span> <span class="p">(</span><span class="s">"%3d"</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">_variables</span><span class="p">[</span><span class="n">row</span> <span class="o">+</span> <span class="n">col</span><span class="p">])</span> <span class="o">+</span> <span class="s">"|"</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">s</span> <span class="o">+=</span> <span class="p">(</span><span class="s">"%3s"</span> <span class="o">%</span> <span class="s">" "</span><span class="p">)</span> <span class="o">+</span> <span class="s">"|"</span>
            <span class="n">s</span> <span class="o">+=</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="n">line</span>

        <span class="k">return</span> <span class="n">s</span>
</code></pre></div></div>
<p>Y luego ejecutar el algoritmo <code>AC3</code>:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">example</span>  <span class="o">=</span> <span class="s">"000102900"</span>
<span class="n">example</span> <span class="o">+=</span> <span class="s">"000090301"</span>
<span class="n">example</span> <span class="o">+=</span> <span class="s">"000008006"</span>
<span class="n">example</span> <span class="o">+=</span> <span class="s">"000030000"</span>
<span class="n">example</span> <span class="o">+=</span> <span class="s">"062000000"</span>
<span class="n">example</span> <span class="o">+=</span> <span class="s">"079016000"</span>
<span class="n">example</span> <span class="o">+=</span> <span class="s">"008060007"</span>
<span class="n">example</span> <span class="o">+=</span> <span class="s">"004000190"</span>
<span class="n">example</span> <span class="o">+=</span> <span class="s">"000004020"</span>
<span class="n">cp</span> <span class="o">=</span> <span class="n">Sudoku</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">cp</span><span class="p">)</span>
<span class="n">AC3</span><span class="p">(</span><span class="n">cp</span><span class="p">)</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">backtracking_search</span><span class="p">(</span><span class="n">cp</span><span class="p">)</span>
<span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">sol</span><span class="p">:</span>
    <span class="n">cp</span><span class="p">.</span><span class="n">assign_variable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sol</span><span class="p">[</span><span class="n">X</span><span class="p">])</span>
</code></pre></div></div>
<p>Sudoku inicial:</p>
<pre><code>-------------------------------------
|   |   |   |  1|   |  2|  9|   |   |
-------------------------------------
|   |   |   |   |  9|   |  3|   |  1|
-------------------------------------
|   |   |   |   |   |  8|   |   |  6|
-------------------------------------
|   |   |   |   |  3|   |   |   |   |
-------------------------------------
|   |  6|  2|   |   |   |   |   |   |
-------------------------------------
|   |  7|  9|   |  1|  6|   |   |   |
-------------------------------------
|   |   |  8|   |  6|   |   |   |  7|
-------------------------------------
|   |   |  4|   |   |   |  1|  9|   |
-------------------------------------
|   |   |   |   |   |  4|   |  2|   |
-------------------------------------
</code></pre>
<p>Sudoku final:</p>
<pre><code>-------------------------------------
|  8|  3|  6|  1|  5|  2|  9|  7|  4|
-------------------------------------
|  2|  4|  5|  6|  9|  7|  3|  8|  1|
-------------------------------------
|  1|  9|  7|  3|  4|  8|  2|  5|  6|
-------------------------------------
|  4|  8|  1|  2|  3|  5|  7|  6|  9|
-------------------------------------
|  5|  6|  2|  4|  7|  9|  8|  1|  3|
-------------------------------------
|  3|  7|  9|  8|  1|  6|  5|  4|  2|
-------------------------------------
|  9|  2|  8|  5|  6|  1|  4|  3|  7|
-------------------------------------
|  6|  5|  4|  7|  2|  3|  1|  9|  8|
-------------------------------------
|  7|  1|  3|  9|  8|  4|  6|  2|  5|
-------------------------------------
</code></pre>
<p>En este caso, consideramos ninguna funci√≥n de costo a optimizar. Generalmente queremos minimizar/maximizar una funci√≥n y a la vez satisfacer las restricciones. Estos problemas de optimizaci√≥n son un mundo, y para que funcionen bien los algoritmos, el problema debe ser modelado de forma correcta, y algunas restricciones pueden podar el √°rbol de b√∫squeda (ej. dual de una restricci√≥n) de manera de hacer que encontrar una soluci√≥n sea factible (En el ejemplo del Sudoku, IA toma prestado conocimiento del campo de la optimizaci√≥n, para crear un agente ‚Äúinteligente‚Äù que resuelva sudokus).</p>
<h2 id="lgica">L√≥gica</h2>
<p>En este punto me extender√© un poco m√°s, ya que es un √°rea bastante interesante, adem√°s, implementar un agente l√≥gico es todo un desaf√≠o.</p>
<p>Los agentes l√≥gicos siguen una cadena de razonamiento en base a s√≠mbolos y representan el conocimiento en una base de conocimiento, de la que se obtienen inferencias en relaci√≥n a un determinado hecho. El cl√°sico ejemplo: Todo hombre es mortal; S√≥crates es Hombre; Por lo tanto S√≥crates es mortal. Este ejemplo sigue una cadena l√≥gica de razonamiento, la gran pregunta es c√≥mo representar este conocimiento de manera que autom√°ticamente un agente sea capaz de realizar inferencias y luego tomar acci√≥n. Para hacerlo m√°s entretenido, tomemos el cl√°sico ejemplo del mundo del Wumpus:</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/0b5be9b0cc96a1a00df1aa33c25a4df4309f59c0/wumpus-problem.png" alt="intel" /></p>
<p><em>Fig 6: Mundo del Wumpus.</em></p>
</div>
<p>De momento consideremos lo siguiente:</p>
<ul>
<li>El mundo es una grilla de 4x4</li>
<li>Los cuadrados adyacentes al Wumpus tienen hedor del wumpus y en los cuadrados adyacentes a los precipicios, se puede percibir una brisa.</li>
<li>Se puede percibir un brillo si en la habitaci√≥n se encuentra el oro (aqu√≠ es donde nuestro agente gana el juego)</li>
</ul>
<p>M√©tricas de rendimiento:</p>
<ul>
<li>Si el agente toma el oro +1000 puntos</li>
<li>Si el agente muere (se cae a un precipicio o es comido por el Wumpus) -1000 puntos</li>
<li>-1 punto por cada acci√≥n</li>
<li>El juego termina cuando el agente toma el oro o muere.</li>
</ul>
<p>Entorno:</p>
<ul>
<li>Grilla de 4x4</li>
<li>El agente empieza en la posici√≥n <code>[1, 1]</code></li>
<li>Las ubicaciones del Wumpus y del Oro se escogen aleatoriamente de una distribuci√≥n uniforme de todos los cuadrados excepto del <code>[1, 1]</code></li>
<li>Cada cuadrado (que no sea el <code>[1, 1]</code>) tiene una probabilidad de 0.2 de ser un precipicio.</li>
</ul>
<p>Actuadores:</p>
<ul>
<li>Girar izquierda, girar derecha, avanzar, recoger</li>
</ul>
<p>Sensores:</p>
<ul>
<li>Hedor, brisa, brillo</li>
</ul>
<p>Propiedades del mundo:</p>
<ul>
<li>Parcialmente observable</li>
<li>Est√°tico</li>
<li>Discreto</li>
<li>Un s√≥lo agente</li>
<li>Determinista</li>
<li>Secuencial</li>
</ul>
<p>Primero, debemos modelar la base de conocimiento que tendr√° el agente. Ello se puede lograr por ejemplo, con l√≥gica proposicional (aqu√≠ recuerdo las clases de √°lgebra de primer a√±o y me empiezan a hacer sentido). De hecho como ejemplo tomemos la figura mostrada anteriormente. De las reglas del mundo del Wumpus, el agente deber√≠a saber:</p>
<ul>
<li>$B_{11} \leftrightarrow \left( P_{12} \lor P_{21}\right)$</li>
<li>$\neg B_{11}$</li>
</ul>
<p>En mi biblioteca opensource <a href="https://github.com/dpalmasan/py-logic">PyLogic</a> implemento una API para l√≥gica proposicional y para cl√°usulas de Horn (sub-conjunto de la l√≥gica de primer orden).</p>
<p>Entonces, el agente, para decidir su siguiente acci√≥n, puede preguntarse: ¬øEs <code>[1, 2]</code> seguro, o $\neg P_{12}$? Consideremos la siguiente tabla de verdad:</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/0b5be9b0cc96a1a00df1aa33c25a4df4309f59c0/truth-table-wumpus.png" alt="intel" /></p>
<p><em>Fig 7: Tabla de verdad para ejemplo de consecuencia l√≥gica para determinar precipicio.</em></p>
</div>
<p>Como se ilustra en la tabla de verdad, en todo modelo en que la base de conocimiento es verdad (asignaci√≥n de variables l√≥gicas) se satisface que $\neg P_{12}$, es decir que $\neg P_{12}$ es una consecuencia l√≥gica de $\neg B_{11} \land \left(B_{11} \leftrightarrow \left(P_{12} \lor P_{21} \right)\right)$ , o, el hecho de que no haya brisa en la habitaci√≥n <code>[1, 1]</code>, significa que las habitaciones <code>[1, 2]</code>, <code>[2, 1]</code> son seguras (no hay precipicio). Ahora, podemos ver un inconveniente de hacer inferencias con tablas de verdad, y es que, crece exponencialmente con el n√∫mero de s√≠mbolos y el n√∫mero de cl√°usulas. Luego, para problemas no de juguete, no ser√≠a factible construir la tabla de verdad. Por otro lado vemos tambi√©n que al construir la tabla de verdad, entre medio se construyen muchas asignaciones innecesarias, por lo que debe haber alguna forma m√°s inteligente de llevar a cabo la ‚Äúb√∫squeda‚Äù de satisfacibilidad. Sin embargo, en esta b√∫squeda debemos tambi√©n considerar la correctitud y la completitud. Como dato extra, los problemas de satisfacibilidad Booleana son NP üòä.</p>
<p>Para automatizar un algoritmo de inferencia l√≥gica, es ideal que las cl√°usulas se puedan escribir de alguna forma can√≥nica. Por suerte, dicha forma existe y se conoce como Forma Normal Conjuntiva (del ingl√©s CNF, conjunctive normal form). De hecho, cualquier cl√°usula (por ahora en l√≥gica proposicional) se puede escribir como una conjunci√≥n de disyunciones. Tomemos como ejemplo la cl√°usula $\left(B_{11} \leftrightarrow \left(P_{12} \lor P_{21} \right)\right)$:</p>
<ol>
<li>$\left(B_{11} \rightarrow \left(P_{12} \lor P_{21}\right)\right) \land \left(\left(P_{12} \lor P_{21}\right) \rightarrow B_{11} \right)$</li>
</ol>
<p>Usando $A \rightarrow B \iff \neg A \lor B$ tenemos que:</p>
<ol start="2">
<li>$\left(\neg B_{11} \lor P_{12} \lor P_{21} \right) \land \left((\neg P_{12} \land \neg P_{21}) \lor B_{11}\right)$</li>
</ol>
<p>Distribuyendo:</p>
<ol start="3">
<li>$\left(\neg B_{11} \lor P_{12} \lor P_{21} \right) \land \left(B_{11} \lor \neg P_{12}\right) \land \left(B_{11} \lor \neg P_{21}\right)$</li>
</ol>
<p>De esta forma obtenemos 3 cl√°usulas que podemos insertar en nuestra base de conocimiento canonicalizada. Como observaci√≥n, Modus Ponens es si tengo $P$ y $P \rightarrow Q$, entonces tambi√©n tengo $Q$. En CNF, tendr√≠amos dos cl√°usulas $P \land \left(\neg P \lor Q\right)$, luego distribuyendo y resolviendo se llega a $\left(P \lor \neg P\right) \land \left(P \lor Q\right)$, y como $P \lor \neg P$ es siempre verdadero, entonces s√≥lo nos quedamos con $\left(P \lor Q\right)$. Esta ‚Äúregla‚Äù se conoce como regla de resoluci√≥n, y puede ser utilizada para realizar una demostraci√≥n por contradicci√≥n (reducci√≥n al absurdo). Volviendo al ejemplo anterior, para demostrar que <code>[1, 2]</code> es seguro (no hay precipicio), podemos seguir la siguiente cadena de razonamiento:</p>
<ol>
<li>Supongamos que hay un precipicio $P_{12}$.</li>
<li>Haciendo resoluci√≥n entre $P_{12}$ y $\neg P_{12} \lor B_{11}$, llegamos a $B_{11}$.</li>
<li>Sin embargo, tenemos en la base de conocimiento que $\neg B_{11}$ es cierto, lo que es contradictorio.</li>
<li>Por lo tanto, podemos concluir que la premisa $P_{12}$ no puede ser verdadera y por lo tanto es seguro visitar la posici√≥n <code>[1, 2]</code>.</li>
</ol>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/0b5be9b0cc96a1a00df1aa33c25a4df4309f59c0/resolution-algo.png" alt="intel" /></p>
<p><em>Fig 8: Algoritmo de resoluci√≥n en l√≥gica proposicional.</em></p>
</div>
<p>El algoritmo de resoluci√≥n est√° <a href="https://github.com/dpalmasan/py-logic/blob/main/pylogic/propositional.py#L588">implementado en pylogic</a> y sigue una idea similar al pseudo-c√≥digo excepto que tiene algunas heur√≠sticas extra para hacer el algoritmo m√°s eficiente. Cabe destacar que el espacio de b√∫squeda tambi√©n crece exponencialmente con la cantidad de s√≠mbolos y cl√°usulas.</p>
<p>El lector astuto podr√° notar que para la representaci√≥n del mundo tuvimos que usar una cl√°usula para cada precipicio, hedor y brisa. Sin embargo, podemos obtener una representaci√≥n m√°s compacta. Para desarrollar esta intuici√≥n, consideremos el siguiente argumento, que es un silogismo (Arist√≥teles) cl√°sico:</p>
<p>$$
\begin{array} {c}
\text{Todo hombre es mortal} \\
\text{S√≥crates es hombre} \\
\hline
\text{S√≥crates es mortal}
\end{array}
$$</p>
<p>Cabe destacar que matem√°ticamente, estos axiomas se pueden f√≥rmular con <strong>L√≥gica de Primer Orden</strong>:</p>
<p>$$
\begin{array} {c}
\forall x (Hombre(x) \rightarrow Mortal(x)) \\
Hombre(s) \\
\hline
Mortal(s)
\end{array}
$$</p>
<p>En el caso del problema del Wumpus, por ejemplo para un precipicio, podriamos representarlo como $P(a, b)$ donde $a$ y $b$ son objetos en este universo, que representan coordenadas en el mundo del Wumpus.</p>
<p>Por otro lado, cabe destacar que existe un subconjunto de la l√≥gica en el cual consideramos s√≥lo cierto tipo de cl√°usulas. Por ejemplo, las <strong>cl√°usulas de Horn</strong> son disyunciones de literales en donde a lo m√°s un literal est√° sin negaci√≥n, por ejemplo: $\neg A \lor \neg B \lor C$ es una cl√°usula de Horn, esta puede representarse como $A \land B \rightarrow C$, es decir una conjunci√≥n de antecedentes y un consecuente. Esto permite implementar algoritmos eficientes para ciertos problemas de satisfacibilidad.</p>
<p>Consideremos el siguiente problema. Tenemos un mapa de Australia con las siguientes regiones:</p>
<ul>
<li>WA: Western Australia</li>
<li>NT: Northern Territory</li>
<li>SA: South Australia</li>
<li>Q: Queensland</li>
<li>NSW: New South Wales</li>
<li>V: Victoria</li>
</ul>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/37b5f28e91e17e8d9b82dc8680de3076a95e86bc/map.png" alt="intel" /></p>
<p><em>Fig 9: Problema de coloreado de mapas (Australia).</em></p>
</div>
<p>Supongamos que queremos colorear el mapa de tal manera que dos regiones adyacentes no sean del mismo color. Podemos representar el problema los siguientes axiomas en modo de cl√°usulas de Horn:</p>
<p>$$
\begin{array} {   rr} \quad Diff(wa, nt) \land Diff(wa, sa) \land \\ Diff(nt, q) \land Diff(nt, sa) \land \\ Diff(q, nsw) \land Diff(q, sa) \land \\ Diff(nsw, v) \land Diff(nsw, a) \land \\ Diff(v, sa) \Rightarrow Coloreable() \\ Diff(Red, Blue) \quad Diff(Red, Green) \\ Diff(Blue, Red) \quad Diff(Blue, Green) \\ Diff(Green, Red) \quad Diff(Green, Blue) \end{array}
$$</p>
<p>Utilizando mi biblioteca pylogic:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pylogic.fol</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">HornClauseFOL</span><span class="p">,</span>
    <span class="n">Predicate</span><span class="p">,</span>
    <span class="n">Term</span><span class="p">,</span>
    <span class="n">TermType</span><span class="p">,</span>
    <span class="n">fol_bc_ask</span><span class="p">,</span>
    <span class="n">Substitution</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">wa</span> <span class="o">=</span> <span class="n">Term</span><span class="p">(</span><span class="s">"wa"</span><span class="p">,</span> <span class="n">TermType</span><span class="p">.</span><span class="n">VARIABLE</span><span class="p">)</span>
<span class="n">sa</span> <span class="o">=</span> <span class="n">Term</span><span class="p">(</span><span class="s">"sa"</span><span class="p">,</span> <span class="n">TermType</span><span class="p">.</span><span class="n">VARIABLE</span><span class="p">)</span>
<span class="n">nt</span> <span class="o">=</span> <span class="n">Term</span><span class="p">(</span><span class="s">"nt"</span><span class="p">,</span> <span class="n">TermType</span><span class="p">.</span><span class="n">VARIABLE</span><span class="p">)</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">Term</span><span class="p">(</span><span class="s">"q"</span><span class="p">,</span> <span class="n">TermType</span><span class="p">.</span><span class="n">VARIABLE</span><span class="p">)</span>
<span class="n">nsw</span> <span class="o">=</span> <span class="n">Term</span><span class="p">(</span><span class="s">"nsw"</span><span class="p">,</span> <span class="n">TermType</span><span class="p">.</span><span class="n">VARIABLE</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">Term</span><span class="p">(</span><span class="s">"v"</span><span class="p">,</span> <span class="n">TermType</span><span class="p">.</span><span class="n">VARIABLE</span><span class="p">)</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">Term</span><span class="p">(</span><span class="s">"t"</span><span class="p">,</span> <span class="n">TermType</span><span class="p">.</span><span class="n">VARIABLE</span><span class="p">)</span>

<span class="nb">map</span> <span class="o">=</span> <span class="n">HornClauseFOL</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">wa</span><span class="p">,</span> <span class="n">nt</span><span class="p">]),</span>
        <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">wa</span><span class="p">,</span> <span class="n">sa</span><span class="p">]),</span>
        <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">nt</span><span class="p">,</span> <span class="n">q</span><span class="p">]),</span>
        <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">nt</span><span class="p">,</span> <span class="n">sa</span><span class="p">]),</span>
        <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">q</span><span class="p">,</span> <span class="n">nsw</span><span class="p">]),</span>
        <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">q</span><span class="p">,</span> <span class="n">sa</span><span class="p">]),</span>
        <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">nsw</span><span class="p">,</span> <span class="n">v</span><span class="p">]),</span>
        <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">nsw</span><span class="p">,</span> <span class="n">sa</span><span class="p">]),</span>
        <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">v</span><span class="p">,</span> <span class="n">sa</span><span class="p">]),</span>
    <span class="p">],</span>
    <span class="n">Predicate</span><span class="p">(</span><span class="s">"Colorable"</span><span class="p">,</span> <span class="p">[]),</span>
<span class="p">)</span>

<span class="n">red</span> <span class="o">=</span> <span class="n">Term</span><span class="p">(</span><span class="s">"Red"</span><span class="p">,</span> <span class="n">TermType</span><span class="p">.</span><span class="n">CONSTANT</span><span class="p">)</span>
<span class="n">blue</span> <span class="o">=</span> <span class="n">Term</span><span class="p">(</span><span class="s">"Blue"</span><span class="p">,</span> <span class="n">TermType</span><span class="p">.</span><span class="n">CONSTANT</span><span class="p">)</span>
<span class="n">green</span> <span class="o">=</span> <span class="n">Term</span><span class="p">(</span><span class="s">"Green"</span><span class="p">,</span> <span class="n">TermType</span><span class="p">.</span><span class="n">CONSTANT</span><span class="p">)</span>

<span class="n">p1</span> <span class="o">=</span> <span class="n">HornClauseFOL</span><span class="p">(</span>
    <span class="p">[],</span>
    <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">red</span><span class="p">,</span> <span class="n">blue</span><span class="p">]),</span>
<span class="p">)</span>
<span class="n">p2</span> <span class="o">=</span> <span class="n">HornClauseFOL</span><span class="p">(</span>
    <span class="p">[],</span>
    <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">red</span><span class="p">,</span> <span class="n">green</span><span class="p">]),</span>
<span class="p">)</span>
<span class="n">p3</span> <span class="o">=</span> <span class="n">HornClauseFOL</span><span class="p">(</span>
    <span class="p">[],</span>
    <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">green</span><span class="p">,</span> <span class="n">red</span><span class="p">]),</span>
<span class="p">)</span>
<span class="n">p4</span> <span class="o">=</span> <span class="n">HornClauseFOL</span><span class="p">(</span>
    <span class="p">[],</span>
    <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">green</span><span class="p">,</span> <span class="n">blue</span><span class="p">]),</span>
<span class="p">)</span>
<span class="n">p5</span> <span class="o">=</span> <span class="n">HornClauseFOL</span><span class="p">(</span>
    <span class="p">[],</span>
    <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">blue</span><span class="p">,</span> <span class="n">red</span><span class="p">]),</span>
<span class="p">)</span>
<span class="n">p6</span> <span class="o">=</span> <span class="n">HornClauseFOL</span><span class="p">([],</span> <span class="n">Predicate</span><span class="p">(</span><span class="s">"Diff"</span><span class="p">,</span> <span class="p">[</span><span class="n">blue</span><span class="p">,</span> <span class="n">green</span><span class="p">]))</span>

<span class="n">kb</span> <span class="o">=</span> <span class="p">[</span><span class="nb">map</span><span class="p">,</span> <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">p3</span><span class="p">,</span> <span class="n">p4</span><span class="p">,</span> <span class="n">p5</span><span class="p">,</span> <span class="n">p6</span><span class="p">]</span>

<span class="n">goal</span> <span class="o">=</span> <span class="n">Predicate</span><span class="p">(</span><span class="s">"Colorable"</span><span class="p">,</span> <span class="p">[])</span>
<span class="n">answers</span> <span class="o">=</span> <span class="n">fol_bc_ask</span><span class="p">(</span><span class="n">kb</span><span class="p">,</span> <span class="p">[</span><span class="n">goal</span><span class="p">],</span> <span class="n">Substitution</span><span class="p">({}))</span>

<span class="k">for</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">answers</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">answer</span><span class="p">.</span><span class="n">substitution_values</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">print</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">7</span><span class="p">)</span>
</code></pre></div></div>
<p>La cual entrega m√∫ltiples soluciones, por ejemplo:</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/37b5f28e91e17e8d9b82dc8680de3076a95e86bc/maps.drawio.png" alt="intel" /></p>
<p><em>Fig 10: Soluciones entregadas por PyLogic para el problema de coloreado de mapas.</em></p>
</div>
<h1 id="un-poco-ms-sobre-problemas-de-bsqueda">Un poco m√°s sobre problemas de b√∫squeda</h1>
<p>Gran parte de la IA, puede reducirse a un problema de b√∫squeda.</p>
<ul>
<li>En machine learning estamos buscando ‚Äúel mejor modelo‚Äù en base a alg√∫n criterio (por ejemplo ajuste de datos)</li>
<li>En problemas de estados, estamos buscando ‚Äúel mejor camino‚Äù para llegar de un estado inicial a un estado objetivo</li>
<li>En l√≥gica dada una cl√°usula y una base de conocimiento estamos buscando si esta cl√°usula se puede satisfacer dado el conocimiento embebido en la base.</li>
<li>En problemas de satisfacci√≥n de restricciones, estamos buscando la soluci√≥n que cumpla todas las restricciones y que minimice o maximice una funci√≥n objetivo.</li>
</ul>
<p>El c√≥mo se hace la b√∫squeda es donde uno tiene que poner cerebro a resolver el problema.</p>
<h2 id="ejemplo-de-estimacin-de-parmetros">Ejemplo de Estimaci√≥n de Par√°metros</h2>
<p>Supongamos que tenemos los siguientes datos:</p>
<ul>
<li><code>t = [0., 0.11111111, 0.22222222, 0.33333333, 0.44444444, 0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.]</code></li>
<li><code>v = [100.96510126, 67.78222915, 48.48101823, 24.98947315, 18.23139621, 12.91163503, 5.18434069, 7.19801177, 4.63123254, 1.91433441]</code></li>
</ul>
<p>Queremos encontrar un modelo que ajuste dichos datos. Supongamos que estudiamos el modelo f√≠sico:</p>
<p>$$v(t) = v_0 \cdot e^{-\frac{t}{\tau}}$$</p>
<p>En este caso podemos transformar el problema a uno lineal en sus par√°metros ($v_0$ y $\tau$):</p>
<ul>
<li>$log\left(v\left(t\right)\right) = log\left(v_0\right) + log\left(e^{-\frac{t}{\tau}}\right)$</li>
<li>$log\left(v\left(t\right)\right) = a - b\cdot t$</li>
</ul>
<p>Luego aplicar m√≠nimos cuadrados para encontrar $a$ y $b$ y re-transformar a los par√°metros originales:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">V0</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">t_truth</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mf">0.0</span><span class="p">,</span>
        <span class="mf">0.11111111</span><span class="p">,</span>
        <span class="mf">0.22222222</span><span class="p">,</span>
        <span class="mf">0.33333333</span><span class="p">,</span>
        <span class="mf">0.44444444</span><span class="p">,</span>
        <span class="mf">0.55555556</span><span class="p">,</span>
        <span class="mf">0.66666667</span><span class="p">,</span>
        <span class="mf">0.77777778</span><span class="p">,</span>
        <span class="mf">0.88888889</span><span class="p">,</span>
        <span class="mf">1.0</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mf">100.96510126</span><span class="p">,</span>
        <span class="mf">67.78222915</span><span class="p">,</span>
        <span class="mf">48.48101823</span><span class="p">,</span>
        <span class="mf">24.98947315</span><span class="p">,</span>
        <span class="mf">18.23139621</span><span class="p">,</span>
        <span class="mf">12.91163503</span><span class="p">,</span>
        <span class="mf">5.18434069</span><span class="p">,</span>
        <span class="mf">7.19801177</span><span class="p">,</span>
        <span class="mf">4.63123254</span><span class="p">,</span>
        <span class="mf">1.91433441</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span> <span class="o">-</span><span class="n">t</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">sol</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">V0_approx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">tau_approx</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">sol</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"V0 = </span><span class="si">{</span><span class="n">V0</span><span class="si">}</span><span class="s">; tau = </span><span class="si">{</span><span class="n">tau</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">V_truth</span> <span class="o">=</span> <span class="n">V0</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">t_truth</span> <span class="o">/</span> <span class="n">tau</span><span class="p">)</span>
<span class="n">V_approx</span> <span class="o">=</span> <span class="n">V0_approx</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">t_truth</span> <span class="o">/</span> <span class="n">tau_approx</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t_truth</span><span class="p">,</span> <span class="n">V_truth</span><span class="p">,</span> <span class="s">"-b"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="s">"*r"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t_truth</span><span class="p">,</span> <span class="n">V_approx</span><span class="p">,</span> <span class="s">"-g"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">((</span><span class="s">"Funci√≥n Original"</span><span class="p">,</span> <span class="s">"Medidas con ruido"</span><span class="p">,</span> <span class="s">"Soluci√≥n encontrada"</span><span class="p">))</span>
</code></pre></div></div>
<p>La salida del programa previo es:</p>
<pre><code>V0 = 100; tau = 0.25
V0_approx = 99.8009989146457; tau_approx = 0.2654186277602548
</code></pre>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/0b5be9b0cc96a1a00df1aa33c25a4df4309f59c0/finding_example.png" alt="intel" /></p>
<p><em>Fig 11: Ejemplo de b√∫squeda de par√°metros por m√≠nimos cuadrados.</em></p>
</div>
<p>El resultado indica que podemos estimar los par√°metros y dependiendo del ruido en los datos la estimaci√≥n ser√° cercana a los par√°metros reales del modelo. Pregunta para el lector ¬øQu√© ocurre en el caso de outliers extremos? ¬øC√≥mo lidiar con estos casos?</p>
<h2 id="pddl-planning-domain-definition-language">PDDL: Planning Domain Definition Language</h2>
<p><em>PDDL</em> es un lenguaje estandarizado desarrollado para agentes que resuelven problemas de planificaci√≥n. El lenguaje es flexible y tiene los siguientes requerimientos:</p>
<ul>
<li>
<p>Definir el dominio del problema</p>
<ul>
<li>Los predicados: van a ser estados que puedene ser verdaderos o falsos. Por ejemplo <code>in x</code>, <code>visited x</code>, <code>connected x y</code></li>
<li>Acciones: Las acciones tienen <strong>pre-requisitos</strong> y efectos. Por ejemplo si el agente se encuentra en la posici√≥n <code>a</code> (<code>in a</code>), <code>a</code> est√° conectado con b, <code>connected a b</code>, se puede tener la acci√≥n <code>move x y</code> cuyo <strong>efecto</strong> sea: <code>in y</code>, <code>visited y</code> y remover <code>in a</code> (hacer este predicado falso)</li>
<li>Cada acci√≥n puede tener un <strong>costo</strong> asociado.</li>
</ul>
</li>
<li>
<p>Tener una instancia del problema, para la cual se haga el plan.</p>
</li>
</ul>
<p>Supongamos que tenemos un mapa de ciudades, y queremos recorrer todas las ciudades en el m√≠nimo de tiempo posible hasta volver al punto inicial.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/1713a4dbddccb96f32b8e0d00a3e3c735c0a442e/tsp.png" alt="intel" /></p>
<p><em>Fig 12: Ejemplo de mapa de ciudades.</em></p>
</div>
<p>En este caso, en PDDL el dominio ser√≠a:</p>
<pre><code class="language-pddl">(define (domain tsp-strips)
  (:requirements :strips)
  (:predicates (in ?x) (visited ?x) (not-visited ?x)
	       (starting ?x) (complete) (not-complete)
	       (connected ?x ?y))

  (:action go-along
    :parameters (?x ?y)
    :precondition (and (in ?x) (not-visited ?y) (not-complete)
		       (connected ?x ?y))
    :effect (and (not (in ?x)) (in ?y) (visited ?y) (not (not-visited ?y))))

  (:action return-along
    :parameters (?x ?y)
    :precondition (and (in ?x) (starting ?y) (not-complete)
		       (connected ?x ?y))
    :effect (and (not (in ?x)) (in ?y) (not (not-complete)) (complete)))

 )
</code></pre>
<p>Ahora definamos la instancia en <code>PDDL</code>:</p>
<pre><code class="language-pddl">(define (problem ten-cities)
  (:domain tsp-strips)
  (:objects c1 c2 c3 c4 c5 c6 c7 c8 c9 c10)
  (:init (connected c1 c2) (connected c1 c3) (connected c2 c4)
         (connected c2 c5) (connected c3 c6) (connected c3 c7)
         (connected c4 c8) (connected c4 c9) (connected c5 c10)
         (connected c5 c1) (connected c6 c2) (connected c6 c3)
         (connected c7 c4) (connected c7 c5) (connected c8 c6)
         (connected c8 c7) (connected c9 c8) (connected c10 c1)
         (visited c1) (not-visited c2) (not-visited c3)
         (not-visited c4) (not-visited c5) (not-visited c6)
         (not-visited c7) (not-visited c8) (not-visited c9)
         (not-visited c10)
         (in c1) (starting c1) (not-complete))
  (:goal (and (visited c1) (visited c2) (visited c3) (visited c4)
              (visited c5) (visited c6) (visited c7) (visited c8)
              (visited c9) (visited c10) (complete)))
  )
</code></pre>
<p>El plan retornado por un planner por ejemplo ser√≠a el mostrado en la figura 13.</p>
<pre><code>(go-along c1 c2)
(go-along c2 c4)
(go-along c4 c9)
(go-along c9 c8)
(go-along c8 c6)
(go-along c6 c3)
(go-along c3 c7)
(go-along c7 c5)
(go-along c5 c10)
(return-along c10 c1)
</code></pre>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/1713a4dbddccb96f32b8e0d00a3e3c735c0a442e/tsp-sol-pddl.png" alt="intel" /></p>
<p><em>Fig 13: Ejemplo de b√∫squeda de par√°metros por m√≠nimos cuadrados.</em></p>
</div>
<h2 id="agentes-llm">¬øAgentes LLM?</h2>
<p>Con los LLM y las nuevas tendencias en la industria, sale el concepto de agentes con LLMs. Estos agentes funcionan en un dominio abierto y son capaces de generar un plan como una consulta en lenguaje natural. Existen frameworks para connectar LLMs como <a href="https://python.langchain.com/v0.1/docs/modules/agents/">LangChain</a>.</p>
<p>Ahora ¬øQu√© soluci√≥n es mejor? Depende del problema, requerimientos, conocimiento de expertos del dominio y coste dispuesto a pagar (no es barato hacer inferencias con LLM dependiendo de las queries a considerar, por ejemplo QPS).</p>
<h1 id="reflexiones">Reflexiones</h1>
<ul>
<li>Se pueden clasificar distintos tipos de agentes dependiendo de la ‚Äúinteligencia‚Äù de estos. La inteligencia en este caso es una definici√≥n simplista que denota el nivel sofisticaci√≥n del agente</li>
<li>Todos los enfoques pueden reducirse a un problema de b√∫squeda. La estrategia cambia, y escoger cu√°l utilizar depender√° del problema a resolver.</li>
<li>Existen lenguajes estandarizados para definir dominios y agentes.</li>
<li>Las nuevas tendencias utilizan agentes que utilizan LLMs para el razonamiento y construcci√≥n de un plan. La ‚Äúmejor‚Äù soluci√≥n depender√° de las restricciones del problema.</li>
</ul>
<p>Espero que el art√≠culo haya sido interesante üòä. ¬°Abrazos!</p>]]></content><author><name>dpalmasan</name></author><category term="algorithms" /><category term="ai" /><summary type="html"><![CDATA[Introducci√≥n En estos momentos estoy en Suvarnabhumi Airport, en Bangkok, en el Sakura Lounge de Japan Airlines, esperando para tomar mi vuelo de vuelta a Seattle. ¬°Rayos! Las vacaciones pasan r√°pido. El art√≠culo de hoy ser√° sobre conceptos b√°sicos de inteligencia artificial, en particular ‚Äúagentes‚Äù, ya este t√©rmino est√° empezando a sonar bastante con la tendencia de utilizar LLMs en la actualidad. Mi art√≠culo, sin embargo, ser√° un poco m√°s simple e intentar√° introducir el concepto de manera intuitiva. Conceptos de IA Definir qu√© es la inteligencia artificial puede ser pol√©mico, por lo que no dar√© una definici√≥n directamente en esta ocasi√≥n. El libro de Peter Norvig Artificial Intelligence: A modern approach tiene un cap√≠tulo introductorio fascinante. El nombre de Inteligencia Artificial para este campo de estudio, fue dado en 1956, aunque anteriormente hubo investigaciones ligadas a lo que desde entonces se conoce como Inteligencia Artificial. Es m√°s, √©ste campo multidisciplinario toma conocimiento y teor√≠a de: filosof√≠a, lenguaje, psicolog√≠a, neurociencia, econom√≠a, etc (en teor√≠a podr√≠amos estar hablando que la teor√≠a asociada existe desde la √©poca de Arist√≥teles). El nombre de IA ha perdurado en el tiempo, pero lo que estudia se asemeja con la racionalidad computacional. La raz√≥n de ello, es que en t√©rminos de ‚Äúinteligencia‚Äù, la inteligencia artificial considera agentes que toman decisiones de forma racional, idealmente, toma la mejor decisi√≥n dada una situaci√≥n. Agentes en IA Primero deber√≠amos definir qu√© es un agente, para luego definir qu√© es un agente inteligente. Un agente, es cualquier ente que pueda percibir su entorno a trav√©s de sensores y ejecutar acciones dentro del entorno mediante actuadores, tal como muestra la figura 1. La caja con el signo de interrogaci√≥n, es qu√© razonamiento/inteligencia se le provee al agente para que tome acciones dada una percepci√≥n del entorno. Fig 1: Interacci√≥n entre agente y entorno en alto nivel. Cabe destacar que esta noci√≥n de agente es una herramienta para analizar sistemas, no es una caracterizaci√≥n que define qu√© es y qu√© no es un agente. Agente Racional Ahora que definimos un agente, hay que definir qu√© es un agente racional. Un agente racional es un agente que toma la acci√≥n correcta, algunos ejemplos: El controlador de aire acondicionado, esperar√≠amos que manejara la temperatura acorde a la temperatura configurada (aunque en mi experiencia personal, esto a veces no resulta jeje); una aspiradora roomba, esperar√≠amos que limpiara satisfactoriamente una habitaci√≥n dada. Pero, desde el punto de vista de IA ¬øQu√© podr√≠a definirse como racionalidad? En realidad, lo que es racional depende de cuatro factores: La m√©trica de rendimiento que define un criterio de √©xito. El conocimiento previo del agente respecto al entorno donde opera. Las acciones que el agente puede tomar Las percepciones del agente en un momento dado. ¬øOmnipotencia? Aqu√≠ tambi√©n hay que hacer una diferencia entre lo racional y el rendimiento perfecto. Esto es, porque en general, el agente no tiene conocimiento del resultado real de sus acciones, s√≥lo tiene conocimiento del resultado esperado. Si el agente fuese omnipotente (cosa imposible en la pr√°ctica), podr√≠a maximizar la m√©trica de rendimiento real, sin embargo, un agente racional busca maximizar la m√©trica de rendimiento esperada (dado a lo que el agente espera de los resultados de sus acciones). Por ejemplo, si me env√≠an un correo diciendo que gan√© un mill√≥n de d√≥lares, y en efecto no era spam, sin embargo el agente clasificador de correos lo clasific√≥ como SPAM, por lo tanto yo decid√≠ que era SPAM, pero en la realidad no era SPAM, es algo fortuito, que el agente no pudo haber esperado. Otro ejemplo, si no viene ning√∫n auto, el sem√°foro marca verde, cruzo la calle y me cae la turbina de un avi√≥n, no puedo decir que no es racional cruzar en verde; es simplemente mala suerte. Otro ejemplo m√°s actual que se me ocurre, mi instinto ar√°cnido me dice que muchos ‚Äúmodelos predictivos‚Äù de algunas empresas no ten√≠an contemplado el COVID-19. Algunas propiedades de los entornos en que un agente operar√° son: Completamente observable / parcialmente observable (¬øTengo conocimiento total del mundo o s√≥lo parcial?) Determin√≠stico / Estoc√°stico (¬øEl estado siguiente se determina completamente del estado actual?) Epis√≥dico / secuencial (¬ødepende mi acci√≥n siguiente de mi acci√≥n previa?) Est√°tico / Din√°mico Discreto / Continuo Un s√≥lo agente / Multiagente ‚ÄúInteligencia‚Äù en IA Los tipos de inteligencia en IA se pueden clasificar de acuerdo al razonamiento que hacen sobre el entorno/mundo, como se muestra en la figura 2. Fig 2: Distintos niveles de ‚Äúinteligencia‚Äù de un agente. Fuente. Agentes por Reflejo En este tipo de inteligencia, se encuentran agentes que act√∫an por reflejo. Consideremos un caso hip√≥tetico de un gato robot, llam√©mosle RoboCat. A este gato artificial le gusta jugar a seguir un punto generado por un puntero laser. import numpy as np]]></summary></entry><entry><title type="html">Redes Neuronales y Variables Multi-Categ√≥ricas</title><link href="https://dpalmasan.github.io/website/probability/algorithms/ai/2024/04/28/multi-categorical.html" rel="alternate" type="text/html" title="Redes Neuronales y Variables Multi-Categ√≥ricas" /><published>2024-04-28T21:22:00+00:00</published><updated>2024-04-28T21:22:00+00:00</updated><id>https://dpalmasan.github.io/website/probability/algorithms/ai/2024/04/28/multi-categorical</id><content type="html" xml:base="https://dpalmasan.github.io/website/probability/algorithms/ai/2024/04/28/multi-categorical.html"><![CDATA[<h1 id="introduccin">Introducci√≥n</h1>
<p>En algunos problemas donde nos interesa poder ‚Äúpredecir‚Äù una cierta clase para una entrada dada (por ejemplo usuario, negocio, entidad gen√©rica), podemos tener diversos tipos de variables, entre ellas variables categ√≥ricas. Una variable categ√≥rica es una variable discreta que puede tomar ciertos valores, que no necesariamente consideran un orden espec√≠fico (no hay noci√≥n de desigualdad). Generalmente los modelos basados en √°rboles de decisi√≥n no tienen problemas para lidiar con este tipo de variables, sin embargo los modelos num√©ricos necesitan un tratamiento especial para poder manipularlas.</p>
<p>Por otro lado, las variables categ√≥ricas por lo general pueden tomar un s√≥lo valor (categor√≠a). Sin embargo, existen problemas m√°s interesantes. Por ejemplo, supongamos que tenemos IDs de p√°ginas visitadas como una variable. El lector podr√° notar, que esta no es una variable ordinal, y que este tipo de variables es <em>Multi-Categr√≥rica</em> ya que una entrada puede tener m√°s de una cateogor√≠a a la vez.</p>
<p>En este art√≠culo, comentar√© c√≥mo lidiar con este tipo de variables, en particular, utilizando un modelo basado en redes neuronales. Tambi√©n mencionar√© representaciones eficientes de variables multi-categ√≥ricas y c√≥mo en la pr√°ctica se procesan este tipo de variables.</p>
<h1 id="variables-categricas">Variables Categ√≥ricas</h1>
<p>Por lo general, los enfoques cl√°sicos para procesar este tipo de variables, consisten en seguir un esquema de <em>One Hot Encoding</em>, que consiste en codificar la variable como una m√°scara (vector de <code>0s</code> y <code>1s</code>), donde la dimensi√≥n de este vector ser√° <code>N_categorias - 1</code>. Por ejemplo, si tuvieramos la variable <code>color</code> que pudiese tomar los valores <code>[celeste, gris, caf√©]</code>, se necesitar√≠a un vector binario de dimensi√≥n 2:</p>
<ul>
<li>$\text{celeste} = \left(1, 0\right)$</li>
<li>$\text{gris} = \left(0, 1\right)$</li>
<li>$\text{caf√©} = \left(0, 0\right)$</li>
</ul>
<p>Se asume que un registro puede pertenecer a una sola categor√≠a, por lo que los vectores posibles consideran todas las combinaciones para dicha dimensi√≥n vectorial. El vector $\left(1, 1\right)$ no representa alg√∫n dato, debido al supuesto mencionado.</p>
<p>Sin embargo, en la naturaleza y en la pr√°ctica existen otro tipo de variables. Estas son variables <em>Multi-Categ√≥ricas</em>, que consisten tambi√©n en variables discretas, pero que pueden tomar m√∫ltiples valores a la vez. Un ejemplo simple es un sistema de recomendaci√≥n de pel√≠culas. Por ejemplo, una persona puede haber visto ciertas pel√≠culas, las cuales al considerarlas como un todo, permiten aproximar, por ejemplo, los gustos de dicha persona. En este caso, la variable podr√≠an ser los t√≠tulos de las pel√≠culas vistas (ej. una lista de pel√≠culas).</p>
<h1 id="problema-de-juguete">Problema de Juguete</h1>
<p>Supongamos que estamos en un universo, en el cual un usuario puede haber visitado una serie de p√°ginas webs, y nos interesa, a partir de dichas visitas, estimar las preferencias del usuario, para por ejemplo, recomendar productos/servicios basados en el contexto actual de dicho usuario. En este universo, cada usuario $u$ se representa como un vector de p√°ginas visitadas (por simplicidad, IDs enteras). Supongamos que tenemos las siguientes definiciones:</p>
<ul>
<li>Si $u$ visit√≥ $\left(1, 5, 11, 19\right)$ entonces $u$ tiene preferencias de contenido acerca de comida.</li>
<li>Si $u$ visit√≥ $\left(2, 4, 8, 16\right)$ entonces $u$ tiene preferencias de contenido acerca de pel√≠culas.</li>
<li>En cualquier otro caso, no sabemos con certeza las preferencias de $u$.</li>
</ul>
<p>Supongamos que existen un total de 200 posibles p√°ginas web a visitar. ¬øC√≥mo podr√≠amos representar a cada usuario $u$ para poder definir un modelo predictivo?</p>
<p>Una forma ingenua de hacerlo, es utilizando un vector m√°scara, similar a lo que se hace para variables categ√≥ricas simples. Por ejemplo, si un usuario $u_i$ visit√≥ las p√°ginas <code>[1, 3, 5]</code> entonces su representaci√≥n ser√≠a:</p>
<ul>
<li>$u_i = \left(0, 1, 0, 1, 0, 1, 0, 0\ldots 0 \right)$</li>
</ul>
<p>El lector atento ya puede ver cu√°l es el problema, pero para hacerlo m√°s claro, se obtiene un vector muy disperso (gran porcentaje de ceros), lo que por lo general trae problemas de estabilidad num√©rica (arrastre de error), adem√°s de uso ineficiente de memoria. ¬øQu√© tal si representaramos cada categor√≠a en un espacio vectorial de dimensi√≥n $K$ y adem√°s tuvi√©semos una lista $N$ donde $N$ es el n√∫mero de <code>IDs</code> posibles para las p√°ginas visitadas? Este tipo de representaci√≥n se conoce como <em>embeddings</em>.</p>
<p>Por otro lado, el problema no es una simple reducci√≥n de dimensionalidad, tenemos que encontrar una forma m√°s inteligente de representar a los usuarios. Supongamos que tenemos el siguiente <em>batch</em> de usuarios:</p>
<ul>
<li><code>u1 = [1, 4, 9]</code></li>
<li><code>u2 = [3, 2]</code></li>
<li><code>u3 = [11, 17, 12, 19]</code></li>
</ul>
<p>No necesitamos utilizar todas las categor√≠as posibles para representar un usuario, en especial si posteriormente queremos agregar (aplicar <em>pooling</em>) la representaci√≥n vectorial de las p√°ginas. En este caso, podr√≠amos representar el <em>batch</em> como dos tensores, uno de <em>offsets</em> y otro de valores:</p>
<ul>
<li><code>values = [1, 4, 9, 3, 2, 11, 17, 12, 19]</code></li>
<li><code>offsets = [0, 3, 5]</code></li>
</ul>
<p>Los valores, son simplemente todos los valores de los usuarios en el <em>batch</em> concatenados, y los <em>offsets</em> representan la posici√≥n donde comienza cada registro (en este caso usuario). Esta es una representaci√≥n m√°s eficiente que s√≥lo requiere la informaci√≥n a procesar. Finalmente, aplicando alg√∫n mecanismo de <em>pooling</em> podemos calcular el centro de masa, la suma vectorial, etc. del conjunto de vectores que representa al usuario, tal y como se muestra en la figura 1.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/4f2bc2edf17bd2522ba7ccd21b08ed92e108feb9/pooling.png" alt="user_emb" /></p>
<p><em>Fig 1: Representaci√≥n de usuario y p√°ginas en espacio vectorial.</em></p>
</div>
<h2 id="implementando-un-clasificador-de-usuarios-basado-en-sus-pginas-visitadas">Implementando un Clasificador de Usuarios basado en sus p√°ginas visitadas</h2>
<p>La red neuronal a ajustar ser√° una simple red neuronal de dos capas, y tendr√° una Bolsa de Embeddings (<em>Embedding bag</em>) para transformar la representaci√≥n del usuario un una representaci√≥n vectorial. Esta arquitectura se muestra en la figura 2.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/5c93d818a78602489880bec56eff1567bb430d34/categorical_classifier.png" alt="user_emb" /></p>
<p><em>Fig 2: Arquitectura de Clasificador para universo de problema multi-categ√≥rico.</em></p>
</div>
<p>Este universo lo simularemos en <code>Python</code> con <code>Pytorch</code>. Comencemos importando las bibliotecas a utilizar:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
</code></pre></div></div>
<p>Definamos un conjunto de constantes:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SAMPLES</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">NUM_OF_CATEGORIES</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">TRAINING_SAMPLES</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">SAMPLES</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">TEST_SAMPLES</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">SAMPLES</span> <span class="o">*</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">EMB_DIM</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">HIDDEN_DIM</span> <span class="o">=</span> <span class="mi">16</span>
</code></pre></div></div>
<p>Muestreo de datos en este universo:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_sparse_features</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">max_categories</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">max_categories</span> <span class="o">&gt;</span> <span class="mi">4</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">universe</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_categories</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="n">max_categories</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="n">max_categories</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">universe</span><span class="p">)</span>
        <span class="n">row</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">universe</span><span class="p">[:</span><span class="n">offset</span><span class="p">]:</span>
            <span class="n">row</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">rows</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">rows</span>

<span class="n">training_sparse_features</span> <span class="o">=</span> <span class="n">generate_sparse_features</span><span class="p">(</span><span class="n">TRAINING_SAMPLES</span><span class="p">,</span> <span class="n">NUM_OF_CATEGORIES</span><span class="p">)</span>
</code></pre></div></div>
<p>Definamos las clases a las que el usuario podr√≠a pertenecer:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Preferences</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">NEUTRAL</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">LIKES_MOVIE_CONTENT</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">LIKES_FOOD_CONTENT</span> <span class="o">=</span> <span class="mi">2</span>
</code></pre></div></div>
<p>Definamos la funci√≥n oculta a aproximar:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">exact_function_to_approximate</span><span class="p">(</span><span class="n">x_set</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">set</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">19</span><span class="p">}).</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">x_set</span><span class="p">)):</span>
        <span class="k">return</span> <span class="n">Preferences</span><span class="p">.</span><span class="n">LIKES_FOOD_CONTENT</span>

    <span class="k">if</span> <span class="nb">set</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">}).</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">x_set</span><span class="p">)):</span>
        <span class="k">return</span> <span class="n">Preferences</span><span class="p">.</span><span class="n">LIKES_MOVIE_CONTENT</span>

    <span class="k">return</span> <span class="n">Preferences</span><span class="p">.</span><span class="n">NEUTRAL</span>
</code></pre></div></div>
<p>Estad√≠sticas:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_labels_sparse</span> <span class="o">=</span> <span class="p">[</span><span class="n">exact_function_to_approximate</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">training_sparse_features</span><span class="p">]</span>
<span class="n">Counter</span><span class="p">(</span><span class="n">training_labels_sparse</span><span class="p">)</span>
</code></pre></div></div>
<pre><code>Counter({&lt;Preferences.NEUTRAL: 0&gt;: 38167,
         &lt;Preferences.LIKES_FOOD_CONTENT: 2&gt;: 941,
         &lt;Preferences.LIKES_MOVIE_CONTENT: 1&gt;: 892})
</code></pre>
<p>Convertir etiquetas a enteros (para luego transformar a tensores).</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_labels_sparse</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">training_labels_sparse</span><span class="p">]</span>
</code></pre></div></div>
<p>Definamos el modelo en <code>Pytorch</code>:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SimpleMultiCategoricalClassifier</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_embeddings</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">EmbeddingBag</span><span class="p">(</span><span class="n">num_embeddings</span><span class="p">,</span>
                                         <span class="n">embed_dim</span><span class="p">,</span>
                                         <span class="n">mode</span><span class="o">=</span><span class="s">"sum"</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">offsets</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">values</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">embed</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">offsets</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">values</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">offsets</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
</code></pre></div></div>
<p>Prueba inicial de funcionamiento:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">SimpleMultiCategoricalClassifier</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">NUM_OF_CATEGORIES</span><span class="p">,</span>
                                         <span class="n">embed_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                                         <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">example_values</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">training_sparse_features</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">example_offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">model</span><span class="p">(</span><span class="n">example_offsets</span><span class="p">,</span> <span class="n">example_offsets</span><span class="p">)</span>
</code></pre></div></div>
<pre><code>tensor([[ 0.1533, -0.3507, -0.0683],
        [ 0.2590, -0.4411, -0.1981]], grad_fn=&lt;AddmmBackward0&gt;)
</code></pre>
<p>Definamos el <em>Dataloader</em>:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SimpleSparseDenseDataLoader</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sparse_features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">sparse_features</span> <span class="o">=</span> <span class="n">sparse_features</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">sparse_features</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">sparse_features</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</code></pre></div></div>
<p>Debemos transformar los datos de manera de obtener los tensores de <em>offset</em> y <em>values</em>, por lo que definimos una funci√≥n personalizada para procesar los <em>batches</em> de datos:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">collate_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="n">label_list</span><span class="p">,</span> <span class="n">data_list</span><span class="p">,</span> <span class="n">offsets</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
        <span class="n">label_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        <span class="n">data_list</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">offsets</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    <span class="n">label_list</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">label_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">values_list</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">offsets</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]).</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">offsets</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_list</span><span class="p">),</span>\
        <span class="sa">f</span><span class="s">"Offsets numel </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">offsets</span><span class="p">)</span><span class="si">}</span><span class="s"> != labels numel </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">label_list</span><span class="p">)</span><span class="si">}</span><span class="s">"</span>
    <span class="k">return</span> <span class="n">label_list</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">values_list</span>
</code></pre></div></div>
<p>Para evitar tener problemas con los pesos de la red, definimos funciones para inicializar los pesos de la red:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">weights_init_uniform_rule</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="n">classname</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span>
    <span class="k">if</span> <span class="n">classname</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">"Linear"</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">in_features</span>
        <span class="n">y</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">classname</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">"EmbeddingBag"</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">initrange</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">initrange</span><span class="p">,</span> <span class="n">initrange</span><span class="p">)</span>
</code></pre></div></div>
<p>Definimos el modelo:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleMultiCategoricalClassifier</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">NUM_OF_CATEGORIES</span><span class="p">,</span>
                                         <span class="n">embed_dim</span><span class="o">=</span><span class="n">EMB_DIM</span><span class="p">,</span>
                                         <span class="n">hidden_dim</span><span class="o">=</span><span class="n">HIDDEN_DIM</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">weights_init_uniform_rule</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">SimpleSparseDenseDataLoader</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">training_sparse_features</span><span class="p">),</span>
                                         <span class="nb">list</span><span class="p">(</span><span class="n">training_labels_sparse</span><span class="p">))</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_batch</span>
<span class="p">)</span>
</code></pre></div></div>
<p>Creamos datos nuevos para validar la precisi√≥n del modelo:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_sparse_features</span> <span class="o">=</span> <span class="n">generate_sparse_features</span><span class="p">(</span><span class="n">TEST_SAMPLES</span><span class="p">,</span> <span class="n">NUM_OF_CATEGORIES</span><span class="p">)</span>
<span class="n">test_labels_sparse</span> <span class="o">=</span> <span class="p">[</span><span class="n">exact_function_to_approximate</span><span class="p">(</span><span class="n">row</span><span class="p">).</span><span class="n">value</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">test_sparse_features</span><span class="p">]</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">SimpleSparseDenseDataLoader</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">test_sparse_features</span><span class="p">),</span> <span class="nb">list</span><span class="p">(</span><span class="n">test_labels_sparse</span><span class="p">))</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">TEST_SAMPLES</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_batch</span>
<span class="p">)</span>
</code></pre></div></div>
<p>Creamos una funci√≥n para evaluar la precisi√≥n del modelo y evaluamos la precisi√≥n previa al entrenamiento:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="n">total_acc</span><span class="p">,</span> <span class="n">total_count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">offsets</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">predicted_label</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
            <span class="n">total_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted_label</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">label</span><span class="p">).</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total_count</span> <span class="o">+=</span> <span class="n">label</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_acc</span> <span class="o">/</span> <span class="n">total_count</span>

<span class="n">evaluate</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">)</span>
</code></pre></div></div>
<pre><code>0.2313
</code></pre>
<p>Entrenamos la red neuronal:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_loss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss_item</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">train_batch</span><span class="p">(</span><span class="n">offsets</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">avg_loss</span> <span class="o">+=</span> <span class="n">loss_item</span>

    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">avg_loss</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span>
    <span class="n">train_loss</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_loss</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s">|</span><span class="si">{</span><span class="n">EPOCHS</span><span class="si">}</span><span class="s"> Avg Loss: </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>
<p>Graficamos la funci√≥n de p√©rdida en cada epoch:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">train_loss</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Epochs"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Learning Curve"</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/82535439ed579a98a62c825c9448aaf98835fd01/multicat-learning-curve.png" alt="multicat_lc" /></p>
<p><em>Fig 3: Curva de aprendizaje de modelo para universo de usuario-p√°ginas.</em></p>
</div>
<p>Finalmente evaluamos el modelo ya entrenado:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">evaluate</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">)</span>
</code></pre></div></div>
<pre><code>0.9999
</code></pre>
<p>Observamos que la precisi√≥n aument√≥ de <code>~0.2</code> a <code>~0.99</code>. Estos n√∫meros pueden variar de ejecuci√≥n en ejecuci√≥n (debido a la aleatoriedad de la inicializaci√≥n de los pesos y de las pasadas por los <em>batches</em>).</p>
<h1 id="conclusiones-y-reflexiones">Conclusiones y Reflexiones</h1>
<ul>
<li>Existen problemas en los que tenemos variables discretas donde cada variable puede tomar 0 o m√°s valores (ejemplo: Lista de <code>IDs</code>).</li>
<li>Representar variables como m√°scaras de vectores se vuelve intratable con el aumento de categor√≠as, por lo que se necesitan representaciones m√°s eficientes para evitar procesar datos dispersos.</li>
<li>Una estrategia para representar multi-categor√≠as es utilizar dos tensores, uno para posiciones de cada registro y otro para los valores. Las categor√≠as pueden tener una representaci√≥n latente en forma de vectores (<em>embeddings</em>).</li>
<li>Se puede representar un registro como una combinaci√≥n interna de pesos de una red neuronal y con ello se puede crear un modelo para un problema de clasificaci√≥n dado.</li>
</ul>
<p>El notebook jupyter se encuentra disponible en Colab: <a href="https://colab.research.google.com/drive/1JdIDklTFa_82BS7d_hxLxt20ldwRc8zB?usp=sharing">Ejemplo de problema multi-categ√≥rico</a></p>]]></content><author><name>dpalmasan</name></author><category term="probability" /><category term="algorithms" /><category term="ai" /><summary type="html"><![CDATA[Introducci√≥n En algunos problemas donde nos interesa poder ‚Äúpredecir‚Äù una cierta clase para una entrada dada (por ejemplo usuario, negocio, entidad gen√©rica), podemos tener diversos tipos de variables, entre ellas variables categ√≥ricas. Una variable categ√≥rica es una variable discreta que puede tomar ciertos valores, que no necesariamente consideran un orden espec√≠fico (no hay noci√≥n de desigualdad). Generalmente los modelos basados en √°rboles de decisi√≥n no tienen problemas para lidiar con este tipo de variables, sin embargo los modelos num√©ricos necesitan un tratamiento especial para poder manipularlas. Por otro lado, las variables categ√≥ricas por lo general pueden tomar un s√≥lo valor (categor√≠a). Sin embargo, existen problemas m√°s interesantes. Por ejemplo, supongamos que tenemos IDs de p√°ginas visitadas como una variable. El lector podr√° notar, que esta no es una variable ordinal, y que este tipo de variables es Multi-Categr√≥rica ya que una entrada puede tener m√°s de una cateogor√≠a a la vez. En este art√≠culo, comentar√© c√≥mo lidiar con este tipo de variables, en particular, utilizando un modelo basado en redes neuronales. Tambi√©n mencionar√© representaciones eficientes de variables multi-categ√≥ricas y c√≥mo en la pr√°ctica se procesan este tipo de variables. Variables Categ√≥ricas Por lo general, los enfoques cl√°sicos para procesar este tipo de variables, consisten en seguir un esquema de One Hot Encoding, que consiste en codificar la variable como una m√°scara (vector de 0s y 1s), donde la dimensi√≥n de este vector ser√° N_categorias - 1. Por ejemplo, si tuvieramos la variable color que pudiese tomar los valores [celeste, gris, caf√©], se necesitar√≠a un vector binario de dimensi√≥n 2: $\text{celeste} = \left(1, 0\right)$ $\text{gris} = \left(0, 1\right)$ $\text{caf√©} = \left(0, 0\right)$ Se asume que un registro puede pertenecer a una sola categor√≠a, por lo que los vectores posibles consideran todas las combinaciones para dicha dimensi√≥n vectorial. El vector $\left(1, 1\right)$ no representa alg√∫n dato, debido al supuesto mencionado. Sin embargo, en la naturaleza y en la pr√°ctica existen otro tipo de variables. Estas son variables Multi-Categ√≥ricas, que consisten tambi√©n en variables discretas, pero que pueden tomar m√∫ltiples valores a la vez. Un ejemplo simple es un sistema de recomendaci√≥n de pel√≠culas. Por ejemplo, una persona puede haber visto ciertas pel√≠culas, las cuales al considerarlas como un todo, permiten aproximar, por ejemplo, los gustos de dicha persona. En este caso, la variable podr√≠an ser los t√≠tulos de las pel√≠culas vistas (ej. una lista de pel√≠culas). Problema de Juguete Supongamos que estamos en un universo, en el cual un usuario puede haber visitado una serie de p√°ginas webs, y nos interesa, a partir de dichas visitas, estimar las preferencias del usuario, para por ejemplo, recomendar productos/servicios basados en el contexto actual de dicho usuario. En este universo, cada usuario $u$ se representa como un vector de p√°ginas visitadas (por simplicidad, IDs enteras). Supongamos que tenemos las siguientes definiciones: Si $u$ visit√≥ $\left(1, 5, 11, 19\right)$ entonces $u$ tiene preferencias de contenido acerca de comida. Si $u$ visit√≥ $\left(2, 4, 8, 16\right)$ entonces $u$ tiene preferencias de contenido acerca de pel√≠culas. En cualquier otro caso, no sabemos con certeza las preferencias de $u$. Supongamos que existen un total de 200 posibles p√°ginas web a visitar. ¬øC√≥mo podr√≠amos representar a cada usuario $u$ para poder definir un modelo predictivo? Una forma ingenua de hacerlo, es utilizando un vector m√°scara, similar a lo que se hace para variables categ√≥ricas simples. Por ejemplo, si un usuario $u_i$ visit√≥ las p√°ginas [1, 3, 5] entonces su representaci√≥n ser√≠a: $u_i = \left(0, 1, 0, 1, 0, 1, 0, 0\ldots 0 \right)$ El lector atento ya puede ver cu√°l es el problema, pero para hacerlo m√°s claro, se obtiene un vector muy disperso (gran porcentaje de ceros), lo que por lo general trae problemas de estabilidad num√©rica (arrastre de error), adem√°s de uso ineficiente de memoria. ¬øQu√© tal si representaramos cada categor√≠a en un espacio vectorial de dimensi√≥n $K$ y adem√°s tuvi√©semos una lista $N$ donde $N$ es el n√∫mero de IDs posibles para las p√°ginas visitadas? Este tipo de representaci√≥n se conoce como embeddings. Por otro lado, el problema no es una simple reducci√≥n de dimensionalidad, tenemos que encontrar una forma m√°s inteligente de representar a los usuarios. Supongamos que tenemos el siguiente batch de usuarios: u1 = [1, 4, 9] u2 = [3, 2] u3 = [11, 17, 12, 19] No necesitamos utilizar todas las categor√≠as posibles para representar un usuario, en especial si posteriormente queremos agregar (aplicar pooling) la representaci√≥n vectorial de las p√°ginas. En este caso, podr√≠amos representar el batch como dos tensores, uno de offsets y otro de valores: values = [1, 4, 9, 3, 2, 11, 17, 12, 19] offsets = [0, 3, 5] Los valores, son simplemente todos los valores de los usuarios en el batch concatenados, y los offsets representan la posici√≥n donde comienza cada registro (en este caso usuario). Esta es una representaci√≥n m√°s eficiente que s√≥lo requiere la informaci√≥n a procesar. Finalmente, aplicando alg√∫n mecanismo de pooling podemos calcular el centro de masa, la suma vectorial, etc. del conjunto de vectores que representa al usuario, tal y como se muestra en la figura 1. Fig 1: Representaci√≥n de usuario y p√°ginas en espacio vectorial. Implementando un Clasificador de Usuarios basado en sus p√°ginas visitadas La red neuronal a ajustar ser√° una simple red neuronal de dos capas, y tendr√° una Bolsa de Embeddings (Embedding bag) para transformar la representaci√≥n del usuario un una representaci√≥n vectorial. Esta arquitectura se muestra en la figura 2. Fig 2: Arquitectura de Clasificador para universo de problema multi-categ√≥rico. Este universo lo simularemos en Python con Pytorch. Comencemos importando las bibliotecas a utilizar: import random from collections import Counter]]></summary></entry><entry><title type="html">Introducci√≥n al Aprendizaje Federado</title><link href="https://dpalmasan.github.io/website/probability/algorithms/ai/2024/04/11/federated-learning.html" rel="alternate" type="text/html" title="Introducci√≥n al Aprendizaje Federado" /><published>2024-04-11T15:09:00+00:00</published><updated>2024-04-11T15:09:00+00:00</updated><id>https://dpalmasan.github.io/website/probability/algorithms/ai/2024/04/11/federated-learning</id><content type="html" xml:base="https://dpalmasan.github.io/website/probability/algorithms/ai/2024/04/11/federated-learning.html"><![CDATA[<h1 id="introduccin">Introducci√≥n</h1>
<p>Un post para hablar de un tema interesante en aprendizaje autom√°tico (a.k.a <em>Machine Learning</em>). Seg√∫n la literatura, el aprendizaje federado (tambi√©n llamado aprendizaje colaborativo) es una t√©cnica de aprendizaje autom√°tico que entrena un algoritmo a trav√©s de una arquitectura descentralizada formada por m√∫ltiples dispositivos los cuales contienen sus propios datos locales y privados. En esencia es una t√©cnica para entrenar datos sin la necesidad de enviar los datos a un lugar central (por ejemplos servidores), con el fin de cumplir ciertas restricciones de privacidad.</p>
<p>En este post, simplemente dar√© un ejemplo de simulaci√≥n de esta t√©cnica, y lo abordaremos con un ejemplo simple.</p>
<h1 id="aprendizaje-federado">Aprendizaje Federado</h1>
<p>En la figura 1, se muestra una simplificaci√≥n sobre qu√© es el aprendizaje federado. En esencia, dado un universo de $N$ clientes (ej. dispositivos android), se escoge un conjunto de $K$ clientes. De esos $K$ clientes, se extraen datos locales y se ejecuta entrenamiento de ML. Luego, mediante alg√∫n canal se env√≠a la infomaci√≥n relevante a un agregador, en general los gradientes de cada paso de entrenamiento, y finalmente en el servidor, se ejecuta un paso de optimizaci√≥n.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/848b5f71dcca6f04032886f0255132dc85383cf7/Screenshot%25202024-04-11%2520at%252010.50.33%25E2%2580%25AFAM.png" alt="fl_high_level" /></p>
<p><em>Fig 1: Ilustraci√≥n del proceso de aprendizaje federado.</em></p>
</div>
<h2 id="simulando-aprendizaje-federado">Simulando Aprendizaje Federado</h2>
<p>Simularemos una situaci√≥n en que queremos ajustar un modelo para un problema de clasificaci√≥n binaria. El modelo a considerar ser√° una red neuronal de dos capas. Primero importamos los datos:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">copy</span>
</code></pre></div></div>
<p>Generamos un espacio sint√©tico, donde ya conocemos la funci√≥n $f$ que determina las clases en base a dos caracter√≠sticas:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Real weights
</span><span class="n">w</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>

<span class="c1"># Generate fake data between -1 and 1
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">x</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Labels based on the weights
</span><span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int8</span><span class="p">)</span>
</code></pre></div></div>
<p>Graficamos los datos y las clases, para asegurarnos que estamos definiendo el problema de forma correcta:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>

<span class="n">xbar</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ybar</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">xbar</span> <span class="o">*</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xbar</span><span class="p">,</span> <span class="n">ybar</span><span class="p">,</span> <span class="s">"--k"</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/f009d90093741af7d76ac37b4ba2ecf92d8c6da0/fl_simple_2f_model.png" alt="ex_fl_class" /></p>
<p><em>Fig 2: Ilustraci√≥n del problema de clasificaci√≥n del ejemplo.</em></p>
</div>
<p>Definimos la funci√≥n de hip√≥tesis y modelo a ajustar:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BCELoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s">"prediction"</span><span class="p">:</span> <span class="n">x</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">train_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)[</span><span class="s">"prediction"</span><span class="p">]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">{</span><span class="s">"loss"</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">())}</span>

    <span class="k">def</span> <span class="nf">eval_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)[</span><span class="s">"prediction"</span><span class="p">]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s">"loss"</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">())}</span>
</code></pre></div></div>
<p>Para simular los clientes, creamos una funci√≥n que carga datos sint√©ticos, los cuales no son visibles para el servidor simulado:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_data_batches</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">n_batches</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">batches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">):</span>
        <span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">x_test</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Labels based on the weights
</span>        <span class="n">labels_test</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int8</span><span class="p">)</span>
        <span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]).</span><span class="nb">float</span><span class="p">()</span>
        <span class="n">batches</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">x_test</span><span class="p">,</span> <span class="n">labels_test</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">batches</span>
</code></pre></div></div>
<p>Creamos una funci√≥n que ejecutar√° los pasos de entrenamiento dado un <em>batch</em> de datos:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">run_client_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">batches</span> <span class="o">=</span> <span class="n">get_data_batches</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">).</span><span class="nb">float</span><span class="p">().</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">model</span><span class="p">.</span><span class="n">train_batch</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))[</span><span class="s">"loss"</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div>
<p>En cada iteraci√≥n para actualizar el server, se debe ejecutar una ronda de entrenamiento que considera los $K$ clientes. En dicha ronda, se actualizan los modelos locales</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">run_round</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="n">new_model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
        <span class="n">new_model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">copy</span><span class="p">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">()))</span>
        <span class="n">new_model</span> <span class="o">=</span> <span class="n">run_client_batch</span><span class="p">(</span><span class="n">new_model</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">models</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">models</span>
</code></pre></div></div>
<p>Posteriormente, necesitamos una funci√≥n que agregue los gradientes de los modelos locales:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">aggregate_gradients</span><span class="p">(</span><span class="n">models</span><span class="p">):</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">m</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">:</span>
            <span class="n">grads</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()):</span>
            <span class="k">if</span> <span class="n">m</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="n">grads</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">m</span><span class="p">.</span><span class="n">grad</span>
    <span class="k">return</span> <span class="n">grads</span>
</code></pre></div></div>
<p>Ahora definamos el modelo y sus par√°metros. Tambi√©n definiremos el optimizador en el lado del servidor, para actualizar el modelo global:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>
<p>Ahora ejecutamos <code>100</code> rondas de entrenamiento, donde en cada ronda, se obtendr√°n datos de cada cliente (dispositivo simulado) se entrenar√°n los modelos locales, se enviar√°n los gradientes al servidor, estos se agregar√°n y se ejecutar√° un paso de entrenamiento del modelo global:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">accs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">rounds</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rounds</span><span class="p">):</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
    <span class="n">models</span> <span class="o">=</span> <span class="n">run_round</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">aggregate_gradients</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>
    <span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">x_test</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">labels_test</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int8</span><span class="p">)</span>
    <span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]).</span><span class="nb">float</span><span class="p">()</span>
    <span class="n">labels_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">labels_test</span><span class="p">).</span><span class="nb">float</span><span class="p">().</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
        <span class="n">accs</span><span class="p">.</span><span class="n">append</span><span class="p">(((</span><span class="n">y_pred</span><span class="p">.</span><span class="nb">round</span><span class="p">().</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)).</span><span class="nb">int</span><span class="p">()</span> <span class="o">==</span> <span class="n">labels_test</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)).</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels_test</span><span class="p">))</span>

    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># Update global model's gradients
</span>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()):</span>
        <span class="k">if</span> <span class="n">m</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">:</span>
            <span class="n">m</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="c1"># Eval current model performance
</span>    <span class="n">loss_item</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">eval_batch</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">labels_test</span><span class="p">)[</span><span class="s">"loss"</span><span class="p">]</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_item</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>
<p>Finalmente, graficamos las funciones de p√©rdida y la precisi√≥n del modelo en cada ronda:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loss</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Round"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Loss after each clients round"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">accs</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Round"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Accuracy after each clients round"</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/30d78bda8814ee4806283ab828959362d5627f52/loss.png" alt="loss_fl" /></p>
<p><em>Fig 3: P√©rdida en cada round de entrenamiento del ejemplo de FL.</em></p>
</div>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/30d78bda8814ee4806283ab828959362d5627f52/acc.png" alt="loss_fl" /></p>
<p><em>Fig 4: ‚ÄúAccuracy‚Äù en cada round de entrenamiento del ejemplo de FL.</em></p>
</div>
<h1 id="proyecto-opensource">Proyecto Opensource</h1>
<p>Dejo como dato un simulador de aprendizaje federado que es de c√≥digo abierto y mucho m√°s robusto que este ejemplo de juguete: <a href="https://github.com/facebookresearch/FLSim">FLSim</a>.</p>
<h1 id="final">Final</h1>
<p>Espero que haya gustado este mini-post. La idea es ser informativo de algunas t√©cnicas que pueden ser desconocidas para algunas personas. Abrazos‚Ä¶</p>]]></content><author><name>dpalmasan</name></author><category term="probability" /><category term="algorithms" /><category term="ai" /><summary type="html"><![CDATA[Introducci√≥n Un post para hablar de un tema interesante en aprendizaje autom√°tico (a.k.a Machine Learning). Seg√∫n la literatura, el aprendizaje federado (tambi√©n llamado aprendizaje colaborativo) es una t√©cnica de aprendizaje autom√°tico que entrena un algoritmo a trav√©s de una arquitectura descentralizada formada por m√∫ltiples dispositivos los cuales contienen sus propios datos locales y privados. En esencia es una t√©cnica para entrenar datos sin la necesidad de enviar los datos a un lugar central (por ejemplos servidores), con el fin de cumplir ciertas restricciones de privacidad. En este post, simplemente dar√© un ejemplo de simulaci√≥n de esta t√©cnica, y lo abordaremos con un ejemplo simple. Aprendizaje Federado En la figura 1, se muestra una simplificaci√≥n sobre qu√© es el aprendizaje federado. En esencia, dado un universo de $N$ clientes (ej. dispositivos android), se escoge un conjunto de $K$ clientes. De esos $K$ clientes, se extraen datos locales y se ejecuta entrenamiento de ML. Luego, mediante alg√∫n canal se env√≠a la infomaci√≥n relevante a un agregador, en general los gradientes de cada paso de entrenamiento, y finalmente en el servidor, se ejecuta un paso de optimizaci√≥n. Fig 1: Ilustraci√≥n del proceso de aprendizaje federado. Simulando Aprendizaje Federado Simularemos una situaci√≥n en que queremos ajustar un modelo para un problema de clasificaci√≥n binaria. El modelo a considerar ser√° una red neuronal de dos capas. Primero importamos los datos: import torch from torch import nn import matplotlib.pyplot as plt import numpy as np from io import BytesIO from typing import Tuple, Dict import random import copy Generamos un espacio sint√©tico, donde ya conocemos la funci√≥n $f$ que determina las clases en base a dos caracter√≠sticas: N = 1000]]></summary></entry><entry><title type="html">Reciclando un poquito m√°s de material viejo</title><link href="https://dpalmasan.github.io/website/probability/algorithms/ai/2024/03/08/mas-reciclaje.html" rel="alternate" type="text/html" title="Reciclando un poquito m√°s de material viejo" /><published>2024-03-08T00:00:00+00:00</published><updated>2024-03-08T00:00:00+00:00</updated><id>https://dpalmasan.github.io/website/probability/algorithms/ai/2024/03/08/mas-reciclaje</id><content type="html" xml:base="https://dpalmasan.github.io/website/probability/algorithms/ai/2024/03/08/mas-reciclaje.html"><![CDATA[<h1 id="introduccin">Introducci√≥n</h1>
<p>No es un post tan interesante, pero sigue la tem√°tica de reciclar material que alguna vez escrib√≠ y que a alguna persona le podr√° servir, aunque sea para pasar el ocio.</p>
<h1 id="reflexiones-iniciales">Reflexiones Iniciales</h1>
<p>Algunas personas me han preguntado consejos, como por ejemplo qu√© cursos tomar, qu√© hacer para mejorar en X/Y/Z. Aprovechar√© de responder, <em>no tengo la menor idea</em>. Supongo que buscando la literatura e intentando estudiar un poco, el espacio de b√∫squeda se puede reducir.</p>
<h1 id="aprendizaje-no-supervisado">Aprendizaje No Supervisado</h1>
<p>El t√©rmino aprendizaje no supervisado hace referencia a m√©todos que extraen informaci√≥n/patrones en los datos, sin necesidad de que estos hayan sido etiquetados por una persona (o datos en el cual la variable de respuesta es conocida). En mis m√°s recientes art√≠culos, he tocado un poco de aprendizaje supervisado: por ejemplo una regresi√≥n. En estos casos, el objetivo es construir un modelo para predecir una respuesta de inter√©s a partir de un conjunto de variables predictoras. En el caso de aprendizaje no supervisado, tambi√©n se construyen modelos de los datos, pero no hay distinci√≥n entre una variable de respuesta y las variables predictoras.</p>
<p>Algunos ejemplos de aprendizaje no supervisado:</p>
<ol>
<li>Agrupamiento o <em>clustering</em></li>
<li>Reducci√≥n dimensional</li>
</ol>
<p>En el caso de agrupamiento, se puede utilizar para identificar grupos en los datos. Por ejemplo, en una aplicaci√≥n web (ej. Amazon, Netflix), se puede tener un sistema de recomendaci√≥n basado en productos, o en usuarios similares (que pueden ser agrupados en base a ciertas caracter√≠sticas).</p>
<p>En el caso de reducci√≥n dimensional, el objetivo puede ser reducir las dimensiones de los datos a un conjunto de variables que sea m√°s manejable. Esta reducci√≥n de variables puede ser utilizada como entrada a modelos predictivos de clasificaci√≥n o regresi√≥n, por ejemplo. O por otro lado, queremos encontrar informaci√≥n subyacente (o latente) en los datos, que puede estar aproximada por m√∫ltiples predictores.</p>
<p>Como ejemplo personal, en mi proyecto open-source <code>TRUNAJOD</code> (<a href="https://github.com/dpalmasan/TRUNAJOD2.0/">Github TRUNAJOD</a>), para explicar al usuario variables de la complejidad textual, b√°sicamente se reduce una gran gama de predictores, en 5 predictores globales de complejidad textual, mediante una t√©cnica llamada an√°lisis factorial.</p>
<h2 id="dimensionalidad">Dimensionalidad</h2>
<p>Los modelos predictivos que hemos visto hasta ahora requieren como entrada un conjunto de datos, que consiste en una variable objetivo y una serie de predictores que idealmente se relacionan con esta variable. Esta serie de predictores, que usualmente son las columnas de nuestro conjunto de datos tabular, pueden ser vistos como vectores matem√°ticos, en donde cada dimension es un atributo (columna).</p>
<p>Podr√≠amos decir, que nuestro conjunto de datos representado por una ‚Äútabla‚Äù de $M\times N$, consiste en $M$ observaciones y $N$ atributos. Esta cantodad $N$ de atributos, es lo que se conoce como <strong>dimensionalidad</strong>. Entonces, en esencia, la <strong>dimensionalidad</strong> de nuestros datos, depender√° de la cantidad de atributos que consideremos por registro.</p>
<p>Es intuitivo pensar que al tener mayor cantidad de atributos (es decir, mayor dimensionalidad), en teor√≠a podr√≠amos tener un mejor modelo, ya que estar√≠amos entregando mayor cantidad de informaci√≥n al modelo predictivo. Sin embargo, al aumentar la dimensionalidad, pueden surgir ciertos inconvenientes:</p>
<ul>
<li>Imaginemos que tenemos $N$ atributos binarios, es decir, tenemos observaciones de la forma $(0, 1, 1, \ldots, 1)$. Para al menos lograr ver todas las combinaciones posibles, necesitariamos $2^N$ registros. Esto es intuitivo, si nuestro modelo requiere m√°s atributos, tendr√° m√°s variabilidad y en consecuencia requerir√° mayor cantidad de registros para poder ajustar un modelo robusto.</li>
<li>Los algoritmo para ajustar modelos tienen complejidades asint√≥ticas (c√≥mo var√≠a cierta m√©trica cuando el tama√±o de la entrada crece) que dependen de $M$ y $N$, por lo tanto, se volver√°n impr√°cticos de ajustar en algunos casos. En otros casos, y esto es intuitivo, el tiempo de ejecuci√≥n aumentar√° (m√°s informaci√≥n que procesar).</li>
<li>Si necesito adem√°s tomar alguna decisi√≥n respecto al an√°lisis de datos ¬øQu√© podr√≠a concluir de un modelo con cientos de atributos? Idealmente, debiese haber alguna forma de reducir la cantidad de dimensiones para facilitar la interpretaci√≥n (ya sea eliminando atributos poco relevantes, o combinando atributos que aproximan propiedades latentes o intr√≠nsecas similares.)</li>
<li>Algo no tan intuitivo, algunos algoritmos para ajuste de modelos padecen lo que se conoce como <strong>maldici√≥n de la dimensionalidad</strong>, es decir que a medida que aumenta la dimensionalidad, el rendimiento comienza a deteriorarse (por ejemplo, aumento en la varianza del error esperado).</li>
</ul>
<p>Existen diferentes manifestaciones de la maldici√≥n de la dimensionalidad, por lo que el lector puede investigar sobre ellas en caso de estar interesado en el tema. Supongamos que queremos implementar un algoritmo de clasificaci√≥n que se base en la similitud de registros para determinar la clase a la que pertenece el registro nuevo (por ejemplo, distancia entre vectores). Supongamos que los datos consisten en puntos distribu√≠dos en un hiper-cubo de dimensi√≥n $p$ (ejemplo: En dos dimensiones ser√≠a un cuadrado de lado 1, en 3 dimensiones un cubo de lado 1, y ya desde 4 dimensiones hacia arriba, no podemos visualizarlo jeje). Consideremos ahora una vecindad hiperc√∫bica de puntos al rededor de un registro objetivo (punto a clasificar), que captura una fracci√≥n $r$ de las observaciones.</p>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/curse_dim.png" alt="dim" /></p>
<p><em>Fig 1: Ilustraci√≥n de la maldici√≥n de la dimensionalidad.</em></p>
</div>
<p>Si quisieramos calcular el largo de los lados del hipercubo que contiene una fraci√≥n $r$ del volumen del total de datos, entonces el largo ser√≠a $e_p(r) = r^{1/p}$. Consideremos una dimensionalidad de 10 atributos ($p = 10$), entonces $e_{10}(0.01) = 0.63$ y $e_{10}(0.1) = 0.80$, cuando el rango total de cada entrada (valor de cada atributo) es s√≥lo 1 (hipercubo unitario). Esto quiere decir, que para calcular el $1\%$ o el $10\%$ de los datos para conformar un promedio local, debemos cubrir el $63\%$ o el $80\%$ del rango de cada variable de entrada. Por lo tanto, dichas vecindades, que en dimensionalidades peque√±as eran locales, dejan de ser locales en dimensionalidades altas. Reducir $r$ no ayudar√≠a, pues tendr√≠amos menos observaciones que promediar y por lo tanto la varianza de nuestro ajuste aumentar√≠a.</p>
<p>Por otro lado, se puede demostrar c√≥mo las m√©tricas de distancia se ven afectadas dependiendo de la cantidad de muestras y de la dimensionalidad. Sin embargo, para no complicar la matem√°tica, s√≥lo obtendremos la intuici√≥n de forma experimental. En el siguiente experimento, podemos observar qu√© pasar√≠a con las m√©tricas de distancia, a medida que aumenta dimensionalidad:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">cdist</span>


<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">"seaborn"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.dpi"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">200</span>


<span class="k">def</span> <span class="nf">get_avg_max_min_dist_ratio</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="s">"""Retorna proporcion entre maxima y minima distancia euclideana de un dataset.

    :param dataset: Conjunto de datos.
    :type dataset: pd.numpy.array
    :return: Promedio proporci√≥n de maxima/minima distancia de cada punto
    :rtype: float
    """</span>
    <span class="n">euclidean_dist</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>

    <span class="c1"># Encontrar minimos que no sean 0
</span>    <span class="n">min_dist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">euclidean_dist</span><span class="p">):</span>
        <span class="n">min_dist</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">amin</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">row</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">max_dist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">amax</span><span class="p">(</span><span class="n">euclidean_dist</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">max_dist</span><span class="o">/</span><span class="n">min_dist</span><span class="p">)</span>

<span class="c1"># Tama√±o de conjunto de datos
</span><span class="n">M</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">dimensionalities</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">avg_farthest_distances</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dimensionalities</span><span class="p">))</span>

<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dimensionalities</span><span class="p">):</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>

    <span class="c1"># Calcular distancia promedio maxima de puntos respecto a cualquier otro punto
</span>    <span class="n">avg_farthest_distances</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_avg_max_min_dist_ratio</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dimensionalities</span><span class="p">,</span> <span class="n">avg_farthest_distances</span><span class="p">,</span> <span class="s">"o"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Dimensionalidad"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s">"$Promedio\left(\frac\right)$"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Media de proporci√≥n entre distancia m√°xima y m√≠nima </span><span class="se">\n</span><span class="s">vs Dimensionalidad"</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/dim_dist.png" alt="dim-dist" /></p>
<p><em>Fig 2: Proporci√≥n de m√°xima distancia-m√≠nima distancia respecto a la cantidad de dimensiones.</em></p>
</div>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Dimensionalidad 5: </span><span class="si">{</span><span class="n">get_avg_max_min_dist_ratio</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="mi">5</span><span class="p">)))</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Dimensionalidad 500: </span><span class="si">{</span><span class="n">get_avg_max_min_dist_ratio</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="mi">500</span><span class="p">)))</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>
<pre><code>Dimensionalidad 5: 9.33633957667241
Dimensionalidad 500: 1.1948297526920728
</code></pre>
<p>Podemos observar por ejemplo, que en promedio, la proporci√≥n entre la m√°xima y m√≠nima distancia entre los puntos es <code>9.34</code> para <code>N = 5</code> y <code>1.19</code> para <code>N = 500</code>. Esto quiere decir que en el primer caso, el la distancia m√°xima puede llegar a ser hasta 10 veces mayor que la distancia m√≠nima para una dimensionalidad peque√±a, pero s√≥lo de un <code>19%</code> para una dimensionalidad de 500. Esto quiere decir, que en esencia, la informaci√≥n que nos entrega la distancia entre los puntos es casi nula, lo que podr√≠a afectar la varianza en las predicciones aunque el sesgo sea bajo; y por lo tanto, afectar el rendimiento del modelo predictivo.</p>
<h2 id="reduccin-de-dimensionalidad">Reducci√≥n de Dimensionalidad</h2>
<p>Como hemos visto hasta ahora, tener alta dimensionalidad puede causar algunos problemas:</p>
<ul>
<li>Dif√≠cil visualizaci√≥n de datos e interpretaci√≥n (ej. tener demasiadas variables predictoras)</li>
<li>Maldici√≥n de la dimensionalidad, la distancia entre puntos de un espacio tiende a ser insignificante en altas dimensiones.</li>
<li>Variabilidad y dispersi√≥n de datos. Por ejemplo cuando se trabaja con textos y consideramos la frecuencia de diferentes t√©rminos como datos, se trabaja con altas dimensionalidades que adem√°s, por la naturaleza del problema, tienden a generarse matrices dispersas. En estos casos la reducci√≥n dimensional permite reducir la variabilidad en los datos.</li>
<li>En algunos casos, es costoso computacionalmente en t√©rminos de rendimiento y uso de memoria, considerar una elevada cantidad de atributos. Por lo que, la reducci√≥n dimensional permite reducir estos problemas.</li>
</ul>
<p>Existen diferentes m√©todos de reducci√≥n dimensional, pero en este curso veremos en particular dos: <strong>An√°lisis de Componentes Principales</strong>, del ingl√©s PCA <em>Principal Component Analysis</em>, y <strong>An√°lisis Factorial</strong> (<em>Factor Analysis</em>). Estos m√©todos tienen algunos supuestos, que en algunos casos los hacen poco √∫tiles. Por ejemplo para visualizaci√≥n de datos, existen tambi√©n otros m√©todos como: Multidimensional Scaling (MDS), T-SNE, Non-Linear PCA, entre otros.</p>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/factor_vs_pca.png" alt="diff-dim" /></p>
<p><em>Fig 3: An√°lisis factorial vs PCA.</em></p>
</div>
<p>El enfoque de PCA para reducci√≥n dimensional es b√°sicamente crear una o m√°s variables a partir de un conjunto de variables medidas. Lo que hace es en esencia crear una combinaci√≥n lineal de estas nuevas variables, que idealmente reproducen las variables medidas. El enfoque en el an√°lisis factorial (utilizado com√∫nmente en psicometr√≠a) es modelar una variable latente/subyacente a partir de un conjunto de mediciones. En simples t√©rminos, los factores a obtener est√°n causando las respuestas en las variables medidas (y sus relaciones), es por ello, que en la figura 3 se muestra la flecha en sentido contrario al caso de PCA. El modelo factorial tambi√©n considera un t√©rmino de error, que en esencia toma la variabilidad que no puede ser explicada √∫nicamente por el factor. En las siguientes secciones se revisar√°n en mayor detalle estos m√©todos.</p>
<h2 id="anlisis-factorial">An√°lisis Factorial</h2>
<p>Los datos multi-variados usualmente son vistos como mediciones indirectas de propiedades subyacentes que no pueden ser medidas directamente. Algunos ejemplos:</p>
<ul>
<li>Pruebas educacionales y psicol√≥gicas utilizan cuestionarios, y usan las respuestas a estos cuestionarios para medir variables subyacentes como la inteligencia u otras habilidades mentales de los sujetos.</li>
<li>Los electroencefalogramas se utilizan para medir actividad neuronal en varias partes del cerebro, mediante mediciones de se√±ales electromagn√©ticas registradas por sensores ubicados en distintas posiciones de la cabeza del sujeto.</li>
<li>Los precios del mercado de acciones cambian constantemente a lo largo del tiempo, y reflejan varios factores que no est√°n medidos, tales como confianza en el mercado, influencias externas, y otras fuerzas que pueden ser dif√≠ciles de identificar o medir.</li>
<li>En caso particular del projecto <code>TRUNAJOD</code>, se intenta medir la complejidad del texto a partir de ciertas propiedades extr√≠nsicas de los mismos. ¬øSe puede medir complejidad textual directamente?</li>
</ul>
<p>El an√°lisis factorial es una t√©cnica estad√≠stica cl√°sica cuyo objetivo es identificar esta informaci√≥n latente (subyacente). Los an√°lisis  factoriales est√°n t√≠picamente ligados a distribuciones Gaussianas, lo que reduce su utilidad en algunos casos.</p>
<p>En esencia los factores est√°n asociados con m√∫ltiples variables observadas, que tienen ciertos patrones similares. Cada factor explica una cantidad particular de la varianza en los datos observados. Esto ayuda en la interpretaci√≥n de los datos, reduciendo la cantidad de variables:</p>
<p>$$X_i = \beta_{i0} + \beta_{i1} F_1 + \ldots \beta_{il}F_l + \varepsilon_i$$</p>
<p>Esto lo podemos visualizar como se muestra en la figura 4.</p>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/factores_ejemplo.png" alt="factorial" /></p>
<p><em>Fig 4: Ejemplo de factores.</em></p>
</div>
<p>Cabe destacar que existen dos tipos de an√°lisis factoriales: An√°lisis Factorial Exploratorio y An√°lisis Factorial Confirmatorio. El primero, se enfoca en explorar posibles relaciones, mientras que el segundo se enfoca en confirmarlas (teniendo obviamente una hip√≥tesis de la relaci√≥n de las variables).</p>
<p>Por otro lado, al hacer un an√°lisis factorial, se deben tener las siguientes consideraciones:</p>
<ul>
<li>No hay outliers en los datos.</li>
<li>El tama√±o de la muestra es mayor que la cantidad de factores a considerar.</li>
<li>No debe haber multi-colinealidad (una columna sea combinaci√≥n lineal de otra).</li>
<li>No existe homocedasticidad entre las variables.</li>
</ul>
<p>Analizaremos los datos de la encuesta del Centro de Estudios P√∫blicos realizada en Junio del 2003. Parte del conjunto de preguntas est√° asociado a preguntas sobre el nivel de confianza institucional. Para m√°s informaci√≥n pueden revisar este enlace: <a href="https://www.cepchile.cl/cep/encuestas-cep/encuestas-1998-2008/estudio-nacional-de-opinion-publica-junio-julio-2003">Estudio Nacional de Opini√≥n P√∫blica N¬∞45, Junio-Julio 2003</a>.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">factor_analyzer</span> <span class="k">as</span> <span class="n">factor</span>
<span class="kn">import</span> <span class="nn">missingno</span> <span class="k">as</span> <span class="n">msngo</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"datos/cep45.csv"</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>
<p>Extraeremos los datos de las preguntas (valores 8 y 9 significa que no hay informaci√≥n, ver detalle en el enlace mencionado):</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trust_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">regex</span><span class="o">=</span><span class="s">"p17_*"</span><span class="p">)</span>
<span class="n">trust_df</span> <span class="o">=</span> <span class="n">trust_df</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">{</span>
        <span class="s">"p17_a"</span><span class="p">:</span> <span class="s">"I.Catolica"</span><span class="p">,</span>
        <span class="s">"p17_b"</span><span class="p">:</span> <span class="s">"I.Evangelica"</span><span class="p">,</span>
        <span class="s">"p17_c"</span><span class="p">:</span> <span class="s">"FFAA"</span><span class="p">,</span>
        <span class="s">"p17_d"</span><span class="p">:</span> <span class="s">"Justicia"</span><span class="p">,</span>
        <span class="s">"p17_e"</span><span class="p">:</span> <span class="s">"Prensa"</span><span class="p">,</span>
        <span class="s">"p17_f"</span><span class="p">:</span> <span class="s">"Television"</span><span class="p">,</span>
        <span class="s">"p17_g"</span><span class="p">:</span><span class="s">"Sindicatos"</span><span class="p">,</span>
        <span class="s">"p17_h"</span><span class="p">:</span><span class="s">"Carabineros"</span><span class="p">,</span>
        <span class="s">"p17_i"</span><span class="p">:</span> <span class="s">"Gobierno"</span><span class="p">,</span>
        <span class="s">"p17_j"</span><span class="p">:</span> <span class="s">"PartidosPol"</span><span class="p">,</span>
        <span class="s">"p17_k"</span><span class="p">:</span> <span class="s">"Congreso"</span><span class="p">,</span>
        <span class="s">"p17_l"</span><span class="p">:</span><span class="s">"Empresas"</span><span class="p">,</span>
        <span class="s">"p17_m"</span><span class="p">:</span><span class="s">"Universidades"</span><span class="p">,</span>
        <span class="s">"p17_n"</span><span class="p">:</span><span class="s">"Radio"</span>
<span class="p">})</span>
</code></pre></div></div>
<p>Podemos explorar la base de datos para visualizar los registros incompletos:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">"seaborn"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.dpi"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">msngo</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">trust_df</span><span class="p">.</span><span class="n">replace</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">]))</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/missing.png" alt="cep" /></p>
<p><em>Fig 5: Visualizaci√≥n de datos incompletos.</em></p>
</div>
<p>Ahora analicemos las medias para cada pregunta:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trust_df</span><span class="p">.</span><span class="n">replace</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">trust_df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">means</span> <span class="o">=</span> <span class="n">trust_df</span><span class="p">.</span><span class="n">mean</span><span class="p">().</span><span class="n">sort_values</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">means</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">means</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="s">"bo"</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/means_atributos.png" alt="cep" /></p>
<p><em>Fig 6: Media de los atributos del ejemplo.</em></p>
</div>
<p>Mientras mayor sea el valor, significa que los encuestados conf√≠an menos en dicha entidad. Se puede observar por ejemplo que los encuestados conf√≠an menos en Partidos Pol√≠ticos, Sindicatos, Justicia y Congreso.</p>
<p>Ahora vamos a proceder a hacer un an√°lisis factorial. Sin embargo, antes de realizar este an√°lisis, se debe hacer una prueba de adecuaci√≥n, que b√°sicamente responde a la pregunta ¬øPodemos encontrar factores en nuestro conjunto de datos? Existen dos m√©todos (quiz√°s m√°s) para verificar la adecuaci√≥n de la muestra de datos para un an√°lisis factorial:</p>
<ul>
<li>Prueba de Bartlett</li>
<li>Prueba de Kaiser-Meyer-Olkin (desde ahora KMO)</li>
</ul>
<p>La prueba de Bartlett es una prueba de hip√≥tesis que verifica si existe correlaci√≥n entre las variables, y lo que hace es comparar la matriz de correlaci√≥n de la muestra con una matriz identidad (es decir, que no haya correlaci√≥n). Si la diferencia no es significativa, entonces no deber√≠amos aplicar an√°lisis factorial.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">factor_analyzer</span> <span class="k">as</span> <span class="n">fact</span>


<span class="n">chisq</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">fact</span><span class="p">.</span><span class="n">calculate_bartlett_sphericity</span><span class="p">(</span><span class="n">trust_df</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Chi-Cuadrado: </span><span class="si">{</span><span class="n">chisq</span><span class="si">}</span><span class="s">, p-value: </span><span class="si">{</span><span class="n">pvalue</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>
<pre><code>Chi-Cuadrado: 2897.0676232781584, p-value: 0.0
</code></pre>
<p>En este caso, el <code>p-value</code> es 0, por lo que podemos rechazar la hip√≥tesis de que no hay correlaci√≥n en los datos.</p>
<p>La prueba de <strong>Kaiser-Meyer-Olkin (KMO)</strong> miden la idoneidad de los datos para un an√°lisis factorial. Determina la adecuaci√≥n para cada variable observada y para el modelo completo. La prueba de KMO estima la proporci√≥n de varianza entre todas las variables observadas. Los valores de KMO est√°n entre 0 y 1. Un valor de KMO menor que 0.6 se considera inadecuado:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">kmo_all</span><span class="p">,</span> <span class="n">kmo_model</span> <span class="o">=</span> <span class="n">fact</span><span class="p">.</span><span class="n">calculate_kmo</span><span class="p">(</span><span class="n">trust_df</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Valor KMO para el modelo: </span><span class="si">{</span><span class="n">kmo_model</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>
<pre><code>Valor KMO para el modelo: 0.8299274694302806
</code></pre>
<p>En este caso obtenemos un valor de 0.83, lo que cumple el requisito para que el an√°lisis factorial sea adecuado. Ahora procederemos a realizar el an√°lisis factorial. Para escoger la cantidad de componentes, por lo general se hace un <em>scree plot</em> que b√°sicamente grafica cada uno de los valores propios (b√°sicamente la varianza explicada por cada factor de la varianza total), y se escogen los valores propios que sean mayores que 1:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">factorize</span> <span class="o">=</span> <span class="n">fact</span><span class="p">.</span><span class="n">FactorAnalyzer</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="s">"varimax"</span><span class="p">)</span>
<span class="n">factorize</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trust_df</span><span class="p">)</span>
<span class="n">factor_screeplot</span> <span class="o">=</span> <span class="n">factorize</span><span class="p">.</span><span class="n">get_eigenvalues</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">factor_screeplot</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">factor_screeplot</span><span class="p">,</span> <span class="s">"o-"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"tomato"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"N√∫mero de Factor"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Valores Propios"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Scree plot"</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/scree_plot.png" alt="valprop" /></p>
<p><em>Fig 7: Valores propios vs n√∫mero de factores.</em></p>
</div>
<p>De los resultados, podemos observar que podemos escoger 4 factores. Luego podemos ver las cargas de cada factor. Las cargas factoriales son b√°sicamente las relaciones de cada factor con cada variable:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">factorize</span> <span class="o">=</span> <span class="n">fact</span><span class="p">.</span><span class="n">FactorAnalyzer</span><span class="p">(</span><span class="n">n_factors</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s">"varimax"</span><span class="p">)</span>
<span class="n">factorize</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trust_df</span><span class="p">)</span>
<span class="n">factor_loadings</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">factorize</span><span class="p">.</span><span class="n">loadings_</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="n">trust_df</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s">"Factor 1"</span><span class="p">,</span> <span class="s">"Factor 2"</span><span class="p">,</span> <span class="s">"Factor 3"</span><span class="p">,</span> <span class="s">"Factor 4"</span><span class="p">))</span>
<span class="n">factor_loadings</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/factores.png" alt="fact" /></p>
</div>
<p>La matriz anterior es un poco complicada de interpretar. Por lo general, un criterio de corte para las cargas factoriales, es remover los factores cuya carga factorial sea menor que 0.4, haremos eso procesando los datos:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">factor_loadings</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">factor_loadings</span> <span class="o">&gt;=</span> <span class="mf">0.4</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/factores_filtrados.png" alt="factfilt" /></p>
</div>
<p>Observamos que el factor 4 fue descartado, debido a que el criterio de corte, consider√≥ que las cargas factoriales no estaban por sobre el umbral. En el resto de los factores, podemos hacer la siguiente interpretaci√≥n: El factor 1, corresponde a medidas relacionadas a como los encuestados ven al gobierno, y temas relacionados a la pol√≠tica. El factor 2 est√° relacionado con componentes de justicia, como las fuerzas armadas, justicia y carabineros. El factor 3 est√° relacionado a la confianza de la gente en los medios de prensa. Y las variables como iglesia Cat√≥lica, iglesia evang√©lica, sindicatos, empresas y universidades, no presentan carga significativa en ninguno de los factores. Probablemente por alta cantidad de datos incompletos, entre otras cosas.</p>
<p>Finalmente observamos que los tres factores  escogidos explican aproximadamente un 31% de la varianza en los datos:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">np</span><span class="p">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">factorize</span><span class="p">.</span><span class="n">get_factor_variance</span><span class="p">()),</span>
    <span class="n">index</span><span class="o">=</span><span class="p">(</span><span class="s">"SS Loadings"</span><span class="p">,</span> <span class="s">"Proportion Var"</span><span class="p">,</span> <span class="s">"Cumulative Var"</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s">"Factor 1"</span><span class="p">,</span> <span class="s">"Factor 2"</span><span class="p">,</span> <span class="s">"Factor 3"</span><span class="p">,</span> <span class="s">"Factor 4"</span><span class="p">))</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/factor_stats.png" alt="var" /></p>
</div>
<p>Observamos que el cuarto factor tiene un <code>SS loadings</code> bajo. El <code>SS loading</code> es la suma cuadr√°tica de las cargas factoriales. Generalmente se conservan los factores cuya suma cuadr√°tica de cargas sea mayor que 1 (consistente con el criterio de corte, ya que vemos que el factor 4, tiene un valor menor que uno).</p>
<p>Finalmente, por completitud, si quieren transformar las observaciones a factores, tienen que usar el m√©todo <code>transform</code> como sigue:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Nos dimos cuenta que solo son 3 factores los relevantes
</span><span class="n">factorize</span> <span class="o">=</span> <span class="n">fact</span><span class="p">.</span><span class="n">FactorAnalyzer</span><span class="p">(</span><span class="n">n_factors</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s">"varimax"</span><span class="p">)</span>
<span class="n">factorize</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trust_df</span><span class="p">)</span>
<span class="n">transformed_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">factorize</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trust_df</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s">"Factor 1"</span><span class="p">,</span> <span class="s">"Factor 2"</span><span class="p">,</span> <span class="s">"Factor 3"</span><span class="p">,</span> <span class="s">"Factor 4"</span><span class="p">))</span>
<span class="n">transformed_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/factores_transform.png" alt="trans" /></p>
</div>
<h2 id="anlisis-de-componentes-principales">An√°lisis de Componentes Principales</h2>
<p>Primero, es interesante entender qu√© significa componentes principales, y cu√°l es la intuici√≥n. En t√©rminos simples, las componentes principales ser√≠an ejes en donde ocurre la m√°xima variaci√≥n en los datos. En t√©rminos simples, podr√≠an verse las componentes principales como un cambio de sistema de coordenadas, o un cambio de vectores bases. Por ejemplo, una transformaci√≥n de un sistema de coordenadas a otro, podr√≠a ser como sigue:</p>
<p>$$
x_1 \begin{bmatrix} a \\\ c \end{bmatrix} + x_2 \begin{bmatrix} b \\\ d \end{bmatrix} =
\begin{bmatrix} ax_1 + bx_2 \\\ cx_1 + dx_2 \end{bmatrix}
$$</p>
<p>En este caso, los vectores en el lado izquierdo son vectores base, como referencia:</p>
<ul>
<li>$[a, c]$ ; $[b, d]$ son los vectores base</li>
<li>En el sistema cartesiano convencional, los vectores base son $[1, 0]$; $[0, 1]$ (o comunmente $x$ e $y$)</li>
</ul>
<p>No cualquier vector puede ser un vector base, algunos puntos clave:</p>
<ul>
<li>Los vectores base son los mismos para todos los registros de un conjunto de datos.</li>
<li>Los vectores base son ortonormales, es decir, perpendiculares entre s√≠ y con norma 1 (largo 1)</li>
<li>Finalmente, podemos representar cada registro del conjunto de datos como una combinaci√≥n lineal de sus vectores base.</li>
</ul>
<p>Lo anterior puede verse abstracto, por lo que tomemos un ejemplo:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">draw_vector</span><span class="p">(</span><span class="n">v0</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span> <span class="ow">or</span> <span class="n">plt</span><span class="p">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">arrowstyle</span><span class="o">=</span><span class="s">"-&gt;"</span><span class="p">,</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">shrinkA</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shrinkB</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s">"b"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="s">""</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v0</span><span class="p">,</span> <span class="n">arrowprops</span><span class="o">=</span><span class="n">arrowprops</span><span class="p">)</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">rng</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">rng</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">200</span><span class="p">)).</span><span class="n">T</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>


<span class="n">pca</span> <span class="o">=</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">"ro"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">length</span><span class="p">,</span> <span class="n">vector</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_</span><span class="p">,</span> <span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">):</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">vector</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">length</span><span class="p">)</span>
    <span class="n">draw_vector</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">mean_</span><span class="p">,</span> <span class="n">pca</span><span class="p">.</span><span class="n">mean_</span> <span class="o">+</span> <span class="n">v</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Ilustraci√≥n PCA"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"$x_1$"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"$x_2$"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"equal"</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/pca_ex1.png" alt="pca" /></p>
<p><em>Fig 8: Ilustraci√≥n de PCA.</em></p>
</div>
<p>Como se observa en la figura, el conjunto de datos llevarse a otro sistema de coordenadas considerando estos vectores base (para transformar los datos, basta simplemente con aplicar la transformaci√≥n lineal descrita). Podemos ver tambi√©n que cada eje se escoge en la direcci√≥n donde haya mayor variabilidad en los datos (varianza).</p>
<p>Un ejemplo de aplicaci√≥n de las componentes principales, es en el caso de reducci√≥n dimensional. Por ejemplo, podemos eliminar las componentes con menor cantidad de varianza, es decir, que explican menos la variabilidad en los datos, y en consecuencia, estar√≠amos proyectando el espacio dimensional en un espacio de menos dimensiones. Para ilustrar esto, consideremos el siguiente ejemplo:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>


<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="n">EJEMPLO_PCA_URL</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s">"https://gist.githubusercontent.com/dpalmasan/"</span>
    <span class="s">"1bba35979f1f284ddf7c8c540f60c66f/raw/"</span>
    <span class="s">"4a3fcf2f97fa2d85be69eedaa98b0ed6f46a3017/tetra.csv"</span>
<span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">EJEMPLO_PCA_URL</span><span class="p">)</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s">"3d"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"x"</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">"y"</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">"z"</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">"b"</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">"o"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"X"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Y"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s">"Z"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Tetera en 3D"</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">"ro"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"PC 1"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"PC 2"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Proyecci√≥n en 2D de la tetera (sombra)"</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/intuicion_pca.png" alt="pca" /></p>
<p><em>Fig 9: Intuici√≥n PCA.</em></p>
</div>
<p>En el ejemplo de la tetera, b√°sicamente tenemos un espacio dimensional de 3 dimensiones (<code>x, y, z</code>). Cuando aplicamos <code>PCA</code> y eliminamos una componente (la de menos variaci√≥n), b√°sicamente estamos calculando una proyecci√≥n de este espacio a un espacio de menor dimensi√≥n, intentando mantener la variabilidad del espacio original. Intuitivamente, en este caso particular, podr√≠a pensarse en cada componente principal como visualizar la ‚Äúsombra‚Äù de la tetera. Claro, que no estamos restringidos s√≥lo a espacios de 3 dimensiones, si no que tambi√©n podemos reducir espacios de cualquier dimension a uno de menor dimensionalidad, por ejemplo, para visualizar datos.</p>
<p>Consideremos los datos de <a href="https://github.com/datasets/world-wealth-and-income-database"><em>World Wealth and Income Database</em></a>.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"income-db.csv"</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s">"object"</span><span class="p">])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Transformar a dos dimensiones
</span><span class="n">X</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">income_greater</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"income"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"&gt;50K"</span>
<span class="n">income_leq</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"income"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"&lt;=50K"</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">income_greater</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">income_greater</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">"ro"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">income_leq</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">income_leq</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">"bo"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">((</span><span class="s">"income &gt; 50K"</span><span class="p">,</span> <span class="s">"income &lt;= 50K"</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"componente principal 1"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Componente principal 2"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Proyecci√≥n datos num√©ricos con PCA"</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/prueba_ejemplo.png" alt="ejpca" /></p>
<p><em>Fig 10: Ejemplo PCA.</em></p>
</div>
<p>Adem√°s, podemos ver c√≥mo impacta cada variable a cada nueva dimensi√≥n:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># El signo no importa, importa el signo relativo, podemos ver
# C√≥mo afecta cada componente a cada variable por ejemplo
</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s">"object"</span><span class="p">]).</span><span class="n">columns</span><span class="p">,</span>
    <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s">"PC-1"</span><span class="p">,</span> <span class="s">"PC-2"</span><span class="p">])</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/pca_corr.png" alt="pccomp" /></p>
</div>
<p>Debe considerarse tambi√©n, que usualmente se estandarizan los datos antes de aplicar PCA (por ejemplo normalizar, o llevar a una misma escala), por lo tanto, cuando lo apliquen, hagan este pre-procesamiento antes. Finalmente, y recapitulando hasta ahora, PCA es un maximizador de varianza, que proyecta los datos originales en las direcciones donde la varianza es m√°xima.</p>
<h3 id="ejemplo-datos-mnist-dgitos-manuscritos">Ejemplo Datos MNIST (d√≠gitos manuscritos)</h3>
<p>Finalmente, por completitud, haremos el ejemplo t√≠pico de analizar el <a href="https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits">conjunto de datos de reconocimiento de d√≠gitos</a>, que en esencia consiste en im√°genes de <code>8x8</code> donde cada imagen contiene un d√≠gito manuscrito.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>


<span class="n">digits</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span>
</code></pre></div></div>
<p>Por ejemplo, miremos un d√≠gito arbitrario:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>


<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">"seaborn"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.dpi"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">reshape</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">((</span><span class="sa">f</span><span class="s">"Imagen de </span><span class="si">{</span><span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s">"</span><span class="p">))</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/digito.png" alt="mnistsample" /></p>
<p><em>Fig 11: Muestra conjunto de datos de d√≠gitos.</em></p>
</div>
<p>Como los datos son de im√°genes de <code>8x8</code> p√≠xeles, b√°sicamente cada atributo es el valor del p√≠xel (en escala de grises), por lo tanto se tienen 64 atr√≠butos por registros. Dada la naturaleza del problema, <code>PCA</code> pareciera ser una buena opci√≥n para visualizar atributos similares en los d√≠gitos (por ejemplo curvatura, simetr√≠a, etc.):</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>


<span class="c1"># Contrario a lo que dice la lectura, PCA NO llama a StandardScaler por debajo
# Lo que s√≠ hace es centrar los datos pero NO los escala
# En este caso da igual, porque todos los atributos est√°n en la misma escala
</span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Dimensionalidad original: </span><span class="si">{</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Dimensionalidad despu√©s de PCA: </span><span class="si">{</span><span class="n">X_pca</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>
<p>En este caso, transformaremos a dos componentes, para hacer una visualizaci√≥n en 2D y dar un vistazo a si existe alguna relaci√≥n en los registros:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">edgecolor</span><span class="o">=</span><span class="s">"none"</span><span class="p">,</span>
    <span class="n">c</span><span class="o">=</span><span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
    <span class="n">cmap</span><span class="o">=</span><span class="s">"Set1"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"PC 1"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"PC 2"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"D√≠gitos proyectados a dos dimensiones"</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/pc_digits.png" alt="proj" /></p>
<p><em>Fig 12: Im√°genes de d√≠gitos manuscritos proyectados en un espacio bi-dimensional.</em></p>
</div>
<p>De la figura se pueden desprender algunas relaciones interesantes. Por ejemplo, el <code>4</code> est√° cerca del <code>9</code>, probablemente porque tienen formas similares, lo mismo el <code>3</code> con el <code>8</code>. Tambi√©n vemos que en general los d√≠gitos est√°n agrupados en distintas porciones del espacio.</p>
<p>Para elegir la cantidad de componentes, en general se debe tener un umbral de cu√°nta informaci√≥n de los datos se quiere retener, o en t√©rminos matem√°ticos, cu√°nta varianza explicada en los datos se quiere considerar. Para ello podemos hacer el siguiente gr√°fico:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pca_full</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pca_full</span><span class="p">.</span><span class="n">n_components_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">pca_full</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s">"Varianza por componente"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">pca_full</span><span class="p">.</span><span class="n">components_</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca_full</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">),</span>
<span class="n">color</span><span class="o">=</span><span class="s">"tomato"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Varianza acumulada"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Cantidad de Dimensiones"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Varianza"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/cumulative_var.png" alt="mnistsample" /></p>
<p><em>Fig 13: Varianza acumulada respecto a la cantidad de dimensiones.</em></p>
</div>
<p>En este caso, podemos ver que alrededor de 10 componentes deber√≠a ser suficiente para explicar gran cantidad de la varianza en los datos (entre 0.7 y 0.8). Esto tambi√©n se puede usar como ‚Äúfiltro‚Äù, ya que quiz√°s, mayores componentes est√©n ajustandose al ruido en los datos. Finalmente, visualicemos c√≥mo contribuye cada componente a cada d√≠gito:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">imshape</span><span class="p">,</span> <span class="n">fontsize</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="s">"""
    Funci√≥n auxiliar para agregar gr√°ficos a la figura.
    """</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">imshape</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">"nearest"</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"Blues"</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">title</span><span class="p">:</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fontsize</span><span class="p">)</span>



<span class="k">def</span> <span class="nf">plot_pca_components</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">coefs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">cmps</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                        <span class="n">imshape</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
                        <span class="n">show_mean</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="s">"""
    Graficar componentes PCA para dataset de d√≠gitos.
    """</span>
    <span class="k">if</span> <span class="n">coefs</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">coefs</span> <span class="o">=</span> <span class="n">x</span>

    <span class="k">if</span> <span class="n">cmps</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">cmps</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">coefs</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="c1"># Como datos fueron centrados en 0, para reconstruirlos en el espacio
</span>    <span class="c1"># Original, a cada componente se le agrega el promedio
</span>    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">mean</span>

    <span class="c1"># Ajustar ancho y alto de figura
</span>    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">1.2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">5</span> <span class="o">+</span> <span class="n">n_components</span><span class="p">),</span> <span class="mf">1.2</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Crear distribuci√≥n de figuras dentro del gr√°fico
</span>    <span class="n">grid</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">show_mean</span><span class="p">)</span> <span class="o">+</span> <span class="n">n_components</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Se grafica en las dos primeras filas y dos primeras columnas del plot
</span>    <span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">imshape</span><span class="p">,</span> <span class="n">fontsize</span><span class="p">,</span> <span class="s">"Original"</span><span class="p">)</span>
    <span class="n">approx</span> <span class="o">=</span> <span class="n">mean</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">show_mean</span><span class="p">:</span>
        <span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">mean</span><span class="p">,</span> <span class="n">imshape</span><span class="p">,</span> <span class="n">fontsize</span><span class="p">,</span> <span class="sa">r</span><span class="s">"$\mu$"</span><span class="p">)</span>
        <span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">approx</span><span class="p">,</span> <span class="n">imshape</span><span class="p">,</span> <span class="n">fontsize</span><span class="p">,</span> <span class="sa">r</span><span class="s">"$1 \cdot \mu$"</span><span class="p">)</span>
        <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_components</span><span class="p">):</span>
        <span class="c1"># Reconstruir imagen considerando i + 1 componentes componentes
</span>        <span class="n">approx</span> <span class="o">=</span> <span class="n">approx</span> <span class="o">+</span> <span class="n">coefs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">cmps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="n">counter</span><span class="p">,</span> <span class="n">cmps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">imshape</span><span class="p">,</span>
            <span class="n">fontsize</span><span class="p">,</span> <span class="sa">r</span><span class="s">"$c_{0}$"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="n">counter</span><span class="p">,</span> <span class="n">approx</span><span class="p">,</span> <span class="n">imshape</span><span class="p">,</span>
            <span class="n">fontsize</span><span class="p">,</span> <span class="sa">r</span><span class="s">"$ {0:.2f} \cdot c_{1}$"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">coefs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">show_mean</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plt</span><span class="p">.</span><span class="n">gca</span><span class="p">().</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">,</span> <span class="s">"$+$"</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s">"right"</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s">"bottom"</span><span class="p">,</span>
                          <span class="n">transform</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">gca</span><span class="p">().</span><span class="n">transAxes</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fontsize</span><span class="p">)</span>

    <span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span> <span class="n">approx</span><span class="p">,</span> <span class="n">imshape</span><span class="p">,</span> <span class="n">fontsize</span><span class="p">,</span> <span class="s">"Aproximaci√≥n"</span><span class="p">)</span>


<span class="n">pca_10</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">X_pca10</span> <span class="o">=</span> <span class="n">pca_10</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">plot_pca_components</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">X_pca10</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">pca_10</span><span class="p">.</span><span class="n">mean_</span><span class="p">,</span> <span class="n">pca_10</span><span class="p">.</span><span class="n">components_</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/components_digits.png" alt="comp" /></p>
<p><em>Fig 14: Ejemplo de diferentes componentes para un d√≠gito.</em></p>
</div>
<h1 id="agrupacin">Agrupaci√≥n</h1>
<p>Existen diversos escenarios en los cuales nos gustar√≠a agrupar los datos o encontrar grupos de datos, pues ello nos permitir√≠a encontrar informaci√≥n relevante acerca de la poblaci√≥n de datos de inter√©s. Algunos ejemplos:</p>
<ul>
<li>Segmentaci√≥n de clientes.</li>
<li>Sistemas de recomendaci√≥n.</li>
<li>Categorizaci√≥n de diversos grupos.</li>
<li>Segmentaci√≥n de Im√°genes.</li>
<li>Entre otros.</li>
</ul>
<p>Existen diversos m√©todos para agrupar datos, nosotros veremos uno bastante simple, que a√∫n a pesar de su simpleza, se utiliza en la pr√°cticas. El algorimo que veremos es conocido como <strong>K-means</strong>.</p>
<h2 id="clstering-k-means">Cl√∫stering K-Means</h2>
<p>La t√©cnica de cl√∫stering consiste en dividir los datos en diferentes grupos, donde los registros en cada grupo son similares entre s√≠. Un objetivo del cl√∫stering es encontrar grupos interesantes de datos. Estos grupos pueden ser utilizados directamente, analizados en profunidad, o ser usados como atributos en un algoritmo de clasificaci√≥n o de regresi√≥n.</p>
<p>El algoritmo <code>K-means</code> divide los datos en <code>K</code> cl√∫sters mediante la minimizaci√≥n de la suma de las distancias cuadr√°ticas de cada registro al centro de su cl√∫ster asignado. En general la serie de pasos a seguir es la siguiente:</p>
<ol>
<li>Comenzar con <code>K</code> centros aleatorios.</li>
<li>Asignar cada registro a un cl√∫ster en base a su distancia hacia el centro. Se asigna al cl√∫ster cuya distancia sea la m√≠nima respecto al centro.</li>
<li>Luego, calcular el ‚Äúcentro de masa‚Äù de cada cl√∫ster (recalcular centros)</li>
<li>Volver al paso 2, y repetir hasta satisfacer un criterio de detenci√≥n (por ejemplo que asignaci√≥n no cambie entre iteraciones).</li>
</ol>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">kmeans_clustering</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">maxit</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="s">"""Calcula cl√∫sters usando K-means.

    Este c√≥digo lo hice cuando era estudiante as√≠ que est√° feo, me
    disculpo por eso.

    :param X: Conjunto de datos
    :type X: np.array
    :param K: Cantidad de cl√∫sters, defaults to 5
    :type K: int, optional
    :param maxit: Cantidad m√°xima de iteraciones, defaults to 10
    :type maxit: int, optional
    :return: (cluster_assign, centroides, iteraciones)
    :rtype: tuple(np.array, np.array, int)
    """</span>
    <span class="c1"># Sample Size
</span>    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Inicializar vector de cl√∫sters
</span>    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>

    <span class="c1"># Inicializar centroides, se escogen al azar datos del conjunto de datos
</span>    <span class="n">mu</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span> <span class="p">:]</span>

    <span class="c1"># Asignar datos a cada cl√∫ster
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">kmin</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">min_dist</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">"Inf"</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">mu</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:])</span>
            <span class="k">if</span> <span class="n">dist</span> <span class="o">&lt;</span> <span class="n">min_dist</span><span class="p">:</span>
                <span class="n">min_dist</span> <span class="o">=</span> <span class="n">dist</span>
                <span class="n">kmin</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmin</span> <span class="o">+</span> <span class="mi">1</span>


    <span class="n">c_new</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">it</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># Iterar hasta m√°ximo de iteraciones o hasta que no haya cambios
</span>    <span class="c1"># en la asignaci√≥n de cl√∫sters
</span>    <span class="k">while</span> <span class="n">it</span> <span class="o">&lt;=</span> <span class="n">maxit</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">c</span> <span class="o">==</span> <span class="n">c_new</span><span class="p">):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">c_new</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="n">kmin</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">min_dist</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">"Inf"</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">mu</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:])</span>
                <span class="k">if</span> <span class="n">dist</span> <span class="o">&lt;</span> <span class="n">min_dist</span><span class="p">:</span>
                    <span class="n">min_dist</span> <span class="o">=</span> <span class="n">dist</span>
                    <span class="n">kmin</span> <span class="o">=</span> <span class="n">k</span>

            <span class="n">c_new</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmin</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># Actualizar centroides a "Centro de Masa"
</span>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">clusters</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">Xk</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">c_new</span> <span class="o">==</span> <span class="n">k</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">mu</span><span class="p">[</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span>  <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">Xk</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">Xk</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">it</span><span class="p">)</span>
</code></pre></div></div>
<p>Probemos con el m√≠tico conjunto de datos <a href="https://archive.ics.uci.edu/ml/datasets/iris"><em>Iris</em></a>. Este conjunto de datos b√°sicamente consiste en muestras de distintas plantas iris, donde los atributos medidos son b√°sicamente longitud y ancho de los s√©palos y p√©talos:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>


<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">"seaborn"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.dpi"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">iris_data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">"none"</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">"k"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/iris_data_unlabeled.png" alt="comp" /></p>
<p><em>Fig 15: Muestra de datos para el conjunto de datos Iris.</em></p>
</div>
<p>Si aplicaramos el algoritmo descrito con <code>K = 3</code>, ocurrir√≠a lo siguiente:</p>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/kmeans.gif" alt="comp" /></p>
<p><em>Fig 16: KMeans en acci√≥n.</em></p>
</div>
<p>Ahora intentemos darle una interpretaci√≥n a cada cl√∫ster. Consideremos las clases de plantas iris en el conjunto de datos. Para obtener los cl√∫sters, utilizaremos la implementaci√≥n de <code>sklearn</code>:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>


<span class="c1"># Configuramos 3 cl√∫sters, para seguir el ejemplo
</span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)])</span>

<span class="n">c1</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="mi">0</span>
<span class="n">c2</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="mi">1</span>
<span class="n">c3</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="mi">2</span>

<span class="n">setosa</span> <span class="o">=</span> <span class="n">iris_data</span><span class="p">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">0</span>
<span class="n">versicolor</span> <span class="o">=</span> <span class="n">iris_data</span><span class="p">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">1</span>
<span class="n">virginica</span> <span class="o">=</span> <span class="n">iris_data</span><span class="p">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">2</span>

<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">setosa</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">setosa</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">"none"</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">"r"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">versicolor</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">versicolor</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">"none"</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">"g"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">virginica</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">virginica</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">"none"</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">"b"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">target_names</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">c1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">c1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">"none"</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">"m"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">c2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">c2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">"none"</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">"c"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">c3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">c3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">"none"</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">"y"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">((</span><span class="s">"cl√∫ster 1"</span><span class="p">,</span> <span class="s">"cl√∫ster 2"</span><span class="p">,</span> <span class="s">"cl√∫ster 3"</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/clusters_int.png" alt="comp" /></p>
<p><em>Fig 17: Grupos originales vs Cl√∫sters encontrados por KMeans.</em></p>
</div>
<p>En este caso el cl√∫ster 1 se puede interpretar como las plantas de clase <code>setosa</code>, el cl√∫ster 2 como plantas de clase <code>virginica</code> y el cl√∫ster 3 como plantas de clase <code>versicolor</code>.</p>
<p>Observaci√≥n: En este caso no lo hicimos, ya que los atributos se encontraban en escalas similares, pero, por lo general, al trabajar con cl√∫stering, se prefiere escalar los datos, para que no haya un atributo que tenga prioridad sobre otros. Pregunta para pensar ¬øQu√© pasa cuando consideramos dimensionalidades altas (o a medida que aumentamos la dimensionalidad)?</p>
<p>Otro problema que vemos es que el valor <code>K</code> de la cantidad de cl√∫sters es una entrada al algoritmo. Existen m√©todos para escoger la cantidad de cl√∫sters, algunas veces funcionan otras no. Existen otras formas estad√≠sticas tambi√©n para encontrar la cantidad de cl√∫sters, sin embargo, siempre hay que tener en cuenta el contexto <em>¬ømejor considerando qu√©?</em>. Una forma de encontrar la cantidad de cl√∫sters es utilizando el <em>m√©todo del codo</em>, en el cual corremos varias veces el algoritmo variando la cantidad de cl√∫sters y vemos como var√≠a la <strong>inercia</strong> de los cl√∫sters (b√°sicamente la suma cuadr√°tica de las distancias de cada centroide a cada registro que pertenece al cl√∫ster). Escogemos la cantidad de cl√∫sters hasta que la variaci√≥n en la inercia sea casi despreciable (en el gr√°fico se ve como un codo). Probemos esto para el ejemplo:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">N</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">inertia</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">clusters</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
    <span class="n">inertia</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="n">clusters</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]).</span><span class="n">inertia_</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">inertia</span><span class="p">,</span> <span class="s">"o-"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"tomato"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Cantidad de clusters"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Inercia"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Elbow graph"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/elbow_graph.png" alt="elbow" /></p>
<p><em>Fig 18: Gr√°fico de codo.</em></p>
</div>
<p>Para este caso particular, podemos observar que <code>K = 3</code> es un buen valor para la cantidad de cl√∫sters.</p>
<p>Existen otros algoritmos que no requieren conocer la cantidad de cl√∫sters apriori (ejemplo: <code>DBScan</code>).</p>
<h3 id="ejemplo-de-compresin-de-imgenes">Ejemplo de compresi√≥n de im√°genes</h3>
<p>Como √∫ltimo ejemplo de <code>Kmeans</code>, utilic√©moslo para comprimir una imagen. Lo que haremos ser√° hacer cl√∫stering, y generar super-p√≠xeles, que ser√°n grupos de pixeles, donde su valor de color ser√° el centroide del cl√∫ster. Para el ejemplo, comprimiremos la imagen para que utilice 30 colores, pero ah√≠ pueden ir jugando, teniendo la intuici√≥n de que reducir la cantidad de colores, reducir√° la calidad de la compresi√≥n:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>


<span class="n">img</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"semana7/oso.jpg"</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">kmeans</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># Usar centroides para comprimir imagen
</span><span class="n">X_compressed</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span><span class="p">]</span>
<span class="n">X_compressed</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">X_compressed</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"uint8"</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>

<span class="c1"># Re-escalar a dimensiones de imagen original
</span><span class="n">X_compressed</span> <span class="o">=</span> <span class="n">X_compressed</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Im√°gen original"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_compressed</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Imagen comprimida con 30 colores"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">)</span>
</code></pre></div></div>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/oso_compresion.png" alt="oso1" />
<img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/oso_compresion2.png" alt="oso2" />
<img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/oso_compresion3.png" alt="oso3" /></p>
<p><em>Fig 19: Compresi√≥n de im√°genes considerando <code>K = 30</code> <code>K = 10</code> y <code>K = 5</code>.</em></p>
</div>
<h1 id="conclusiones">Conclusiones</h1>
<ul>
<li>Se introdujo el concepto de aprendizaje ‚Äúno supervisado‚Äù y algunos ejemplos como reducci√≥n dimensional y agrupamiento.</li>
<li>Se habl√≥ de los problemas que pueden surgir cuando se aumenta la dimensionalidad y se habl√≥ sobre la maldici√≥n de la dimensionalidad, donde se dieron algunas intuiciones.</li>
<li>Se revisaron t√©cnicas t√≠picas de reducci√≥n dimensional tales como an√°lisis factorial y an√°lisis de componentes principales y se mostraron ejemplos pr√°cticos.</li>
<li>Se introdujo un ejemplo de agrupamiento (cl√∫stering), se explic√≥ did√°cticamente en qu√© consiste el algoritmo <code>KMeans</code> y se mostr√≥ un ejemplo pr√°ctico de compresi√≥n de im√°genes.</li>
</ul>]]></content><author><name>dpalmasan</name></author><category term="probability" /><category term="algorithms" /><category term="ai" /><summary type="html"><![CDATA[Introducci√≥n No es un post tan interesante, pero sigue la tem√°tica de reciclar material que alguna vez escrib√≠ y que a alguna persona le podr√° servir, aunque sea para pasar el ocio. Reflexiones Iniciales Algunas personas me han preguntado consejos, como por ejemplo qu√© cursos tomar, qu√© hacer para mejorar en X/Y/Z. Aprovechar√© de responder, no tengo la menor idea. Supongo que buscando la literatura e intentando estudiar un poco, el espacio de b√∫squeda se puede reducir. Aprendizaje No Supervisado El t√©rmino aprendizaje no supervisado hace referencia a m√©todos que extraen informaci√≥n/patrones en los datos, sin necesidad de que estos hayan sido etiquetados por una persona (o datos en el cual la variable de respuesta es conocida). En mis m√°s recientes art√≠culos, he tocado un poco de aprendizaje supervisado: por ejemplo una regresi√≥n. En estos casos, el objetivo es construir un modelo para predecir una respuesta de inter√©s a partir de un conjunto de variables predictoras. En el caso de aprendizaje no supervisado, tambi√©n se construyen modelos de los datos, pero no hay distinci√≥n entre una variable de respuesta y las variables predictoras. Algunos ejemplos de aprendizaje no supervisado: Agrupamiento o clustering Reducci√≥n dimensional En el caso de agrupamiento, se puede utilizar para identificar grupos en los datos. Por ejemplo, en una aplicaci√≥n web (ej. Amazon, Netflix), se puede tener un sistema de recomendaci√≥n basado en productos, o en usuarios similares (que pueden ser agrupados en base a ciertas caracter√≠sticas). En el caso de reducci√≥n dimensional, el objetivo puede ser reducir las dimensiones de los datos a un conjunto de variables que sea m√°s manejable. Esta reducci√≥n de variables puede ser utilizada como entrada a modelos predictivos de clasificaci√≥n o regresi√≥n, por ejemplo. O por otro lado, queremos encontrar informaci√≥n subyacente (o latente) en los datos, que puede estar aproximada por m√∫ltiples predictores. Como ejemplo personal, en mi proyecto open-source TRUNAJOD (Github TRUNAJOD), para explicar al usuario variables de la complejidad textual, b√°sicamente se reduce una gran gama de predictores, en 5 predictores globales de complejidad textual, mediante una t√©cnica llamada an√°lisis factorial. Dimensionalidad Los modelos predictivos que hemos visto hasta ahora requieren como entrada un conjunto de datos, que consiste en una variable objetivo y una serie de predictores que idealmente se relacionan con esta variable. Esta serie de predictores, que usualmente son las columnas de nuestro conjunto de datos tabular, pueden ser vistos como vectores matem√°ticos, en donde cada dimension es un atributo (columna). Podr√≠amos decir, que nuestro conjunto de datos representado por una ‚Äútabla‚Äù de $M\times N$, consiste en $M$ observaciones y $N$ atributos. Esta cantodad $N$ de atributos, es lo que se conoce como dimensionalidad. Entonces, en esencia, la dimensionalidad de nuestros datos, depender√° de la cantidad de atributos que consideremos por registro. Es intuitivo pensar que al tener mayor cantidad de atributos (es decir, mayor dimensionalidad), en teor√≠a podr√≠amos tener un mejor modelo, ya que estar√≠amos entregando mayor cantidad de informaci√≥n al modelo predictivo. Sin embargo, al aumentar la dimensionalidad, pueden surgir ciertos inconvenientes: Imaginemos que tenemos $N$ atributos binarios, es decir, tenemos observaciones de la forma $(0, 1, 1, \ldots, 1)$. Para al menos lograr ver todas las combinaciones posibles, necesitariamos $2^N$ registros. Esto es intuitivo, si nuestro modelo requiere m√°s atributos, tendr√° m√°s variabilidad y en consecuencia requerir√° mayor cantidad de registros para poder ajustar un modelo robusto. Los algoritmo para ajustar modelos tienen complejidades asint√≥ticas (c√≥mo var√≠a cierta m√©trica cuando el tama√±o de la entrada crece) que dependen de $M$ y $N$, por lo tanto, se volver√°n impr√°cticos de ajustar en algunos casos. En otros casos, y esto es intuitivo, el tiempo de ejecuci√≥n aumentar√° (m√°s informaci√≥n que procesar). Si necesito adem√°s tomar alguna decisi√≥n respecto al an√°lisis de datos ¬øQu√© podr√≠a concluir de un modelo con cientos de atributos? Idealmente, debiese haber alguna forma de reducir la cantidad de dimensiones para facilitar la interpretaci√≥n (ya sea eliminando atributos poco relevantes, o combinando atributos que aproximan propiedades latentes o intr√≠nsecas similares.) Algo no tan intuitivo, algunos algoritmos para ajuste de modelos padecen lo que se conoce como maldici√≥n de la dimensionalidad, es decir que a medida que aumenta la dimensionalidad, el rendimiento comienza a deteriorarse (por ejemplo, aumento en la varianza del error esperado). Existen diferentes manifestaciones de la maldici√≥n de la dimensionalidad, por lo que el lector puede investigar sobre ellas en caso de estar interesado en el tema. Supongamos que queremos implementar un algoritmo de clasificaci√≥n que se base en la similitud de registros para determinar la clase a la que pertenece el registro nuevo (por ejemplo, distancia entre vectores). Supongamos que los datos consisten en puntos distribu√≠dos en un hiper-cubo de dimensi√≥n $p$ (ejemplo: En dos dimensiones ser√≠a un cuadrado de lado 1, en 3 dimensiones un cubo de lado 1, y ya desde 4 dimensiones hacia arriba, no podemos visualizarlo jeje). Consideremos ahora una vecindad hiperc√∫bica de puntos al rededor de un registro objetivo (punto a clasificar), que captura una fracci√≥n $r$ de las observaciones. Fig 1: Ilustraci√≥n de la maldici√≥n de la dimensionalidad. Si quisieramos calcular el largo de los lados del hipercubo que contiene una fraci√≥n $r$ del volumen del total de datos, entonces el largo ser√≠a $e_p(r) = r^{1/p}$. Consideremos una dimensionalidad de 10 atributos ($p = 10$), entonces $e_{10}(0.01) = 0.63$ y $e_{10}(0.1) = 0.80$, cuando el rango total de cada entrada (valor de cada atributo) es s√≥lo 1 (hipercubo unitario). Esto quiere decir, que para calcular el $1\%$ o el $10\%$ de los datos para conformar un promedio local, debemos cubrir el $63\%$ o el $80\%$ del rango de cada variable de entrada. Por lo tanto, dichas vecindades, que en dimensionalidades peque√±as eran locales, dejan de ser locales en dimensionalidades altas. Reducir $r$ no ayudar√≠a, pues tendr√≠amos menos observaciones que promediar y por lo tanto la varianza de nuestro ajuste aumentar√≠a. Por otro lado, se puede demostrar c√≥mo las m√©tricas de distancia se ven afectadas dependiendo de la cantidad de muestras y de la dimensionalidad. Sin embargo, para no complicar la matem√°tica, s√≥lo obtendremos la intuici√≥n de forma experimental. En el siguiente experimento, podemos observar qu√© pasar√≠a con las m√©tricas de distancia, a medida que aumenta dimensionalidad: import matplotlib.pyplot as plt import numpy as np import pandas as pd]]></summary></entry><entry><title type="html">Entendiendo los Modelos del Lenguaje (Parte 2)</title><link href="https://dpalmasan.github.io/website/probability/algorithms/ai/2024/03/05/modelos-lenguaje-parte2.html" rel="alternate" type="text/html" title="Entendiendo los Modelos del Lenguaje (Parte 2)" /><published>2024-03-05T00:00:00+00:00</published><updated>2024-03-05T00:00:00+00:00</updated><id>https://dpalmasan.github.io/website/probability/algorithms/ai/2024/03/05/modelos-lenguaje-parte2</id><content type="html" xml:base="https://dpalmasan.github.io/website/probability/algorithms/ai/2024/03/05/modelos-lenguaje-parte2.html"><![CDATA[<h1 id="introduccin">Introducci√≥n</h1>
<p>Este es el segundo art√≠culo de la serie que estoy escribiendo sobre modelos de lenguaje. En mi art√≠culo previo:</p>
<ul>
<li><a href="/website/probability/algorithms/ai/2024/03/03/modelos-lenguaje-parte1.html"><em>Entendiendo los Modelos del Lenguaje (Parte 1)</em></a></li>
</ul>
<p>expliqu√© en qu√© consiste un modelo de lenguaje y c√≥mo el problema a resolver es encontrar una distribuci√≥n conjunta $p(w_1, w_2, \ldots w_N)$ donde $N$ es el largo del contexto a considerar y $w_i$ es la i-√©sima palabra de un texto en esta distribuci√≥n.</p>
<p>En este art√≠culo, describir√© en t√©rminos b√°sicos, la soluci√≥n del estado del arte en este problema y adem√°s contar√© la historia de ChatGPT y los fundamentos de este sistema de IA.</p>
<h1 id="cmo-se-ementrenaem-chatgpt">¬øC√≥mo se ‚Äú<em>entrena</em>‚Äù ChatGPT?</h1>
<p>Cuando hablamos de ‚Äú<em>entrenamiento</em>‚Äù, nos referimos al proceso de encontrar $p(w_1, w_2, \ldots w_N)$. En general esto se hace construyendo un <strong>conjunto de datos</strong>. Como se describi√≥ en el art√≠culo previo, una forma de encontrar esta distribuci√≥n es mediante la <em>predicci√≥n de la siguiente palabra</em>, estrategia que consiste en encadenar m√∫ltiples probabilidades condicionales. Sin embargo, ChatGPT es un sistema que tiene otros ingredientes que permiten que funcione bien para diferentes tareas, como por ejemplo, tener una conversaci√≥n <em>coherente</em> con un ser humano (en algunos casos, puede no ser coherente). En la figura 1. se muestra la evoluci√≥n de ChatGPT.</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/23af0a877eb19a022e0682f565d7c9a9d6475a82/chat-gpt-history.png" alt="chat-gpt" /></p>
<p><em>Fig 1: ChatGPT y su evoluci√≥n en el tiempo.</em></p>
</div>
<p>El conjunto de datos para entrenar los modelos que utiliza el sistema, consisten en un repositorio de textos extra√≠dos desde m√∫ltiples fuentes en internet, como art√≠culos de Wikipedia, libros, y otras p√°ginas web. Finalmente, chatGPT es un sistema de IA que debe ejecutar las siguientes tareas:</p>
<ol>
<li>Predecir la palabra siguiente.</li>
<li>Aprender a seguir instrucciones.</li>
<li>Aprender a conversar.</li>
</ol>
<h2 id="predecir-la-siguiente-palabra">Predecir la siguiente palabra</h2>
<p>Como mencion√© en la parte 1 de esta serie, la tarea de aprender a predecir la siguiente palabra es una forma de estimar la distribuci√≥n de probabilidad que representa el modelo de lenguaje. Tomemos el siguiente ejemplo:</p>
<ul>
<li><em>El gato estaba sentado en el _____</em></li>
</ul>
<p>En este caso existen varias formas de completar el texto. Por ejemplo las palabras <em>sof√°</em>, <em>mat</em>, <em>techo</em>, <em>mes√≥n</em>, llevar√≠an a tener un texto coherente. Esto quiere decir, que el modelo podr√≠a <strong>entregar respuestas diferentes cuando se le consulta el mismo texto en m√∫ltiples ocasiones</strong>, pero cada una de estas respuestas tendr√° sentido en el contexto de la oraci√≥n. Si se provee mayor contexto, el modelo podr√° ser m√°s determinista/consistente en completar la oraci√≥n:</p>
<ul>
<li><em>Pedro busc√≥ por todos lados a su gato que estaba perdido. Busc√≥ en su casa, en el armario, incluso en el patio. Pedro decidi√≥ ir salir a la calle a buscar al felino, hasta que escuch√≥ un maullido que ven√≠a desde arriba. El gato estaba sentado en el techo.</em></li>
</ul>
<p>En este caso, el modelo elimin√≥ las palabras mat, sof√° y mes√≥n, ya que el contexto dado suger√≠a que dichas palabras no mantendr√≠an la coherencia del texto. Cabe destacar, que para lograr considerar el contexto, se requiere un modelo sofisticado, que sea capaz tener cierta noci√≥n sem√°ntica de las palabras y poner <strong>atenci√≥n</strong> a las palabras relevantes que entregan la informaci√≥n necesaria para hacer la mejor predicci√≥n. M√©todos tradicionales utilizando cadenas de Markov y N-Gramas en general no tienen estas caracter√≠sticas y consideraban a todas las palabras con igual importancia (hubo intentos de mejora, pero nada que pudiese considerar un contexto <em>largo</em>).</p>
<p>En el 2018 investigadores de OpenAI entrenaron un modelo que era capaz de realizar la tarea de predecir la siguiente palabra utilizando una arquitectura de <em>transformers</em>: <a href="https://arxiv.org/abs/1706.03762"><em>Attention Is All You Need</em></a>. El modelo utiliz√≥ una gran cantidad de datos extra√≠dos de distintas fuentes (ej. wikipedia, sitios web p√∫blicos, libros, etc). El modelo tambi√©n ten√≠a una gran cantidad de par√°metros, lo que le permiti√≥ aprender patrones que era imposible aprender con modelos menos complejos. Este modelo lo llamaron <strong>GPT</strong>, y era capaz de completar oraciones y p√°rrafos. En los siguientes dos a√±os, mejoraron este modelo agregando incluso m√°s par√°metros y datos de entrenamiento. Finalmente, lograron el modelo <strong>GPT-3</strong> que tiene 175 billones de par√°metros.</p>
<p>Cabe destacar que <strong>GPT-3</strong> no fue entrenado para alguna tarea espec√≠fica, otra que no sea predecir la siguiente palabra. Sin embargo, el tama√±o del conjunto de datos era masivamente grande que conten√≠a texto con varios ejemplos de tareas espec√≠ficas (sistemas pregunta-respuesta, resumir textos, traducci√≥n, etc.), lo que si se utilizaba una consulta/contexto apropiado, el modelo iba a ser capaz de resolver dicha tarea.</p>
<h2 id="aprendiendo-a-seguir-instrucciones">Aprendiendo a seguir instrucciones</h2>
<p>En la siguiente fase, el modelo GPT-3 fue entrenado para seguir instrucciones. Para lograr esto, se cre√≥ un conjunto de datos que contiene respuestas ‚Äúdeseables‚Äù generadas por humanos para una variada cantidad de instrucciones. Primeramente, el modelo fue entrenado de manera que aprendiera qu√© respuestas son deseables. Adem√°s, el modelo se fue ajustando con retroalimentaci√≥n humana para mejorar su entendimiento  sobre contenido deseable. Cada vez que el modelo generaba una respuesta satisfactoria, se le recompensaba con un puntaje positivo, en caso contrario hab√≠a una penalizaci√≥n. El modelo intentaba aprender c√≥mo generar contenido, de manera de maximizar los puntajes entregados por la retroalimentaci√≥n, aprendiendo lentamente a generar contenido de acuerdo a esta escala de deseabilidad. Este proceso de ense√±arle al modelo v√≠a retroalimentaci√≥n humana se conoce como <em>Aprendizaje por Refuerzo con Retroalimentaci√≥n Humana</em> (<em>RHLF: Reinforcement Learning with Human Feedback</em>). A este sistema le pusieron <strong>InstructGPT</strong>, y fue lanzado el 2022: <a href="https://arxiv.org/abs/2203.02155"><em>Training language models to follow instructions with human feedback</em></a>.</p>
<h2 id="aprendiendo-a-conversar">Aprendiendo a Conversar</h2>
<p>En la siguiente fase, que culmin√≥ en ChatGPT, OpenAI entren√≥ al modelo para que pudiese conversar de manera efectiva. El conjunto de datos inicial consisti√≥ en conversaciones donde los humanos actuaban en ambos roles: El usuario del <em>chatbot</em> con IA, y el chatbot (un humano ‚Äúactuaba‚Äù de ChatGPT). Este modelo tambi√©n fue mejorado v√≠a RLHF. El formato de di√°logo permiti√≥ al modelo a responder preguntas de seguimiento, admitir errores, y desafiar premisas incorrectas.</p>
<h2 id="emprompt-engineeringem-y-reflexiones">‚Äú<em>Prompt Engineering</em> y Reflexiones‚Äù</h2>
<p>Del uso masivo de ChatGPT, naci√≥ la ingenier√≠a de consultas ‚Äú<em>Prompt Engineering</em>‚Äù, la que consiste en realizar una interacci√≥n <em>adecuada</em> con el sistema de IA, de manera de obtener respuestas que satisfagan mejor o tengan la mejor ‚Äúdeseabilidad‚Äù posible. De aqu√≠ nacen super-usuarios del sistema, que logran optimizar al m√°ximo esta herramienta de IA. El gran problema, es el sensacionalismo que algunos creadores de contenido generan, sobre-estimando y exagerando las capacidades del modelo. Mi opini√≥n personal, no tengo nada en contra de que la gente utilice estas herramientas y comparta contenido que permita optimizar la experiencia de usuario. Es m√°s, yo tambi√©n utilizo alg√∫n modelo GPT para ayudarme a ser m√°s eficiente para escribir c√≥digo. Sin embargo, lo que me molesta es que existan creadores de contenido que divulgan informaci√≥n falsa/enga√±osa. Hay que ser responsables con el uso de la tecnolog√≠a.</p>
<p>Finalmente, recordar que ChatGPT (y cualquier otro modelo similar), es simplemente un modelo que intenta estimar la distribuci√≥n $p(w_1, w_2, \ldots w_N)$ y que gracias a tener un gran repositorio de textos para <em>‚Äúaprender‚Äù</em>, se logr√≥ re-ajustar para que pudiese resolver m√°s tareas que predecir la siguiente palabra. Pero no debemos olvidar que es un simple muestreo de una distribuci√≥n de probabilidad. Por el momento, estamos lejos de <em>ser reemplazados</em> por IA. Es m√°s, puede darse que algunos trabajos queden obsoletos, sin embargo pueden nacer nuevos empleos. Lo mismo ha ocurrido con varias revoluciones tecnol√≥gicas.</p>
<h2 id="bonus-qu-es-el-significado">Bonus: ¬øQu√© es el significado?</h2>
<p>Al ver el lenguaje en t√©rminos de l√≥gica se vislumbra el significado de ciertos tipos de expresiones justific√°ndolas en la validez de los argumentos. Un argumento v√°lido es un argumento donde si las premisas son verdaderas, entonces las conclusiones tambi√©n son verdaderas. El significado de ciertas expresiones en el lengaje natural juegan un rol crucial en contribuir a la validez de los argumentos y as√≠, uno puede representar su significado modelando dicha validez.</p>
<p>Por ejemplo, consideremos el siguiente argumento, que es un silogismo (Arist√≥teles) cl√°sico:</p>
<p>$$
\begin{array} {c}
\text{Todo hombre es mortal} \\
\text{S√≥crates es hombre} \\
\hline
\text{S√≥crates es mortal}
\end{array}
$$</p>
<p>Cabe destacar que matem√°ticamente, estos axiomas se pueden f√≥rmular con <strong>L√≥gica de Primer Orden</strong>:</p>
<p>$$
\begin{array} {c}
\forall x (Hombre(x) \rightarrow Mortal(x)) \\
Hombre(s) \\
\hline
Mortal(s)
\end{array}
$$</p>
<p>En este caso $\forall$ es un cuantificador <em>universal</em>, $x$ es una entidad (u objeto), y $Hombre$ y $Mortal$ son predicados l√≥gicos. En este caso se lee que cualquier objeto $x$ que tenga el predicado $Hombre(x)$ implica que tendr√° tambi√©n el predicado $Mortal(x)$. Consideremos los siguientes axiomas:</p>
<ol>
<li>Todos los ni√±os aman al Viejo Pascuero</li>
<li>Todos los ni√±os que aman al Viejo Pascuero, aman a cualquier reno</li>
<li>Rodolfo es un reno y Rodolfo tiene la nariz Roja</li>
<li>Cualquiera que tenga la nariz roja es extra√±o o es un payaso</li>
<li>Ning√∫n reno es un payaso</li>
<li>Juan no ama cualquier cosa que sea extra√±a</li>
</ol>
<p>¬øPodemos concluir que Juan no es un ni√±o?</p>
<p>Una posible respuesta de ChatGPT:</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/874f82dc54fdb39bcca26fd04c9a4e6c99702059/logic-gpt.png" alt="logic-on-chatgpt" /></p>
<p><em>Fig 2: ChatGPT y su respuesta a los axiomas de navidad.</em></p>
</div>
<p>Sin embargo, si transformamos los axiomas a l√≥gica de primer √≥rden:</p>
<ol>
<li>$\forall x \text{ ni√±o}(x) \rightarrow ama(x, vp)$</li>
<li>$\forall x, y (\text{ni√±o}(x) \land reno(y) \land ama(x, vp) \rightarrow ama(x, y))$</li>
<li>$reno(r) \land nariz\ roja(r)$</li>
<li>$\forall x (nariz\ roja(x) \rightarrow \text{extra√±o}(x) \lor payaso(x))$</li>
<li>$\neg \exists x(reno(x) \land payaso(x))$</li>
<li>$\forall x (\text{extra√±o}(x) \rightarrow \neg ama(j, x))$</li>
<li>Conclusi√≥n: $\neg \text{ni√±o}(j)$</li>
</ol>
<p>Supongamos que Juan fuese ni√±o:</p>
<ul>
<li>Si juan fuera un ni√±o, amar√≠a al Viejo pascuero por axioma <code>1.</code></li>
<li>Si Juan fuera un ni√±o, entonces juan amar√≠a al reno Rodolfo, por axioma <code>2.</code>, ya que juan ama al Viejo Pascuero</li>
<li>Rodolfo tiene la nariz roja, por lo tanto o es extra√±o o es un payaso, por axioma <code>4.</code></li>
<li>Rodolfo no es un payaso ya que no existe una entidad que sea reno y payaso a la vez por axioma <code>5.</code></li>
<li>Rodolfo es extra√±o por axioma <code>4.</code></li>
<li>Juan no ama a nada que sea extra√±o, pero rodolfo es extra√±o, por lo que juan no amar√≠a a rodolfo, axioma <code>6.</code></li>
<li>Por lo tanto hay una contradicci√≥n y Juan no puede ser un ni√±o.</li>
</ul>
<p>Recordemos que ChatGPT no es determinista, por lo que en algunos casos podr√≠a dar la respuesta correcta (ya que este es un ejemplo conocido). Sin embargo, en este caso podemos notar que ChatGPT llega a una conclusi√≥n err√≥nea, por lo que no est√° realmente razonando.</p>
<h1 id="conclusiones">Conclusiones</h1>
<ul>
<li>ChatGPT comenz√≥ con un modelo GPT entrenado para predicci√≥n de la siguiente palabra.</li>
<li>El modelo fue entrenado con una cantidad masiva de datos, por lo que indirectamente pod√≠a resolver algunas tareas d√°ndole una consulta/contexto indicado.</li>
<li>ChatGPT utiliza RLHF para aprender a interactuar con humanos.</li>
<li>ChatGPT no est√° razonando l√≥gicamente y no entiende el significado de los textos.</li>
<li>Estamos lejos de ser reemplazados por IA, sin embargo, existen Super-usuarios o <em>power users</em> que le pueden sacar m√°ximo provecho a este tipo de sistemas con IA.</li>
</ul>]]></content><author><name>dpalmasan</name></author><category term="probability" /><category term="algorithms" /><category term="ai" /><summary type="html"><![CDATA[Introducci√≥n Este es el segundo art√≠culo de la serie que estoy escribiendo sobre modelos de lenguaje. En mi art√≠culo previo: Entendiendo los Modelos del Lenguaje (Parte 1) expliqu√© en qu√© consiste un modelo de lenguaje y c√≥mo el problema a resolver es encontrar una distribuci√≥n conjunta $p(w_1, w_2, \ldots w_N)$ donde $N$ es el largo del contexto a considerar y $w_i$ es la i-√©sima palabra de un texto en esta distribuci√≥n. En este art√≠culo, describir√© en t√©rminos b√°sicos, la soluci√≥n del estado del arte en este problema y adem√°s contar√© la historia de ChatGPT y los fundamentos de este sistema de IA. ¬øC√≥mo se ‚Äúentrena‚Äù ChatGPT? Cuando hablamos de ‚Äúentrenamiento‚Äù, nos referimos al proceso de encontrar $p(w_1, w_2, \ldots w_N)$. En general esto se hace construyendo un conjunto de datos. Como se describi√≥ en el art√≠culo previo, una forma de encontrar esta distribuci√≥n es mediante la predicci√≥n de la siguiente palabra, estrategia que consiste en encadenar m√∫ltiples probabilidades condicionales. Sin embargo, ChatGPT es un sistema que tiene otros ingredientes que permiten que funcione bien para diferentes tareas, como por ejemplo, tener una conversaci√≥n coherente con un ser humano (en algunos casos, puede no ser coherente). En la figura 1. se muestra la evoluci√≥n de ChatGPT. Fig 1: ChatGPT y su evoluci√≥n en el tiempo. El conjunto de datos para entrenar los modelos que utiliza el sistema, consisten en un repositorio de textos extra√≠dos desde m√∫ltiples fuentes en internet, como art√≠culos de Wikipedia, libros, y otras p√°ginas web. Finalmente, chatGPT es un sistema de IA que debe ejecutar las siguientes tareas: Predecir la palabra siguiente. Aprender a seguir instrucciones. Aprender a conversar. Predecir la siguiente palabra Como mencion√© en la parte 1 de esta serie, la tarea de aprender a predecir la siguiente palabra es una forma de estimar la distribuci√≥n de probabilidad que representa el modelo de lenguaje. Tomemos el siguiente ejemplo: El gato estaba sentado en el _____ En este caso existen varias formas de completar el texto. Por ejemplo las palabras sof√°, mat, techo, mes√≥n, llevar√≠an a tener un texto coherente. Esto quiere decir, que el modelo podr√≠a entregar respuestas diferentes cuando se le consulta el mismo texto en m√∫ltiples ocasiones, pero cada una de estas respuestas tendr√° sentido en el contexto de la oraci√≥n. Si se provee mayor contexto, el modelo podr√° ser m√°s determinista/consistente en completar la oraci√≥n: Pedro busc√≥ por todos lados a su gato que estaba perdido. Busc√≥ en su casa, en el armario, incluso en el patio. Pedro decidi√≥ ir salir a la calle a buscar al felino, hasta que escuch√≥ un maullido que ven√≠a desde arriba. El gato estaba sentado en el techo. En este caso, el modelo elimin√≥ las palabras mat, sof√° y mes√≥n, ya que el contexto dado suger√≠a que dichas palabras no mantendr√≠an la coherencia del texto. Cabe destacar, que para lograr considerar el contexto, se requiere un modelo sofisticado, que sea capaz tener cierta noci√≥n sem√°ntica de las palabras y poner atenci√≥n a las palabras relevantes que entregan la informaci√≥n necesaria para hacer la mejor predicci√≥n. M√©todos tradicionales utilizando cadenas de Markov y N-Gramas en general no tienen estas caracter√≠sticas y consideraban a todas las palabras con igual importancia (hubo intentos de mejora, pero nada que pudiese considerar un contexto largo). En el 2018 investigadores de OpenAI entrenaron un modelo que era capaz de realizar la tarea de predecir la siguiente palabra utilizando una arquitectura de transformers: Attention Is All You Need. El modelo utiliz√≥ una gran cantidad de datos extra√≠dos de distintas fuentes (ej. wikipedia, sitios web p√∫blicos, libros, etc). El modelo tambi√©n ten√≠a una gran cantidad de par√°metros, lo que le permiti√≥ aprender patrones que era imposible aprender con modelos menos complejos. Este modelo lo llamaron GPT, y era capaz de completar oraciones y p√°rrafos. En los siguientes dos a√±os, mejoraron este modelo agregando incluso m√°s par√°metros y datos de entrenamiento. Finalmente, lograron el modelo GPT-3 que tiene 175 billones de par√°metros. Cabe destacar que GPT-3 no fue entrenado para alguna tarea espec√≠fica, otra que no sea predecir la siguiente palabra. Sin embargo, el tama√±o del conjunto de datos era masivamente grande que conten√≠a texto con varios ejemplos de tareas espec√≠ficas (sistemas pregunta-respuesta, resumir textos, traducci√≥n, etc.), lo que si se utilizaba una consulta/contexto apropiado, el modelo iba a ser capaz de resolver dicha tarea. Aprendiendo a seguir instrucciones En la siguiente fase, el modelo GPT-3 fue entrenado para seguir instrucciones. Para lograr esto, se cre√≥ un conjunto de datos que contiene respuestas ‚Äúdeseables‚Äù generadas por humanos para una variada cantidad de instrucciones. Primeramente, el modelo fue entrenado de manera que aprendiera qu√© respuestas son deseables. Adem√°s, el modelo se fue ajustando con retroalimentaci√≥n humana para mejorar su entendimiento sobre contenido deseable. Cada vez que el modelo generaba una respuesta satisfactoria, se le recompensaba con un puntaje positivo, en caso contrario hab√≠a una penalizaci√≥n. El modelo intentaba aprender c√≥mo generar contenido, de manera de maximizar los puntajes entregados por la retroalimentaci√≥n, aprendiendo lentamente a generar contenido de acuerdo a esta escala de deseabilidad. Este proceso de ense√±arle al modelo v√≠a retroalimentaci√≥n humana se conoce como Aprendizaje por Refuerzo con Retroalimentaci√≥n Humana (RHLF: Reinforcement Learning with Human Feedback). A este sistema le pusieron InstructGPT, y fue lanzado el 2022: Training language models to follow instructions with human feedback. Aprendiendo a Conversar En la siguiente fase, que culmin√≥ en ChatGPT, OpenAI entren√≥ al modelo para que pudiese conversar de manera efectiva. El conjunto de datos inicial consisti√≥ en conversaciones donde los humanos actuaban en ambos roles: El usuario del chatbot con IA, y el chatbot (un humano ‚Äúactuaba‚Äù de ChatGPT). Este modelo tambi√©n fue mejorado v√≠a RLHF. El formato de di√°logo permiti√≥ al modelo a responder preguntas de seguimiento, admitir errores, y desafiar premisas incorrectas. ‚ÄúPrompt Engineering y Reflexiones‚Äù Del uso masivo de ChatGPT, naci√≥ la ingenier√≠a de consultas ‚ÄúPrompt Engineering‚Äù, la que consiste en realizar una interacci√≥n adecuada con el sistema de IA, de manera de obtener respuestas que satisfagan mejor o tengan la mejor ‚Äúdeseabilidad‚Äù posible. De aqu√≠ nacen super-usuarios del sistema, que logran optimizar al m√°ximo esta herramienta de IA. El gran problema, es el sensacionalismo que algunos creadores de contenido generan, sobre-estimando y exagerando las capacidades del modelo. Mi opini√≥n personal, no tengo nada en contra de que la gente utilice estas herramientas y comparta contenido que permita optimizar la experiencia de usuario. Es m√°s, yo tambi√©n utilizo alg√∫n modelo GPT para ayudarme a ser m√°s eficiente para escribir c√≥digo. Sin embargo, lo que me molesta es que existan creadores de contenido que divulgan informaci√≥n falsa/enga√±osa. Hay que ser responsables con el uso de la tecnolog√≠a. Finalmente, recordar que ChatGPT (y cualquier otro modelo similar), es simplemente un modelo que intenta estimar la distribuci√≥n $p(w_1, w_2, \ldots w_N)$ y que gracias a tener un gran repositorio de textos para ‚Äúaprender‚Äù, se logr√≥ re-ajustar para que pudiese resolver m√°s tareas que predecir la siguiente palabra. Pero no debemos olvidar que es un simple muestreo de una distribuci√≥n de probabilidad. Por el momento, estamos lejos de ser reemplazados por IA. Es m√°s, puede darse que algunos trabajos queden obsoletos, sin embargo pueden nacer nuevos empleos. Lo mismo ha ocurrido con varias revoluciones tecnol√≥gicas. Bonus: ¬øQu√© es el significado? Al ver el lenguaje en t√©rminos de l√≥gica se vislumbra el significado de ciertos tipos de expresiones justific√°ndolas en la validez de los argumentos. Un argumento v√°lido es un argumento donde si las premisas son verdaderas, entonces las conclusiones tambi√©n son verdaderas. El significado de ciertas expresiones en el lengaje natural juegan un rol crucial en contribuir a la validez de los argumentos y as√≠, uno puede representar su significado modelando dicha validez. Por ejemplo, consideremos el siguiente argumento, que es un silogismo (Arist√≥teles) cl√°sico: $$ \begin{array} {c} \text{Todo hombre es mortal} \\ \text{S√≥crates es hombre} \\ \hline \text{S√≥crates es mortal} \end{array} $$ Cabe destacar que matem√°ticamente, estos axiomas se pueden f√≥rmular con L√≥gica de Primer Orden: $$ \begin{array} {c} \forall x (Hombre(x) \rightarrow Mortal(x)) \\ Hombre(s) \\ \hline Mortal(s) \end{array} $$ En este caso $\forall$ es un cuantificador universal, $x$ es una entidad (u objeto), y $Hombre$ y $Mortal$ son predicados l√≥gicos. En este caso se lee que cualquier objeto $x$ que tenga el predicado $Hombre(x)$ implica que tendr√° tambi√©n el predicado $Mortal(x)$. Consideremos los siguientes axiomas: Todos los ni√±os aman al Viejo Pascuero Todos los ni√±os que aman al Viejo Pascuero, aman a cualquier reno Rodolfo es un reno y Rodolfo tiene la nariz Roja Cualquiera que tenga la nariz roja es extra√±o o es un payaso Ning√∫n reno es un payaso Juan no ama cualquier cosa que sea extra√±a ¬øPodemos concluir que Juan no es un ni√±o? Una posible respuesta de ChatGPT: Fig 2: ChatGPT y su respuesta a los axiomas de navidad. Sin embargo, si transformamos los axiomas a l√≥gica de primer √≥rden: $\forall x \text{ ni√±o}(x) \rightarrow ama(x, vp)$ $\forall x, y (\text{ni√±o}(x) \land reno(y) \land ama(x, vp) \rightarrow ama(x, y))$ $reno(r) \land nariz\ roja(r)$ $\forall x (nariz\ roja(x) \rightarrow \text{extra√±o}(x) \lor payaso(x))$ $\neg \exists x(reno(x) \land payaso(x))$ $\forall x (\text{extra√±o}(x) \rightarrow \neg ama(j, x))$ Conclusi√≥n: $\neg \text{ni√±o}(j)$ Supongamos que Juan fuese ni√±o: Si juan fuera un ni√±o, amar√≠a al Viejo pascuero por axioma 1. Si Juan fuera un ni√±o, entonces juan amar√≠a al reno Rodolfo, por axioma 2., ya que juan ama al Viejo Pascuero Rodolfo tiene la nariz roja, por lo tanto o es extra√±o o es un payaso, por axioma 4. Rodolfo no es un payaso ya que no existe una entidad que sea reno y payaso a la vez por axioma 5. Rodolfo es extra√±o por axioma 4. Juan no ama a nada que sea extra√±o, pero rodolfo es extra√±o, por lo que juan no amar√≠a a rodolfo, axioma 6. Por lo tanto hay una contradicci√≥n y Juan no puede ser un ni√±o. Recordemos que ChatGPT no es determinista, por lo que en algunos casos podr√≠a dar la respuesta correcta (ya que este es un ejemplo conocido). Sin embargo, en este caso podemos notar que ChatGPT llega a una conclusi√≥n err√≥nea, por lo que no est√° realmente razonando. Conclusiones ChatGPT comenz√≥ con un modelo GPT entrenado para predicci√≥n de la siguiente palabra. El modelo fue entrenado con una cantidad masiva de datos, por lo que indirectamente pod√≠a resolver algunas tareas d√°ndole una consulta/contexto indicado. ChatGPT utiliza RLHF para aprender a interactuar con humanos. ChatGPT no est√° razonando l√≥gicamente y no entiende el significado de los textos. Estamos lejos de ser reemplazados por IA, sin embargo, existen Super-usuarios o power users que le pueden sacar m√°ximo provecho a este tipo de sistemas con IA.]]></summary></entry></feed>