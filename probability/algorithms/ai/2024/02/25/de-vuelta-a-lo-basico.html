<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>De vuelta a lo b√°sico | Mr Dipalma‚Äôs Pub üç∫</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="De vuelta a lo b√°sico">
<meta name="author" content="dpalmasan">
<meta property="og:locale" content="en_US">
<meta name="description" content="Este es un blog donde compartir√© un poco sobre m√≠ y mis experiencias en el mundo tecnol√≥gico‚Ä¶">
<meta property="og:description" content="Este es un blog donde compartir√© un poco sobre m√≠ y mis experiencias en el mundo tecnol√≥gico‚Ä¶">
<link rel="canonical" href="https://dpalmasan.github.io/website/probability/algorithms/ai/2024/02/25/de-vuelta-a-lo-basico.html">
<meta property="og:url" content="https://dpalmasan.github.io/website/probability/algorithms/ai/2024/02/25/de-vuelta-a-lo-basico.html">
<meta property="og:site_name" content="Mr Dipalma‚Äôs Pub üç∫">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2024-02-25T23:50:00+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="De vuelta a lo b√°sico">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"dpalmasan"},"dateModified":"2024-02-25T23:50:00+00:00","datePublished":"2024-02-25T23:50:00+00:00","description":"Este es un blog donde compartir√© un poco sobre m√≠ y mis experiencias en el mundo tecnol√≥gico‚Ä¶","headline":"De vuelta a lo b√°sico","mainEntityOfPage":{"@type":"WebPage","@id":"https://dpalmasan.github.io/website/probability/algorithms/ai/2024/02/25/de-vuelta-a-lo-basico.html"},"url":"https://dpalmasan.github.io/website/probability/algorithms/ai/2024/02/25/de-vuelta-a-lo-basico.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css">
    <link rel="stylesheet" href="/website/assets/css/style.css">
    <style type="text/css">
        div#disqus_thread iframe[sandbox] {
                max-height: 0px !important;
        }
    </style>
<link type="application/atom+xml" rel="alternate" href="https://dpalmasan.github.io/website/feed.xml" title="Mr Dipalma's Pub üç∫">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KHXBX5G1VP"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){window.dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-KHXBX5G1VP');
</script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<header class="site-header">

  <div class="wrapper">
<a class="site-title" rel="author" href="/website/">Mr Dipalma's Pub üç∫</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/website/about/">About</a></div>
      </nav>
</div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">De vuelta a lo b√°sico</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-02-25T23:50:00+00:00" itemprop="datePublished">
        Feb 25, 2024
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/modelo_probabilistico.png" alt="header"></p>
</div>
<h1 id="introduccin">Introducci√≥n</h1>
<p>Estuve revisando material de cuando hac√≠a clases/ayudant√≠as en diversos lugares (que me reservar√© ya que no es informaci√≥n relevante), y not√© que si bien viven en sitios olvidados, podr√≠a revivir dicho material. Por otro lado, el material contiene en forma muy resumida algunos temas b√°sicos de estad√≠stica y probabilidad.</p>
<p>En mi m√°s reciente art√≠culo: <a href="/website/python/algorithms/ai/2024/02/23/generando-imagenes-vqvae.html"><em>Generando Im√°genes con VQ-VAE</em></a>, describ√≠ la teor√≠a y entregu√© una implementaci√≥n b√°sica de una de las arquitecturas fundamentales utilizadas en sistemas de IA generativa (ej. DALL-E). ¬øC√≥mo esto se relaciona con el p√°rrafo anterior? He visto los siguientes perfiles en algunas redes sociales:</p>
<ol>
<li>Personas no t√©cnicas (generalmente de <em>marketing</em>) que hablan de IA como si fuesen expertos y peor a√∫n, proliferan informaci√≥n incorrecta y sensacionalista.</li>
<li>Personas t√©cnicas (ej. ingenieros de software) que no tienen buenas bases matem√°ticas y caen en el mismo juego de lo sensacionalista. En este caso, conectando las <code>API</code> de turno, sin tener conocimiento de lo que realmente hacen los sistemas.</li>
</ol>
<p>Ambos perfiles mencionados, son perjudiciales, ya que llenan las redes sociales con informaci√≥n generalmente err√≥nea y en los peores casos enga√±osa. Coment√© en un sitio, si usted ve a alguien con el encabezado ‚Äú<em>Generative AI expert</em>‚Äù y no encuentra a dicha persona aportando en alguna revista cient√≠fica en temas de IA, es una mala se√±al üö©. Una cosa es ser usuario de una tecnolog√≠a y otra muy distinta es ser experto en dicha tecnolog√≠a.</p>
<p>Comenzar√© una seria de art√≠culos, en los cuales, de forma muy resumida, intento explicar conceptos fundamentales para entender las tecnolog√≠as actuales, con el fin de democratizar la informaci√≥n.</p>
<h1 id="estadstica-descriptiva">Estad√≠stica Descriptiva</h1>
<p>Existen 3 descriptores fundamentales de los datos, los cuales se utilizan como estad√≠sticas descriptiva:</p>
<ol>
<li>Media</li>
<li>Mediana</li>
<li>Desviaci√≥n est√°ndar</li>
</ol>
<h2 id="media">Media</h2>
<p>La media de un conjunto de datos discreto es el valor central, espec√≠ficamente, la suma de los valores dividido por el n√∫mero de valores.</p>
<p>$$media = \frac{1}{n} \sum_{i=1}^{n} x_i$$</p>
<h2 id="mediana">Mediana</h2>
<p>La mediana es el valor que separa la mitad inferior y superior de una muestra de datos. La forma de calcularla es, ordenar las muestras. Luego, si se tienen $n$ muestras en√∫meradas de $1$ a $n$, es decir $x_1, x_2, \ldots, x_n$, la mediana se calcula como:</p>
<p>$$mediana = \frac{1}{2} \left( x_{\lfloor (n+1)/2\rfloor} + x_{\lceil (n+1)/2\rceil} \right)$$</p>
<p>Supongamos que tenemos las siguientes observaciones de altura $h = (1, 3, 3, 5, 7)$, en este caso la mediana ser√≠a $3$, y aplicando
la f√≥rmula, se tienen $5$ observaciones, por lo tanto se requiere $0.5 \cdot (x_{3} + x_{3}) = x_{3} = 3$. Ahora supongamos que tenemos las
siguientes observaciones $h = (1, 2, 3, 4, 5, 6, 8, 9)$, en este caso el n√∫mero de observaciones es $8$, n√∫mero par. Por lo tanto seg√∫n
la f√≥rmula $0.5 \cdot (x_{4} + x_{5}) = 0.5 \cdot (4 + 5) = 4.5$. En el caso par, se consideran las muestras que caen en el medio, y se
calcula el punto medio entre ellas. Esto sigue la intuici√≥n de la definici√≥n de mediana, que es b√°sicamente una medida que separa las
observaciones en una mitad inferior y una mitad superior.</p>
<h2 id="desviacin-estndar">Desviaci√≥n Est√°ndar</h2>
<p>La desviaci√≥n est√°ndar es una medida de cantidad de dispersi√≥n en un conjunto de valores. Un valor bajo de desviaci√≥n est√°ndar muestra
que los valores tienden a estar cerca del promedio, mientras que un valor alto indica que los valores tienden a exparcirse en un rango m√°s
amplio de valores. Por ejemplo, consideremos dos distribuciones de valores $(50, 50)$, $(0, 100)$. Ambos tienen una media de 50, pero los
rangos de valores en la primera no se alejan del promedio, por lo tanto tienen 0 dispersi√≥n, mientras que en el segundo caso, la desviaci√≥n
est√°ndar es 50.</p>
<p>$$Desv.Std = \sqrt{\frac{1}{n} \sum_{i=1}^{n} \left( x_i - media \right)^2}$$</p>
<h2 id="calculo-en-python">Calculo en Python</h2>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>


<span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">array</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">std</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="n">avg</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">((</span><span class="n">xi</span> <span class="o">-</span> <span class="n">avg</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">xi</span> <span class="ow">in</span> <span class="n">array</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">array</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">median</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="n">sorted_array</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>

    <span class="c1"># Indexacion empieza desde 0, por eso le resto 1
</span>    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span>
        <span class="n">sorted_array</span><span class="p">[</span><span class="n">math</span><span class="p">.</span><span class="n">floor</span><span class="p">((</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="o">+</span> <span class="n">sorted_array</span><span class="p">[</span><span class="n">math</span><span class="p">.</span><span class="n">ceil</span><span class="p">((</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
    <span class="p">)</span>


<span class="n">x1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="n">x2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Usando las formulas y operaciones en python"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"x1; media: </span><span class="si">{</span><span class="n">mean</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span><span class="si">}</span><span class="s">, mediana: </span><span class="si">{</span><span class="n">median</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span><span class="si">}</span><span class="s">, desv std: </span><span class="si">{</span><span class="n">std</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"x2; media: </span><span class="si">{</span><span class="n">mean</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span><span class="si">}</span><span class="s">, mediana: </span><span class="si">{</span><span class="n">median</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span><span class="si">}</span><span class="s">, desv std: </span><span class="si">{</span><span class="n">std</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">np_x1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
<span class="n">np_x2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Usando numpy"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s">"x1; media: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np_x1</span><span class="p">)</span><span class="si">}</span><span class="s">, mediana: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">median</span><span class="p">(</span><span class="n">np_x1</span><span class="p">)</span><span class="si">}</span><span class="s">, desv std: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">np_x1</span><span class="p">)</span><span class="si">}</span><span class="s">"</span>
<span class="p">)</span>
<span class="k">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s">"x2; media: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np_x2</span><span class="p">)</span><span class="si">}</span><span class="s">, mediana: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">median</span><span class="p">(</span><span class="n">np_x2</span><span class="p">)</span><span class="si">}</span><span class="s">, desv std: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">np_x2</span><span class="p">)</span><span class="si">}</span><span class="s">"</span>
<span class="p">)</span>

<span class="n">df_x1</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">"x1"</span><span class="p">:</span> <span class="n">x1</span><span class="p">})</span>
<span class="n">df_x2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">"x2"</span><span class="p">:</span> <span class="n">x2</span><span class="p">})</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Usando pandas"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s">"x1; media: </span><span class="si">{</span><span class="n">df_x1</span><span class="p">.</span><span class="n">x1</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s">, mediana: </span><span class="si">{</span><span class="n">df_x1</span><span class="p">.</span><span class="n">x1</span><span class="p">.</span><span class="n">median</span><span class="p">()</span><span class="si">}</span><span class="s">, desv std: </span><span class="si">{</span><span class="n">df_x1</span><span class="p">.</span><span class="n">x1</span><span class="p">.</span><span class="n">std</span><span class="p">()</span><span class="si">}</span><span class="s">"</span>
<span class="p">)</span>
<span class="k">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s">"x1; media: </span><span class="si">{</span><span class="n">df_x2</span><span class="p">.</span><span class="n">x2</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s">, mediana: </span><span class="si">{</span><span class="n">df_x2</span><span class="p">.</span><span class="n">x2</span><span class="p">.</span><span class="n">median</span><span class="p">()</span><span class="si">}</span><span class="s">, desv std: </span><span class="si">{</span><span class="n">df_x2</span><span class="p">.</span><span class="n">x2</span><span class="p">.</span><span class="n">std</span><span class="p">()</span><span class="si">}</span><span class="s">"</span>
<span class="p">)</span>
</code></pre></div></div>
<pre><code>Usando las formulas y operaciones en python
x1; media: 3.8, mediana: 3.0, desv std: 2.039607805437114
x2; media: 4.75, mediana: 4.5, desv std: 2.6339134382131846
Usando numpy
x1; media: 3.8, mediana: 3.0, desv std: 2.039607805437114
x2; media: 4.75, mediana: 4.5, desv std: 2.6339134382131846
Usando pandas
x1; media: 3.8, mediana: 3.0, desv std: 2.280350850198276
x2; media: 4.75, mediana: 4.5, desv std: 2.815771906346718
</code></pre>
<p>En <code>pandas</code> la diferencia se debe a que se divide por $n - 1$ en lugar de $n$, para obtener un valor sin sesgo. Queda como tarea para el lector entender lo que es un estimador sesgado y sin sesgo.</p>
<h1 id="probabilidades-y-funciones">Probabilidades y Funciones</h1>
<h2 id="probabilidad">Probabilidad</h2>
<p>En general, se habla de probabilidad en casos en que existe incertidumbre en una situaci√≥n. Por ejemplo, si voy al doctor y recibo un tratamiento, ¬øQu√© tan probable es que con dicho tratamiento me recupere? O por ejemplo, en un casino jugando black jack, ¬øCu√°l es la probabilidad de que me salga black jack en la siguiente mesa?</p>
<p>Un <strong>modelo probabil√≠stico</strong> es una descripci√≥n matem√°tica de una situaci√≥n incierta. Dicho modelo matem√°tico contiene los siguientes elementos:</p>
<ul>
<li>El <strong>espacio muestral</strong> $\Omega$, que es el conjunto de todos los posibles resultados de un experimento.</li>
<li>La <strong>ley de probabilidad</strong>, que asigna a un conjunto $A$ (tambi√©n llamado <strong>evento</strong>) de posibiles resultados, un n√∫mero no negativo $P(A)$ (conocido como la probabilidad de $A$) y que codifica nuestro conocimiento o creencia sobre qu√© tan posible es que $A$ ocurra.</li>
</ul>
<p>La siguiente figura ilustra los elementos de un modelo probabil√≠stico:</p>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/modelo_probabilistico.png" alt="prob-model"></p>
<p><em>Fig 1: Visualizaci√≥n modelo probabil√≠stico</em></p>
</div>
<p>Todo modelo probabil√≠stico involucra un proceso subyacente, el cual se le denomina <strong>experimento</strong>, y que producir√° exactamente uno de los muchos posibles <strong>resultados</strong>. El conjunto de todos los posibles resultados se llama <strong>espacio muestral</strong> del experimento, y se denota $\Omega$. Un subconjunto del espacio muestral, es decir, una colecci√≥n de posibles resultados, se conoce como <strong>evento&lt;</strong>.</p>
<p>La <strong>ley de probabilidad</strong> especifica la ‚Äúposibilidad‚Äù de cualquier resultado, o cualquier conjunto de posibles resultados (evento). Esta ley asigna a cada evento $A$, un n√∫mero $P(A)$, llamado la <strong>probabilidad</strong> de $A$, la cual satisface los siguientes axiomas:</p>
<ol>
<li>
<strong>(No negatividad)</strong> $P(A) \geq 0$, para todo evento $A$</li>
<li>
<strong>(Aditividad)</strong> Si $A$ y $B$ son dos eventos disjuntos, entonces la probabilidad de su union satisface:</li>
</ol>
<p>$$P(A \cup B) = P(A) + P(B)$$</p>
<p>Esto se puede generalizar a la union de m√°s eventos.</p>
<ol start="3">
<li>
<strong>(Normalizaci√≥n)</strong> La probabilidad del espacio muestral $\Omega$ es igual a 1, es decir $P(\Omega) = 1$</li>
</ol>
<p>Consideremos el experimento de lanzar dos dados de 4 caras. Asumimos que los dados no est√°n cargados, y con este supuesto queremos decir que cada uno de los 16 posibles resultados: $\{(i, j) | i, j = 1, 2, 3, 4\}$ cada uno tiene la misma probabilidad de
ocurrir $\frac{1}{16}$. Algunos ejemplos:</p>
<ul>
<li>$P(\{ \text{la suma de los dados es par}\}) = \frac{8}{16} = \frac{1}{2}$</li>
<li>$P(\{ \text{la suma de los dados es impar}\}) = \frac{8}{16} = \frac{1}{2}$</li>
<li>$P(\{ \text{El primer dado es igual al segundo}\}) = \frac{4}{16} = \frac{1}{4}$</li>
<li>$P(\{ \text{El primer dado es mayor que el segundo}\}) = \frac{6}{16} = \frac{3}{8}$</li>
<li>$P(\{ \text{Al menos un dado da 4}\}) = \frac{7}{16}$</li>
</ul>
<p>El espacio muestral y algunos ejemplos de eventos se muestran en la figura 2.</p>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/ejemplo_espacio.png" alt="em-dice"></p>
<p><em>Fig 2: Espacio muestral del experimento de lanzar dos dados de 4 caras.</em></p>
</div>
<h2 id="probabilidad-condicional">Probabilidad Condicional</h2>
<p>La probabilidad coondicional nos entrega una manera de razonar acerca los resultados de un experimento, bas√°ndonos en <strong>informaci√≥n parcial</strong>.</p>
<p>Algunos ejemplos de situaciones:</p>
<ul>
<li>En un experimento de lanzamiento consecutivo de dos dados, nos dicen que la suma es 9. ¬øQu√© tan posible es que el primer dado haya sido un 6?</li>
<li>¬øQu√© tan probable es que una persona tiene cierta enfermedad dado un test m√©dico que sali√≥ negativo?</li>
<li>Un cliente est√° usando un la versi√≥n gratuita de servicio con cierta frecuencia. ¬øQu√© tan probable es que acepte una oferta de suscripci√≥n premium?</li>
</ul>
<p>Siendo m√°s precisos, dado un experimento, su espacio muestral correspondiente y su ley de probabilidad, supongamos que el resultado se encuentra dentro de algun evento $B$ dado. Deseamos cuantificar la posibilidad que el resultado pertenece tambi√©n a otro evento $A$. Por lo tanto, construimos una nueva ley de probabilidad que considera el conocimiento disponible: Una ley de probabilidad que para cualquier evento $A$, especifica la <strong>probabilidad condicional de $A$ dado $B$</strong>, y se denota como $P\left(A\mid B\right)$</p>
<p>Por otro lado, nos gustar√≠a que las probabilidades condicionales $P\left(A\mid B\right)$ de diferentes eventos $A$, constituyeran una  ley de probabilidad que satisfaga todos los axiomas de probabilidad. Este tipo de probabilidades tambi√©n deben ser consistentes con la intuici√≥n en casos especiales, por ejemplo, cuando todos los posibles resultados del experimento son igualmente posibles. Por ejemplo, supongamos que los 6 resultados del lanzamiento de un dado de 6 caras son igualmente probables. Si nos dijeran que el resultado fue par, nos quedan s√≥lo 3 posibles resultados, 2, 4, y 6. Estos resultados en principio ten√≠an la misma probabilidad, por lo tanto ahora que sabemos que el n√∫mero fue par, debiesen ser igualmente probables. As√≠, es razonable pensar:</p>
<p>$$P\left(\text{el resultado es 6}\mid \text{el resultado es par}\right) = \frac{1}{3}$$</p>
<p>Generalizando esta intuici√≥n, la definici√≥n de probabilidad condicional es:</p>
<p>$$P\left(A\mid B\right) = \frac{P(A \cap B)}{P(B)}$$</p>
<p>donde asumimos que $P(B) &gt; 0$; la probabilidad condicional es indefinida si el evento condicionante tiene probabilidad cero.</p>
<p>Dado que $P(A) \geq 0$ y $P(B) &gt; 0$, esta ley de probabilidad satisface el axioma de no negatividad. El axioma de normalizaci√≥n tambi√©n se satisface:</p>
<p>$$P\left(\Omega \mid B\right) = \frac{P\left( \Omega \cap B\right)}{P(B)} = \frac{P(B)}{P(B)} = 1$$</p>
<p>Y el axioma de aditivdad tambi√©n se satisface, para cualquier par de eventos disjuntos $A_1$ y $A_2$:</p>
<p>$$
\begin{align}
P\left(A_1 \cup A_2 \mid B\right) &amp; = \frac{P\left(\left(A_1 \cup A_2 \right) \cap B\right)}{P(B)}\\
&amp; = \frac{P\left(\left(A_1 \cap B \right) \cup \left(A_2\cap B\right)\right)}{P(B)}\\
&amp; = \frac{P\left(A_1 \cap B \right) + \left(A_2\cap B\right)}{P(B)}\\
&amp; = \frac{P\left(A_1 \cap B \right)}{P(B)} + \frac{\left(A_2\cap B\right)}{P(B)}\\
&amp; = P\left(A_1 \mid B\right) + P\left(A_2 \mid B\right)
\end{align}
$$</p>
<p>Consideremos nuevamente el experimento de dos lanzamientos de dados de 4 caras, donde los 16 resultados posibles tienen la misma probabilidad. Supongamos que queremos determinar la probabilidad $P\left(A \mid B\right)$ donde:</p>
<p>$$A = \left\{max(X, Y) = m\right\}, \quad B = \left\{min(X, Y) = 2\right\},$$</p>
<p>y $m$ puede tomar cualquiera de los valores 1, 2, 3, 4.</p>
<div align="center">
<p><img src="https://raw.githubusercontent.com/dpalmasan/homepage/master/public/imgs/ejemplo_condicional.png" alt="em-2dice"></p>
<p><em>Fig 3: Espacio muestral lanzamiento dos dados.</em></p>
</div>
<p>En la figura 3 se muestra el espacio muestral de un experimento que involucra dos lanzamientos de dados de 4 caras. El evento condicionante $B = \left\{min(X, Y) = 2\right\}$ es el conjunto sombreado en la figura. El evento $A = \left\{max(X, Y) = m\right\}$ comparte con $B$ dos elementos si $m = 3$ o $m = 4$, un elemento si $m = 2$, y ning√∫n elemento si $m = 1$. Por lo tanto tenemos:</p>
<p>$$
P (\left\{max(X, Y) = m\right\} \mid B)=
\left\{
\begin{array}{ll}
2/5  &amp; \mbox{si } m = 3 \text{ o } m = 4 \\
1/5 &amp; \mbox{si } m = 2 \\
0 &amp; \mbox{si } m = 1
\end{array}
\right.
$$</p>
<h2 id="distintos-enfoques-a-la-estadstica">Distintos enfoques a la estad√≠stica</h2>
<p>En el campo de la estad√≠stica hay dos prominentes escuelas de pensamiento, con visiones opuestas: la <strong>Bayesiana</strong> y la <strong>cl√°sica</strong> (
tambi√©n llamada <strong>frecuentista</strong>). Su diferencia fundamental est√° relacionada con la naturaleza de modelos desconocidos o variables. En una
visi√≥n Bayesiana, estos modelos se tratan como variables aleatorias (tema que veremos m√°s adelante) con distribuciones conocidas. En la visi√≥n cl√°sica, estos modelos/variables se tratan como cantidades determin√≠sticas que se desconocen. En fin, es un tema pr√°cticamente filos√≥fico, pero en t√©rminos pr√°cticos, los modelos Bayesianos sol√≠an ser intratables computacionalmente, ahora con los avances en computaci√≥n y en semiconductores (procesadores), muchas investigaciones recientes se enfocan en hacer m√©todos Bayesianos que puedan ser usados en la pr√°ctica. Pueden leer este <a href="http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/" target="_blank" rel="noopener noreferrer">interesante art√≠culo</a>.</p>
<h1 id="eso-es-todo-amigos">¬°Eso es todo amigos!</h1>
<p>Por el momento, lo dejar√© hasta aqu√≠. Con esta informaci√≥n y definiciones, debiese ser m√°s simple leer mis art√≠culos anteriores. Ya que esto no es un curso ni nada, s√≥lo informaci√≥n b√°sica, sesgada a mi opini√≥n y que se transmite de manera as√≠ncrona, no pondr√© muchas simulaciones o ejercicios computacionales. Sin embargo, en el futuro puede que agregue algo de c√≥digo, en caso de ser necesario.</p>
<p>Rezo, para que la gente que est√° predicando humo, dedique un par de minutos de su vida a entender al menos los fundamentos de lo que predican (actualmente AI y GenAI). En mis otros art√≠culos hablo de varios temas relacionados; armando el puzle completo, se puede entender mejor c√≥mo funcionan las tecnolog√≠as actuales.</p>
<p>¬°Abrazos!</p>

  </div>
<div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = '';
      this.page.identifier = 'https://dpalmasan.github.io/website/probability/algorithms/ai/2024/02/25/de-vuelta-a-lo-basico.html';
    };

    (function() {
      var d = document, s = d.createElement('script');

      s.src = 'https://dpalmasan.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow noopener noreferrer" target="_blank">comments powered by Disqus.</a>
</noscript>
<a class="u-url" href="/website/probability/algorithms/ai/2024/02/25/de-vuelta-a-lo-basico.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/website/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="https://dpalmasan.github.io/website/feed.xml">
            <svg class="svg-icon orange">
              <path d="M12.8 16C12.8 8.978 7.022 3.2 0 3.2V0c8.777 0 16 7.223 16 16h-3.2zM2.194
                11.61c1.21 0 2.195.985 2.195 2.196 0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017 0
                13.806c0-1.21.983-2.195 2.194-2.195zM10.606
                16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818 0 10.606 4.79 10.606 10.607z"></path>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">dpalmasan</li>
          
        </ul>
      </div>
      <div class="footer-col">
        <p>Este es un blog donde compartir√© un poco sobre m√≠ y mis experiencias en el mundo tecnol√≥gico...</p>
      </div>
    </div>

    <div class="social-links">
<ul class="social-media-list">
<li>
    <a rel="me noopener noreferrer" href="https://www.linkedin.com/in/dpalmasan/" target="_blank" title="Mi perfil en Linkedin">
      <span class="grey fa-brands fa-linkedin fa-lg"></span>
    </a>
  </li>
<li>
    <a rel="me noopener noreferrer" href="https://www.github.com/dpalmasan" target="_blank" title="Mi Github">
      <span class="grey fa-brands fa-github fa-lg"></span>
    </a>
  </li>
<li>
    <a rel="me noopener noreferrer" href="https://scholar.google.com/citations?user=Y5PN_1AAAAAJ&hl=en" target="_blank" title="Mi Google Scholar">
      <span class="grey fa-brands fa-google-scholar fa-lg"></span>
    </a>
  </li>
<li>
    <a rel="me noopener noreferrer" href="https://stackoverflow.com/users/4051219/dpalma" target="_blank" title="Mis preguntas en SO LOL!">
      <span class="grey fa-brands fa-stack-overflow fa-lg"></span>
    </a>
  </li>
</ul>
</div>

  </div>

</footer>

</body>

</html>
