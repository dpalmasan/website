<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Un poco de NLP b√°sico (no un tutorial de pytorch/tensor flow) | Mr Dipalma‚Äôs Pub üç∫</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="Un poco de NLP b√°sico (no un tutorial de pytorch/tensor flow)">
<meta name="author" content="dpalmasan">
<meta property="og:locale" content="en_US">
<meta name="description" content="La entrada de hoy no tendr√° nada pol√©mico ni ninguna afirmaci√≥n que pudiera herir los sentimientos/egos de alg√∫n lector. Esta entrada es para compartir un poco de lo b√°sico de Procesamiento de Lenguaje Natural (Natural Language Processing o NLP). Est√° un poco relacionado a un post que hace un tiempo hice en Linkedin. La diferencia, esta vez no me las dar√© de experto en TypeScript (porque estoy muy lejos de serlo :sweat_smile:), sin embargo el c√≥digo a compartir ser√° en python ya que veo que la mayor√≠a de las personas metidas en el mundo de TI, en especial √°rea de datos/inteligencia artificial utilizan este lenguaje.">
<meta property="og:description" content="La entrada de hoy no tendr√° nada pol√©mico ni ninguna afirmaci√≥n que pudiera herir los sentimientos/egos de alg√∫n lector. Esta entrada es para compartir un poco de lo b√°sico de Procesamiento de Lenguaje Natural (Natural Language Processing o NLP). Est√° un poco relacionado a un post que hace un tiempo hice en Linkedin. La diferencia, esta vez no me las dar√© de experto en TypeScript (porque estoy muy lejos de serlo :sweat_smile:), sin embargo el c√≥digo a compartir ser√° en python ya que veo que la mayor√≠a de las personas metidas en el mundo de TI, en especial √°rea de datos/inteligencia artificial utilizan este lenguaje.">
<link rel="canonical" href="https://dpalmasan.github.io/website/entrevistas/ti/2023/01/08/nlp-intro.html">
<meta property="og:url" content="https://dpalmasan.github.io/website/entrevistas/ti/2023/01/08/nlp-intro.html">
<meta property="og:site_name" content="Mr Dipalma‚Äôs Pub üç∫">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-01-08T21:03:03+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Un poco de NLP b√°sico (no un tutorial de pytorch/tensor flow)">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"dpalmasan"},"dateModified":"2023-01-08T21:03:03+00:00","datePublished":"2023-01-08T21:03:03+00:00","description":"La entrada de hoy no tendr√° nada pol√©mico ni ninguna afirmaci√≥n que pudiera herir los sentimientos/egos de alg√∫n lector. Esta entrada es para compartir un poco de lo b√°sico de Procesamiento de Lenguaje Natural (Natural Language Processing o NLP). Est√° un poco relacionado a un post que hace un tiempo hice en Linkedin. La diferencia, esta vez no me las dar√© de experto en TypeScript (porque estoy muy lejos de serlo :sweat_smile:), sin embargo el c√≥digo a compartir ser√° en python ya que veo que la mayor√≠a de las personas metidas en el mundo de TI, en especial √°rea de datos/inteligencia artificial utilizan este lenguaje.","headline":"Un poco de NLP b√°sico (no un tutorial de pytorch/tensor flow)","mainEntityOfPage":{"@type":"WebPage","@id":"https://dpalmasan.github.io/website/entrevistas/ti/2023/01/08/nlp-intro.html"},"url":"https://dpalmasan.github.io/website/entrevistas/ti/2023/01/08/nlp-intro.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css">
    <link rel="stylesheet" href="/website/assets/css/style.css">
    <style type="text/css">
        div#disqus_thread iframe[sandbox] {
                max-height: 0px !important;
        }
    </style>
<link type="application/atom+xml" rel="alternate" href="https://dpalmasan.github.io/website/feed.xml" title="Mr Dipalma's Pub üç∫">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KHXBX5G1VP"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){window.dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-KHXBX5G1VP');
</script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<header class="site-header">

  <div class="wrapper">
<a class="site-title" rel="author" href="/website/">Mr Dipalma's Pub üç∫</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/website/about/">About</a></div>
      </nav>
</div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Un poco de NLP b√°sico (no un tutorial de pytorch/tensor flow)</h1>
    <p class="post-meta"><time class="dt-published" datetime="2023-01-08T21:03:03+00:00" itemprop="datePublished">
        Jan 8, 2023
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>La entrada de hoy no tendr√° nada pol√©mico ni ninguna afirmaci√≥n que pudiera herir los sentimientos/egos de alg√∫n lector. Esta entrada es para compartir un poco de lo b√°sico de Procesamiento de Lenguaje Natural (<em>Natural Language Processing</em> o <em>NLP</em>). Est√° un poco relacionado a un <a href="https://www.linkedin.com/pulse/generaci%2525C3%2525B3n-autom%2525C3%2525A1tica-de-oraciones-una-humilde-intro-y-palma-s%2525C3%2525A1nchez%3FtrackingId=jwAk4Po8EYaTMJ9z1BUP8g%253D%253D/?trackingId=jwAk4Po8EYaTMJ9z1BUP8g%3D%3D" target="_blank" rel="noopener noreferrer">post que hace un tiempo hice en Linkedin</a>. La diferencia, esta vez no me las dar√© de experto en TypeScript (porque estoy muy lejos de serlo<img class="emoji" title=":sweat_smile:" alt=":sweat_smile:" raw="üòÖ" src="https://github.githubassets.com/images/icons/emoji/unicode/1f605.png" style="vertical-align: middle; display: inline; max-width: 1em; visibility: hidden;" onload="this.style.visibility='visible'" onerror="this.replaceWith(this.getAttribute('raw'))">), sin embargo el c√≥digo a compartir ser√° en <code>python</code> ya que veo que la mayor√≠a de las personas metidas en el mundo de TI, en especial √°rea de datos/inteligencia artificial utilizan este lenguaje.</p>
<p><strong>Aclaraci√≥n</strong>: Esto no es un tutorial de modelos de <strong>HuggingFace</strong> con <code>pytorch</code> o <code>keras</code> con <code>tensor flow</code>. Si vienes buscando contenido as√≠, mejor googlear o leer la documentaci√≥n/foros de discusi√≥n de tales sitios.</p>
<h2 id="n-gramas-conocimiento-bsico-de-nlp">N-Gramas, conocimiento b√°sico de NLP</h2>
<p>En simple, un <code>n-grama</code> es una secuencia de <strong>tokens</strong>, en el caso del lenguaje humano, es una secuencia de palabras. ¬øPor qu√© los <code>n-gramas</code> son tan importantes? Los <code>n-gramas</code> dan informaci√≥n contextual del contenido del discurso, por ello es que se utilizan en modelos m√°s sofisticados como <code>Word2Vec</code>, <code>GloVe</code> entre otros.</p>
<p>En el contexto de NLP, los n-gramas sirven para computacionalmente procesar discurso humano, y lograr que la m√°quina pueda automatizar ciertas tareas, que ser√≠a intractable automatizar con un conjunto de reglas pre-definido. Por ejemplo, supongamos que queremos implementar un programa que prediga la palabra siguiente dado un contexto. Ser√≠a poco pr√°ctico tener un conjunto con todas las reglas y combinaciones posibles:</p>
<ol>
<li>El lenguaje humano es infinito, ya que se pueden generar infinitas oraciones siguiendo la gram√°tica.</li>
<li>El costo computacional ser√≠a alt√≠simo, incluso teniendo capacidad de c√≥mputo infinita, el tiempo de b√∫squeda lo har√≠a impr√°ctico; De hecho es un problema que aunque tenga soluci√≥n puede que pasen trillones de a√±os en encontrarse.</li>
</ol>
<p>¬øExiste una manera m√°s simple? Por supuesto, podemos utilizar razonamiento con incertidumbre y utilizar la opci√≥n que, dado un contexto, sea la m√°s probable. Como intuici√≥n, tomemos la siguiente oraci√≥n: <strong>Ir√© al supermercado, necesito‚Ä¶</strong>. Una opci√≥n de palabra siguiente podr√≠a ser comprar o cualquiera de sus variaciones. Aqu√≠ es donde entra la probabilidad y los n-gramas.</p>
<h3 id="estimando-probabilidades-en-el-lenguaje">Estimando Probabilidades en el Lenguaje</h3>
<p>Como an√©cdota, en proyectos de investigaci√≥n he trabajado con ling√º√≠stas, y las veces que habl√© de probabilidades en el lenguaje, reaccionaron como si estuviera cometiendo el peor de los delitos. Para estimar la probabilidad de una oraci√≥n, dentro del lenguaje habr√≠a que estimar la probabilidad conjunta de un grupo de palabras, por ejemplo, responder a la pregunta <strong>‚ÄúDe todas las oraciones posibles con 7 palabras, cu√°l es la probabilidad de tener la oraci√≥n ¬øMi abuela me cocin√≥ tallarines con salsa?‚Äù</strong>. La probabilidad conjunta de una oraci√≥n se puede calcular utilizando la regla de la cadena de probabilidades:</p>
<p>$$P(a, b, c) = P(a, b)P(c|a, b) = P(a)P(b|a)P(c|a,b)$$</p>
<p>La f√≥rmula anterior se puede generalizar para oraciones de cualquier tama√±o. Sin embargo, sigue existiendo un problema, no podemos calcular la probabilidad conjunta de una secuencia, porque necesitar√≠amos contar la ocurrencia de secuencias de largo $N-1$. Esto se vuelve intratable debido a la variedad del lenguaje.</p>
<p>La intuici√≥n de utilizar un modelo de <code>n-gramas</code> es, en lugar de tomar todas las palabras previas para calcular la probabilidad de una oraci√≥n, podemos utilizar como aproximaci√≥n el contexto en el que la palabra se encuentra, por ejemplo las <code>n</code> palabras anteriores (modelos m√°s sofisticados utilizan variaciones, como por ejemplo, predecir una palabra en medio de una ventana de palabras, esto considerar√≠a palabras previas y palabras posteriores). Volviendo a lo b√°sico, y el tema anterior, podemos aproximar la probabilidad condicional considerando s√≥lo una parte del contexto previo, por ejemplo:</p>
<p>$$P(salsa|\text{Mi abuela me cocin√≥ tallarines con}) \approx P(salsa|con)$$</p>
<p>Este supuesto se conoce como <strong>Supuesto de Markov</strong>. Finalmente, para calcular las probabilidades de estos <code>n-gramas</code> podemos utilizar una <strong>estimaci√≥n de M√°xima Verosimilitud</strong> contando las palabras de un CORPUS (repositorio de textos) dado:</p>
<p>$$P(w_n|w_{n - 1}) = \displaystyle \frac{C(w_{n-1}{w_n})}{\sum_w C(w_{n-1}w)}$$</p>
<p>La ecuaci√≥n anterior se puede generalizar para todo tipo de <code>n-grama</code>, <code>bi-grama</code> ($P(salsa|con)$), <code>tri-grama</code> ($P(salsa|\text{tallarines con})$), etc.</p>
<h4 id="generacin-de-lenguaje-con-modelo-de-n-gramas">Generaci√≥n de Lenguaje con modelo de N-gramas</h4>
<p>Luego de tener la teor√≠a, implementaremos un simple programa en <code>python</code> para crear un modelo generativo de lenguaje. En este ejemplo, utilizaremos como CORPUS el corpus <a href="http://clic.ub.edu/corpus/en" target="_blank" rel="noopener noreferrer">AnCora</a> que consiste en m√∫ltiples textos manualmente anotados por humanos (y en su forma de √°rbol de derivaci√≥n). Lo primero que necesitamos es procesar el CORPUS para obtener las oraciones (ya que de momento no estamos interesados ni en las etiquetas l√©xicas ni en los √°rboles de derivaci√≥n).</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AncoraCorpusReader</span><span class="p">(</span><span class="n">SyntaxCorpusReader</span><span class="p">):</span>
    <span class="s">"""Implementaci√≥n lectura de CORPUS AnCora."""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">files</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="s">"""Constructor.

        Si no se provee una lista de archivos, lee el CORPUS completo.

        :param path: Ruta al directorio del CORPUS.
        :type path: str
        :param files: Lista de archivos a considerar, defaults to None
        :type files: List[str], optional
        """</span>
        <span class="k">if</span> <span class="n">files</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">files</span> <span class="o">=</span> <span class="s">".*\.tbf\.xml"</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">xmlreader</span> <span class="o">=</span> <span class="n">xmldocs</span><span class="p">.</span><span class="n">XMLCorpusReader</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">files</span><span class="p">)</span>

    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">parsed</span><span class="p">(</span><span class="n">element</span><span class="p">):</span>
        <span class="s">"""Procesa corpus.

        Convierte una 'oraci√≥n' XML element (xml.etree.ElementTree.Element) a
        un √°rbol en formato NLTK.
        element -- the XML sentence element (or a subelement)

        :param element: Oraci√≥n a procesar.
        :type element: xml.etree.ElementTree.Element
        :return: √Årbol en formato NLTK
        :rtype: tree.Tree
        """</span>
        <span class="k">if</span> <span class="n">element</span><span class="p">:</span>
            <span class="n">subtrees</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">AncoraCorpusReader</span><span class="p">.</span><span class="n">parsed</span><span class="p">,</span> <span class="n">element</span><span class="p">)</span>
            <span class="n">subtrees</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">subtrees</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">tree</span><span class="p">.</span><span class="n">Tree</span><span class="p">(</span><span class="n">element</span><span class="p">.</span><span class="n">tag</span><span class="p">,</span> <span class="n">subtrees</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">element</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"elliptic"</span><span class="p">)</span> <span class="o">==</span> <span class="s">"yes"</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">element</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"wd"</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">tree</span><span class="p">.</span><span class="n">Tree</span><span class="p">(</span>
                    <span class="n">element</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span> <span class="ow">or</span> <span class="n">element</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"ne"</span><span class="p">)</span> <span class="ow">or</span> <span class="s">"unk"</span><span class="p">,</span>
                    <span class="p">[</span><span class="n">element</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"wd"</span><span class="p">)],</span>
                <span class="p">)</span>

    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">tagged</span><span class="p">(</span><span class="n">element</span><span class="p">:</span> <span class="n">xml</span><span class="p">.</span><span class="n">etree</span><span class="p">.</span><span class="n">ElementTree</span><span class="p">.</span><span class="n">Element</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
        <span class="s">"""Convierte elemento de XML a oraci√≥n etiquetada.

        :param element: Oraci√≥n a procesar.
        :type element: xml.etree.ElementTree.Element
        :return: Lista de tags de la oraci√≥n.
        :rtype: List[Tuple[str, str]]
        """</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">AncoraCorpusReader</span><span class="p">.</span><span class="n">parsed</span><span class="p">(</span><span class="n">element</span><span class="p">).</span><span class="n">pos</span><span class="p">()</span>
        <span class="c1"># Puede terminar en lista vac√≠a!
</span>        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">,</span> <span class="n">pos</span><span class="p">))</span>

    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">untagged</span><span class="p">(</span><span class="n">element</span><span class="p">:</span> <span class="n">xml</span><span class="p">.</span><span class="n">etree</span><span class="p">.</span><span class="n">ElementTree</span><span class="p">.</span><span class="n">Element</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="s">"""Obtiene lista de palabras sin etiqueta.

        :param element: Oraci√≥n a procesar.
        :type element: xml.etree.ElementTree.Element
        :return: Lista de palabras de la oraci√≥n.
        :rtype: List[str]
        """</span>

        <span class="n">sent</span> <span class="o">=</span> <span class="n">AncoraCorpusReader</span><span class="p">.</span><span class="n">parsed</span><span class="p">(</span><span class="n">element</span><span class="p">).</span><span class="n">leaves</span><span class="p">()</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">,</span> <span class="n">sent</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">parsed_sents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fileids</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="s">"""Obteniene oraciones como √°rboles NLTK."""</span>
        <span class="k">return</span> <span class="n">LazyMap</span><span class="p">(</span><span class="n">AncoraCorpusReader</span><span class="p">.</span><span class="n">parsed</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">elements</span><span class="p">(</span><span class="n">fileids</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">tagged_sents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fileids</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="s">"""Obtiene oraciones como tuplas de palabras/tag."""</span>
        <span class="k">return</span> <span class="n">LazyMap</span><span class="p">(</span><span class="n">AncoraCorpusReader</span><span class="p">.</span><span class="n">tagged</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">elements</span><span class="p">(</span><span class="n">fileids</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">sents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fileids</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="s">"""Obtiene oraciones como listas de palabras."""</span>
        <span class="k">return</span> <span class="n">LazyMap</span><span class="p">(</span><span class="n">AncoraCorpusReader</span><span class="p">.</span><span class="n">untagged</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">elements</span><span class="p">(</span><span class="n">fileids</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">elements</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fileids</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="s">"""Obtiene lista de oraciones como elementos XML."""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">fileids</span><span class="p">:</span>
            <span class="n">fileids</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">xmlreader</span><span class="p">.</span><span class="n">fileids</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">LazyConcatenation</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">xmlreader</span><span class="p">.</span><span class="n">xml</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fileids</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">tagged_words</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fileids</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="s">"""Obtiene listas de palabras etiquetdas como tuplas palbra/tag."""</span>
        <span class="k">return</span> <span class="n">LazyConcatenation</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">tagged_sents</span><span class="p">(</span><span class="n">fileids</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">"&lt;AncoraCorpusReader&gt;"</span>


<span class="k">class</span> <span class="nc">SimpleAncoraCorpusReader</span><span class="p">(</span><span class="n">AncoraCorpusReader</span><span class="p">):</span>
    <span class="s">"""Ancora Corpus con conjunto de tags simplificados de Stanford.

    Revisar el siguiente enlace para ver descripci√≥n de los tags.
    https://nlp.stanford.edu/software/spanish-faq.shtml#tagset
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">files</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">files</span><span class="p">)</span>

    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">simple_tag</span><span class="p">(</span><span class="n">t</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="s">"""Convierte etiqueta Ancora en Stanford.

        :param t: Etiqueta a convertir.
        :type t: str
        :return: Etiqueta en formato Stanford.
        :rtype: str
        """</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"a"</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">t</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="s">"0000"</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"d"</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">t</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="s">"0000"</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"f"</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">t</span>
        <span class="k">if</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s">"cc"</span><span class="p">,</span> <span class="s">"cs"</span><span class="p">,</span> <span class="s">"i"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">,</span> <span class="s">"zm"</span><span class="p">,</span> <span class="s">"zu"</span><span class="p">]:</span>
            <span class="k">return</span> <span class="n">t</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"nc"</span><span class="p">):</span>
            <span class="k">return</span> <span class="s">"nc0{}000"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"np"</span><span class="p">):</span>
            <span class="k">return</span> <span class="s">"np00000"</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"p"</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">t</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="s">"000000"</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"r"</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">t</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"sp"</span><span class="p">):</span>
            <span class="k">return</span> <span class="s">"sp000"</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"v"</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">t</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span> <span class="o">+</span> <span class="s">"000"</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"z"</span><span class="p">):</span>
            <span class="k">return</span> <span class="s">"z0"</span>
        <span class="c1"># Probablemente inv√°lido o "unk"
</span>        <span class="k">return</span> <span class="n">t</span>

    <span class="k">def</span> <span class="nf">tagged_sents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fileids</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="s">"""Obtener oraciones etiquetadas con tags de Stanford."""</span>

        <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[(</span><span class="n">w</span><span class="p">,</span> <span class="n">SimpleAncoraCorpusReader</span><span class="p">.</span><span class="n">simple_tag</span><span class="p">(</span><span class="n">t</span><span class="p">))</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">LazyMap</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">super</span><span class="p">().</span><span class="n">tagged_sents</span><span class="p">(</span><span class="n">fileids</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">parsed_sents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fileids</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="s">"""Obtener arboles NLTK etiquetados con tags de Stanford."""</span>

        <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">t</span><span class="p">.</span><span class="n">treepositions</span><span class="p">(</span><span class="s">"leaves"</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">tag</span> <span class="o">=</span> <span class="n">t</span><span class="p">[</span><span class="n">p</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]].</span><span class="n">label</span><span class="p">()</span>
                    <span class="n">t</span><span class="p">[</span><span class="n">p</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]].</span><span class="n">set_label</span><span class="p">(</span><span class="n">SimpleAncoraCorpusReader</span><span class="p">.</span><span class="n">simple_tag</span><span class="p">(</span><span class="n">tag</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">t</span>

        <span class="k">return</span> <span class="n">LazyMap</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">super</span><span class="p">().</span><span class="n">parsed_sents</span><span class="p">(</span><span class="n">fileids</span><span class="p">))</span>
</code></pre></div></div>
<p>Con ello podemos cargar el CORPUS, y as√≠ las oraciones. Las oraciones, ser√°n una lista de lista de palabras, por ejemplo:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span>
    <span class="p">[</span><span class="s">"el"</span><span class="p">,</span> <span class="s">"perro"</span><span class="p">,</span> <span class="s">"come"</span><span class="p">,</span> <span class="s">"carne"</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"el"</span><span class="p">,</span> <span class="s">"gato"</span><span class="p">,</span> <span class="s">"me"</span><span class="p">,</span> <span class="s">"mordi√≥"</span><span class="p">],</span>
<span class="p">]</span>
</code></pre></div></div>
<p>Podemos luego crear la clase <code>HMMGenerator</code> cuyo constructor recibir√° como par√°metro el tama√±o del <code>n-grama</code>. Luego, debemos calcular las probabilidades, y una tabla hash conteniendo el contexto (palabras previas) y una lista posible de palabras siguientes:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sents</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sents</span><span class="p">):</span>
        <span class="n">new_sent</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[</span><span class="n">HMMGenerator</span><span class="p">.</span><span class="n">START_SYMBOL</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ngram_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">sent</span>
            <span class="o">+</span> <span class="p">[</span><span class="n">HMMGenerator</span><span class="p">.</span><span class="n">END_SYMBOL</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_sent</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">ngram_length</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_sent</span><span class="p">):</span>
                <span class="k">break</span>
            <span class="n">ngram</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">new_sent</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">ngram_length</span><span class="p">])</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">ngram</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">_probs</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">context</span> <span class="o">=</span> <span class="n">ngram</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">_context</span><span class="p">[</span><span class="n">context</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ngram</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_probs</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_probs</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_context</span><span class="p">[</span><span class="n">ngram</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">_trained</span> <span class="o">=</span> <span class="bp">True</span>
</code></pre></div></div>
<p>El c√≥digo anterior, resulta en las probabilidades de los ngramas, y una lista de palabras siguientes dado el contexto:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">probs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">(</span><span class="s">"el"</span><span class="p">,</span> <span class="s">"perro"</span><span class="p">,</span> <span class="s">"come"</span><span class="p">):</span> <span class="mf">0.022</span>
<span class="p">}</span>

<span class="n">context</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"(el, perro)"</span><span class="p">:</span> <span class="p">[</span><span class="s">"ladra"</span><span class="p">,</span> <span class="s">"come"</span><span class="p">]],</span>
<span class="p">}</span>
</code></pre></div></div>
<p>Luego del entrenamiento, se pueden generar oraciones, basados en la probabilidad de los <code>n-gramas</code> eligiendo una palabra aleatoreamente dado el contexto y respetando la distribuci√≥n generada en el entrenamiento:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_random_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">current_token</span> <span class="o">=</span> <span class="n">HMMGenerator</span><span class="p">.</span><span class="n">START_SYMBOL</span>
    <span class="n">ngram_prev</span> <span class="o">=</span> <span class="p">(</span><span class="n">HMMGenerator</span><span class="p">.</span><span class="n">START_SYMBOL</span><span class="p">,)</span> <span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ngram_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">candidate_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_context</span><span class="p">[</span><span class="n">ngram_prev</span><span class="p">]:</span>
            <span class="n">candidate_tokens</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">candidate</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">_probs</span><span class="p">[(</span><span class="o">*</span><span class="n">ngram_prev</span><span class="p">,</span> <span class="n">candidate</span><span class="p">)]))</span>

        <span class="n">prob</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">cum_prob</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="n">candidate_tokens</span><span class="p">:</span>
            <span class="n">cum_prob</span> <span class="o">+=</span> <span class="n">candidate</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">cum_prob</span> <span class="o">&gt;=</span> <span class="n">prob</span><span class="p">:</span>
                <span class="n">current_token</span> <span class="o">=</span> <span class="n">candidate</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="n">current_token</span> <span class="o">==</span> <span class="n">HMMGenerator</span><span class="p">.</span><span class="n">END_SYMBOL</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">tokens</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_token</span><span class="p">)</span>
        <span class="n">ngram_prev</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">ngram_prev</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">current_token</span><span class="p">)</span>
    <span class="k">return</span> <span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</code></pre></div></div>
<p>Finalmente, podemos tener un programa que se entrene con distintos trama√±os de <code>n-gramas</code>, por ejemplo:</p>
<pre><code>===============================================================================
Oraciones con ngramas n = 2
===============================================================================
El secretario general de la investigaci√≥n militar , y la que los que Espa√±a , el pa√≠s , el presidente de la reuni√≥n que los palestinos , que se han sido el " , el sistema de la reelecci√≥n en la ley .
La angustia .
El presidente del Gobierno de la mayor√≠a de la formaci√≥n de la investigaci√≥n y el proceso de la que la necesidad de los que " .
El secretario general de la que se ha sido un mercado de su campa√±a electoral de la mayor√≠a de la situaci√≥n de la ca√≠da del pa√≠s , la reuni√≥n de la necesidad de la compa√±√≠a .
El presidente de la presidencia de los salarios de la empresa de las empresas de la que se ha llegado al que se ha sido el ex primer trimestre del mundo en la empresa , la pol√≠tica de los comicios , que los comicios .
El presidente de la sociedad civil " , que " , que se ha sido suspendida hasta el caso de las elecciones para el proceso de la econom√≠a , esta noche .
El paro entre Espa√±a , y con el sistema de la ley .
El presidente de los que se fijen los presidentes de la que se ha sido un soldador .
El presidente del Gobierno , la operaci√≥n de la reforma laboral de la legislaci√≥n a_trav√©s_de la que los que se ha sido inmejorable .
El desempleo en la que se situ√≥ en el l√≠der del Estado , uno de los expertos de la que se han sido el presidente de la situaci√≥n de la urgencia .
===============================================================================
Oraciones con ngramas n = 3
===============================================================================
El responsable del grupo , la de un est√≠mulo determinado , como el del pasado a√±o .
El portavoz del PNV , Xabier_Arzalluz , cuestiona la legitimidad en s√≠ .
Durante la presentaci√≥n de un PP que est√°n inmersos es un superviviente , por_m√°s_que haya much√≠simos rasgos andaluces en el sector productivo .
La oposici√≥n ha visto alterada por la paz " , y en el que se han registrado 2.430.879 contratos indefinidos e incentivados .
El n√∫mero de sufragios , la Reina y con 23.000 empleados , opera en el que se ha mantenido una impresionante lucha contra el dictamen pericial por la banda terrorista ETA .
En el sondeo que publica hoy el conseller de Pol√≠tica_Territorial , Felip_Puig , sellaron ayer en defensa de la segunda vuelta electoral , y el de la petici√≥n de la compa√±√≠a de electricidad .
Este grupo ha creado un mayor incremento del n√∫mero de v√≠ctimas demuestra que " el esfuerzo de estos dos centrocampistas de marca , repartidas en el mercado laboral " peruano .
El secretario general de CCOO , Jos√©_Mar√≠a_Fidalgo , opin√≥ que las autoridades ambientales de Colombia , que ha sido el objeto de una grave enfermedad .
El presidente de la Liga , Pauleta insisti√≥ ante los ex : ex_bigotudos , ex_ministros , ex_futbolistas , obstinadas secuelas de su partido n√∫mero 300 en Primera , precisamente en el que se ha creado un " problema inmenso " la √∫ltima semana , el primero que escribi√≥ T√≥nicos_de_la_voluntad , Charlas_de_Caf√© , Cuentos_de_Vacaciones con los huesos de las dos cualidades de un mes , constar√° de 49 a√±os , ley√≥ una nota de prensa de Barcelona , inmersos en una conferencia de prensa , a_sabiendas_de que si las circunstancias que todos los espa√±oles " .
El presidente de la sociedad vasca " , ya_que en la que es muy interesante porque encarna la tolerancia y la construcci√≥n de Altamira_2 y , como el riego localizado o por fax .
===============================================================================
Oraciones con ngramas n = 5
===============================================================================
La Fiscal√≠a_General de este pa√≠s emiti√≥ hoy ordenes de detenci√≥n contra la directiva de Sov_Invest , sociedad que administr√≥ el Fondo_Nacional_de_Inversiones , tras comprobarse un agujero de m√°s_de 500.000 d√≥lares de un total de 170 millones de d√≥lares que este fondo privado hab√≠a atra√≠do de la poblaci√≥n .
La compa√±√≠a , una de las m√°s antiguas de Oriente_Pr√≥ximo , tiene numerosos cr√≠ticos en su propio pa√≠s y son muchas e insistentes las voces que reclaman su privatizaci√≥n .
El secretario general de Empleo , Juan_Chozas , dijo que hay que insistir en las pol√≠ticas activas de empleo para conseguir que los colectivos con m√°s problemas - parados de larga duraci√≥n y con los j√≥venes " .
El presidente de la Junta_de_Extremadura pidi√≥ " esperanzas " para el Pa√≠s_Vasco , " esperanzas para los dem√≥cratas y desesperanza para los que creen que todo lo pueden conseguir con la lucha armada , - yo no estoy de_acuerdo - comentaba uno de ellos - ; despu√©s de cinco a√±os en la escuder√≠a todav√≠a no lo hablaba y la llegada de Barrichello , que domina la lengua de Dante , le ha hecho cambiar sus costumbres y en la presentaci√≥n del equipo a finales de enero , pronunci√≥ sus primeras palabras en italiano en p√∫blico .
La elecci√≥n de un nuevo presidente por parte del Parlamento israel√≠ se decidi√≥ despu√©s de que el Ejecutivo se diera_cuenta de que era " insostenible " mantener el acuerdo de Gobierno con EH , pero insisti√≥ en que corresponde al lehendakari tomar las decisiones que considere oportunas .
El presidente de la Comisi√≥n_Europea , la griega Anna_Diamantoupoulou , como un respaldo moral a las posiciones de la ACB en este asunto .
En esa situaci√≥n , sus recursos legales podr√≠an tramitarse en tribunales de apelaci√≥n o podr√≠an pasar directamente al Tribunal_Supremo_de_Justicia , una opci√≥n que existe para los grandes casos de monopolio .
El gobernador , que se caracteriza por una tensi√≥n de los m√∫sculos de cara y cuello , acompa√±ado de dolor de cabeza , n√°useas y vah√≠do " .
El grupo de los complementos ha evolucionado de manera muy positiva en los √∫ltimos cinco a√±os , que se saldaron con cinco muertos , m√°s de 15 heridos y al_menos 130 detenidos .
El mismo jugador yugoslavo dispuso de una inmejorable oportunidad para empatar el partido a los dos minutos de la segunda parte ser√° comunicado oficialmente hoy por la Comisi√≥n_de_Control que verifica que el desarrollo de las comunidades que riega , ¬ø c√≥mo conciliar los leg√≠timos y comprensibles derechos del Gobierno aragon√©s con los de las otras autonom√≠as sedientas ? .
</code></pre>
<p>En teor√≠a, mientras mayor sea $n$, es cada vez menos probable que ciertas secuencias ocurran repetidamente, por lo que las distribuciones resultantes son dispersas. Si se observa, para $n = 5$, las oraciones son bastante coherentes, pero ¬°son oraciones del CORPUS! Una forma de evaluar estos modelos de lenguaje es utilizar una m√©trica conocida como <strong>perplejidad</strong>. La perplejidad est√° asociada a qu√© tan bien la distribuci√≥n de probabilidades obtenida puede predecir el lenguaje. A menor perplejidad, mejor es el modelo (en esencia la perplejidad representa nivel de entrop√≠a):</p>
<p>$$PP(W) = \sqrt[n]{\displaystyle \frac{1}{P(w_1, w_2, \ldots , w_n)}}$$</p>
<h4 id="sistema-pregunta-respuesta-qa-system-utilizando-n-gramas">Sistema Pregunta-Respuesta (QA-system) utilizando N-Gramas</h4>
<p>En el paper <a href="https://aclanthology.org/W02-1033.pdf" target="_blank" rel="noopener noreferrer">An Analysis of the AskMSR Question-Answering System </a> se implement√≥ un sistema QA (Question Answering System) minando N-gramas desde la web. La arquitectura del sistema se muestra en la figura 1:</p>
<div align="center">
<p><img src="https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/13980a4a24ba09c7c5010b285fcf0948fdf486ec/qa-system.png" alt="AskMSR"></p>
<p><em>Fig 1: Arquitectura Sistema Pregunta-Respuesta AskMSR.</em></p>
</div>
<p>En esencia, el sistema necesita:</p>
<ol>
<li>Clasificar el tipo de pregunta (e.g. D√≥nde, Qui√©n, Cu√°ndo, etc.)</li>
<li>Reformular la pregunta para enviar al motor de b√∫squeda</li>
<li>Minar <code>N-gramas</code>
</li>
<li>Darle un puntaje a las respuestas candidatas (e.g. utilizar palabras capitalizadas como aproximaci√≥n a un sustantivo)</li>
</ol>
<p>Cabe destacar que el sistema no utiliza ning√∫n tipo de procesamiento, otro m√°s que un lexicon para encontrar los verbos y reformular la pregunta. Este sistema lo implement√© a nivel b√°sico y estas fueron las entradas y salidas:</p>
<pre><code>cual es la capital de argentina?
1 ('Buenos', 'Aires') (207)
2 ('',) (93)
3 ('Buenos',) (69)
4 ('Aires',) (69)
5 ('de', 'Buenos', 'Aires') (63)
6 ('Buenos', 'Aires', 'The') (54)
7 ('Argentina',) (42)
8 ('de',) (31)
9 ('the',) (28)
10 ('Presentday', 'Buenos', 'Aires') (27)
Donde est√° el museo de louvre?
1 ('',) (168)
2 ('Louvre',) (63)
3 ('', '') (63)
4 ('Museo', 'del', 'Louvre') (54)
5 ('', '', '') (54)
6 ('del', 'Louvre') (33)
7 ('The',) (27)
8 ('', 'Louvre', 'Museum') (27)
9 ('Louvre', 'Museum', 'Official') (27)
10 ('Visit', 'Explore', 'Whats') (27)
Quien es el presidente de Chile?
1 ('',) (195)
2 ('Gabriel', 'Boric') (90)
3 ('de',) (85)
4 ('', 'Ver') (63)
5 ('', 'Ver', 'm√°s') (63)
6 ('de', '') (57)
7 ('Chile', 'Spanish', 'Presidente') (54)
8 ('Gabriel', 'Boric', 'Font') (54)
9 ('Chile', 'Gabriel', 'Boric') (54)
10 ('', 'de') (48)
Que idioma se habla en Paraguay?
1 ('',) (96)
2 ('', 'de') (42)
3 ('El',) (39)
4 ('', 'Wikipedia') (36)
5 ('', 'Wikipedia', 'la') (36)
6 ('de',) (34)
7 ('Paraguay',) (27)
8 ('Paraguay', '', 'Wikipedia') (27)
9 ('El', 'Guaran√≠', 'Es') (27)
10 ('', 'Idioma', 'Oficial') (27)
</code></pre>
<p>Con un poco de ajustes, se puede armar una respuesta en base a los mejores <code>N-gramas</code> (e.g. como en el paper combinan <code>N-Gramas</code>). Una m√©trica de desempe√±o de estos sistemas es el <strong>Mean Reciprocal Rank</strong>, o $MRR$, que es un promedio ponderado de las respuestas y c√≥mo las categoriz√≥ el sistema a un conjunto de preguntas.</p>
<p>$$MRR = \displaystyle \frac{1}{|Q|}\sum^{|Q|}_{i=1}\frac{1}{r_i}$$</p>
<p>Se observa que el m√°ximo valor es 1 (el sistema siempre entrega la respuesta en la primera posici√≥n), y el m√≠nimo en el l√≠mite es 0 (asumiendo que el RR es 0 si el sistema no entrega la respuesta).</p>
<h2 id="conclusiones">Conclusiones</h2>
<ul>
<li>Es complicado lidiar con discursos computacionalmente (problema intratable)</li>
<li>Se puede utilizar aproximaciones para estimar la probabilidad de una secuencia de palabras</li>
<li>Se pueden utilizar N-Gramas para tareas b√°sicas de NLP (e.g. generar lenguaje, sistema pregunta respuesta)</li>
</ul>
<p>Todos los ejemplos de c√≥digo e implementaciones los pueden encontrar en <a href="https://github.com/dpalmasan/python-nlp-examples" target="_blank" rel="noopener noreferrer">este repo en Github</a></p>
<h2 id="desafo-y-pregunta-de-entrevista">Desaf√≠o y pregunta de entrevista</h2>
<p>Esta fue una pregunta que me hicieron en una empresa top (a mi criterio jeje):</p>
<p>Escriba un programa que dada una palabra, entregue la palabra siguiente m√°s probable.</p>
<ul>
<li>¬øQu√© supuestos de deben realizar?</li>
<li>¬øC√≥mo testear el algoritmo?</li>
<li>¬øCu√°l es la complejidad en tiempo y espacio?</li>
<li>¬øQu√© problemas pueden haber en la implementaci√≥n que realicen?</li>
</ul>
<p>Asuman que tienen entre 20 y 30 minutos para resolver el problema<img class="emoji" title=":smile:" alt=":smile:" raw="üòÑ" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" style="vertical-align: middle; display: inline; max-width: 1em; visibility: hidden;" onload="this.style.visibility='visible'" onerror="this.replaceWith(this.getAttribute('raw'))">.</p>

  </div>
<div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = '';
      this.page.identifier = 'https://dpalmasan.github.io/website/entrevistas/ti/2023/01/08/nlp-intro.html';
    };

    (function() {
      var d = document, s = d.createElement('script');

      s.src = 'https://dpalmasan.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow noopener noreferrer" target="_blank">comments powered by Disqus.</a>
</noscript>
<a class="u-url" href="/website/entrevistas/ti/2023/01/08/nlp-intro.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/website/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="https://dpalmasan.github.io/website/feed.xml">
            <svg class="svg-icon orange">
              <path d="M12.8 16C12.8 8.978 7.022 3.2 0 3.2V0c8.777 0 16 7.223 16 16h-3.2zM2.194
                11.61c1.21 0 2.195.985 2.195 2.196 0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017 0
                13.806c0-1.21.983-2.195 2.194-2.195zM10.606
                16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818 0 10.606 4.79 10.606 10.607z"></path>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">dpalmasan</li>
          
        </ul>
      </div>
      <div class="footer-col">
        <p>Este es un blog donde compartir√© un poco sobre m√≠ y mis experiencias en el mundo tecnol√≥gico...</p>
      </div>
    </div>

    <div class="social-links">
<ul class="social-media-list">
<li>
    <a rel="me noopener noreferrer" href="https://www.linkedin.com/in/dpalmasan/" target="_blank" title="Mi perfil en Linkedin">
      <span class="grey fa-brands fa-linkedin fa-lg"></span>
    </a>
  </li>
<li>
    <a rel="me noopener noreferrer" href="https://www.github.com/dpalmasan" target="_blank" title="Mi Github">
      <span class="grey fa-brands fa-github fa-lg"></span>
    </a>
  </li>
<li>
    <a rel="me noopener noreferrer" href="https://scholar.google.com/citations?user=Y5PN_1AAAAAJ&hl=en" target="_blank" title="Mi Google Scholar">
      <span class="grey fa-brands fa-google-scholar fa-lg"></span>
    </a>
  </li>
<li>
    <a rel="me noopener noreferrer" href="https://stackoverflow.com/users/4051219/dpalma" target="_blank" title="Mis preguntas en SO LOL!">
      <span class="grey fa-brands fa-stack-overflow fa-lg"></span>
    </a>
  </li>
</ul>
</div>

  </div>

</footer>

</body>

</html>
