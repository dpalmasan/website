---
layout: post
title:  "Mi Tercer Ciclo"
date:   2025-02-25 14:30:00 -0400
categories: swe dev
---

<div align="center">

![fl-genai](http://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/6ce5ad83ead7e76414a35ffffe14aa79f1082fa9/fl-genai.jpeg)

</div>

# Introducci√≥n

Como muchos sabr√°n llevo un poco m√°s de dos a√±os trabajando en Meta. En este post comparto algunas experiencias √∫ltimo fragmento en estos 2.8 a√±os que llevo ac√°. Adelanto que no ser√° un post tan largo ni con mucho detalle, y tendr√° dos secciones principales:

1. Mi experiencia en este 3er ciclo (2024)
2. Algunas reflexiones/opiniones

Vale la pena leer el post completo para llegar a lo jugoso/sabroso.

## Contexto

En [otro post habl√© sobre mis experiencias en Meta]({{ site.baseurl }}{% link _posts/2024-09-06-diferentes-experiencias.markdown %}), b√°sicamente sobre los primeros dos a√±os que tuve. En este post hablar√© de mi tercer ciclo, de c√≥mo me cambi√© de equipo, las diferencias.

# Mi tercer a√±o en USA

Primero lo m√°s importante, sobreviv√≠ 3 rondas de despidos: 2022 y 2023 hubo recortes de presupuesto y el m√°s reciente (Febrero 10, 2025) fue por desempe√±o. No me referir√© mucho a estos temas, ya que en mi post [_Diferentes Experiencias_]({{ site.baseurl }}{% link _posts/2024-09-06-diferentes-experiencias.markdown %}) mencion√© c√≥mo es el tema de la evaluaci√≥n de desempe√±o en Meta (que vale la pena recordar, es muy intensa, m√°s intensa que en cualquier experiencia previa que haya tenido).

Mi _performance rating_ de este tercer ciclo (2024) fue **Exceeded Expectations**. He ido a la baja jaja, mi primer a√±o saqu√© redefined, el segundo greatly exceeded y ahora exceeded... En fin, significa que hay espacio para mejorar üòä

## Algunas Memorias Personales

Para destacar este a√±o:

* Trabaj√© en problemas interesantes, en particular en el espacio de _Federated Learning_.
* Me toc√≥ tocar e implementar bibliotecas nativas (`jni`) (android y otros dispositivos), tuve que hacer implementaciones en `java` y `kotlin`. Este √∫ltimo nunca lo hab√≠a tocado, fue una experiencia interesante.
* He sido mentor 4 veces en Meta. Un@ de ell@s logr√≥ el rating Exceeds Expectations habiendo entrado en la segunda mitad del a√±o. Originalmente se iba a ir por saltarse la evaluaci√≥n al ser nuev@ pero le di soporte y logr√≥ algo mucho mejor. Pecho inflado cuando me agradeci√≥ mi apoyo üòä.
* Voy a empezar a ser entrevistador para posiciones de SWE/ML.
* Tuve excelente feedback de ingenieros que admiro (y tengo en un pedestal). Palabras como _top engineer in the problem space_, _standout engineer_, _great engineer_, _best in class XFN_, etc.
* Baj√© m√°s de 11 kg, estoy en mi aventura de ser influencer _fitness_ üòÇ.
* Romp√≠ mi record de pull ups y estoy haciendo pull ups con +50kg (extras).
* Logr√© sacar el muscle up üòä. Tambi√©n de a poco mejorando mi press de banca.

<div align="center">

![muscle-up](https://gist.github.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/66a60e26abc012301ce7a15e98481eb0f0d53d77/muscle-up.gif)

_Fig 1: Yo haciendo un muscle up, anduve por Santiago en Enero._

</div>

## Tiempo para una Historia

A fines del 2023 me cambi√© de equipo, rechazando una posible promoci√≥n a E6, y tir√°ndome hacia lo desconocido. Me transfer√≠ de un equipo de producto, a un equipo de infraestructura. Qu√© significa ello, en un equipo de producto los proyectos est√°n orientados a resolver problemas con objetivos claros y espec√≠ficos, por ejemplo _implementar X para aumentar el revenue en un Y%_. En este tipo de ambiente el **impacto** est√° alineado a objetivos globales directos. Lo que he notado, es que las iteraciones son r√°pidas, ya que hay que mover los gradientes en direcci√≥n a un mejoramiento de m√©tricas que impacten el _revenue_ y los proyectos son en general cortoplacistas. Por otro lado, en un equipo de infraestructura, las iteraciones son lentas. Los proyectos son m√°s a largo plazo y el objetivo principal es implementar infraestructura que sea escalable, confiable, f√°cil de usar, y con buen desempe√±o en medidas de eficiencia (uso de memoria, latencia, etc.). En este tipo de proyecto el **impacto** por lo general es indirecto y m√°s complicado de medir en comparaci√≥n a un equipo de producto. Cabe destacar que la direcci√≥n es a largo plazo.

## Aprendizaje Federado

En particular, mi equipo actual provee una infraestructura para el aprendizaje federado (_Federated Learning_, _FL_), el cual expliqu√© en mi post [_Introducci√≥n al Aprendizaje Federado_]({{ site.baseurl }}{% link _posts/2024-04-11-federated-learning.markdown %}). Debo admitir que inicialmente sufr√≠ en mi fase de _ramp up_, ya que el stack era completamente diferente a lo que estaba acostumbrado. En mi equipo previo el stack era principalmente [Haskell](https://www.haskell.org/), [Hack](https://hacklang.org/) y [python](https://www.python.org/). Tuve que aprender y meterme en una base de c√≥digo gigante donde el 90% del c√≥digo est√° escrito en [C++](https://cplusplus.com/). Las √∫nicas experiencias que hab√≠a tenido en C++ fueron m√°s bien acad√©micas, y nada comparables a programar en este lenguaje en un sistema a nivel de industria. Mucho menos lidiar con una base de c√≥digo con cientos de archivos, l√≠neas de c√≥digo, m√∫ltiples servicios, y un problema nuevo (FL) en el que no ten√≠a experiencia.

Primeros meses, tengo la tarea de entender los diferentes ejecutores de c√≥digo nativo en pytorch. No voy a discutir el stack en detalle, pero para ejecutar pytorch en multi-plataformas se puede usar [JIT](https://pytorch.org/docs/main/jit.html), b√°sicamete scriptear los modelos y hacer tracing de todos los componentes necesarios para su ejecuci√≥n. Debiese ser obvio, pero para aclarar, hay ciertas restricciones a la hora de scriptear, como por ejemplo no se pueden tener todas las directivas de `python` y s√≥lo se puede scriptear un subconjunto de tipos/objetos. Por otro lado, el tama√±o del binario importa, por lo que no podemos llegar y scriptear el modelo utilizando todos los operadores de pytorch. La ingenier√≠a de esto no la mencionar√©, pero es un tema complicado, dado que en federated learning se debe poder ejecutar el modelo de ML en m√∫ltiples dispositivos, que pueden tener diferentes APIs a nivel de OS, y tambi√©n otras restricciones como uso de memoria y CPU. No se puede llegar y matar la bater√≠a del dispositivo ejecutando un proceso alto en el uso de CPU (como lo es entrenar un modelo), por ejemplo.

Por otro lado, existen otras restricciones ¬øc√≥mo se deben estandarizar las entradas al modelo (batches) para poder tener soporte en m√∫ltiples tipos de modelos que pueden tener diferentes tipos de entrada? (ej. im√°genes, textos, features). Un sub-proyecto que propuse, consisti√≥ en traer claridad en estas restricciones y ambiente. Luego de m√∫ltiples desarrollos, logr√© implementar diferentes tipos de modelos (modelos basados en features simples, visi√≥n computacional, NLP, clasificadores, auto-codificadores variacionales _VAE_, etc) que se pod√≠an ejecutar en una arquitectura homog√©nea. En la implementaci√≥n, para lograr esta estandarizaci√≥n, se requiere incrustar metadata al modelo (qu√© tipo de feature es, entre otras cosas). Mis XFN estaban implementando un modelo de visi√≥n computacional bastante complejo (no quiero ni recordar lo complejo que era ese c√≥digo y esa red neuronal üòÖ). En la implementaci√≥n existente del sistema que estaba en nuestro lado (c√≥digo viejo), para poder normalizar los datos y ejecutarlos en este motor, se deb√≠a leer la imagen y cada pixel era una feature.

Para modelos con entradas peque√±as como [FEMNIST](https://paperswithcode.com/dataset/femnist), esto funcionaba perfecto. Sin embargo, para el modelo que se estaba desarrollando, las imagenes a procesar eran mucho m√°s grandes, por lo que hab√≠a problemas de escalabilidad. No entrar√© en detalle, pero se me ocurri√≥ implementar un algoritmo que redujo la cabtidad de escrituras de $O(C\cdot H \cdot W)$ a $O(C)$ (donde $C$ es el n√∫mero de canales, $H$ la altura y $W$ la anchura de la imagen). Esto solucion√≥ el problema de escalabilidad y permiti√≥ a los XFN a continuar explorando FL. Como el lector se dar√° cuenta esto era un _launch blocker_.

En fin, hubo una pl√©tora de _launch blockers_ durante el a√±o (encriptaci√≥n, problemas con _backpropagation_, observabilidad, exportaci√≥n de operadores, _model authoring_, _you name it_), que afortunadamente como logr√© familarizarme r√°pido con el c√≥digo, solucion√© de forma satisfactoria. Lo curioso es que me toc√≥ meter mano en base de c√≥digo ajena, lo que fue una experiencia enriquecedora, que a√±adi√≥ m√°s cicatrices a mis a√±os de circo lidiando con b√°ses de c√≥digo gigantes, desconocidas y de forma r√°pida. El impacto, logramos poner en producci√≥n el primer modelo de visi√≥n computacional utilizando FL, un logro nada menor.

## Un poco m√°s de on-device training

Otro proyecto interesante en el que trabaj√© fue hacer fine-tuning _on device_ de LLMs usando [ExecuTorch](https://pytorch.org/executorch-overview). Los resultados fueron presentados en la [Pytoch Conference 2024](https://pytorch2024.sched.com/event/1fHln/executorch-beta-and-on-device-generative-ai-support-mergen-nachin-mengtao-martin-yuan-meta) (minuto 16:24). Esto fue un gran desaf√≠o y tiene un impacto a nivel de industria, lo que hace que me sienta orgulloso del trabajo y los proyectos que he escogido. Por supuesto, hay consideraciones t√©cnicas importantes, y hay que ser muy orientado al detalle: Tener benchmarks, asegurarse de una correcta implementaci√≥n a bajo nivel, tener claro c√≥mo delegar instrucciones y que el backend tenga soporte de las distintas operaciones a nivel de OS. Por ejemplo, es una mala idea usar `malloc` en _embedded systems_. Dejo al lector investigar por qu√©...

## Simulaciones FL

Otro proyecto interesante fue escalar un simulador de FL, proyecto OSS [flsim](https://github.com/facebookresearch/FLSim). Sin embargo, para uso interno, hab√≠a problemas de escalabilidad entre otros detalles. Escalar el sistema no fue simple. Adem√°s de la l√≥gica de serializaci√≥n y deserializaci√≥n de los modelos, para simular dispositivos el servidor, hay otros detalles, como el hacer la transferencia por red de forma eficiente. En este caso utilizamos APIs de bajo nivel `isend` e `irecv` (provistas por `pytoch` distributed). Despu√©s de una fase experimental de benchmarks, probamos distintos tipos de tareas (SFT, clasificaci√≥n, procesamiento de im√°genes). Finalmente, en temas de _throughput_ nos decantamos por una soluci√≥n usando el protocolo `RPC` (hab√≠an otros temas de uso de memoria, por ejemplo entrenando LLMs que fueron un gran desaf√≠o t√©cnico). Para hacer escalar la carga de datos, y la ejecuci√≥n, hubo que dise√±ar un sistema como el mostrado en la figura 2. Hubo otros desaf√≠os como por ejemplo no agregar todos los modelos de los clientes en el servidor (cuello de botella), si no que distribuir la carga de forma inteligente para aprovechar de mejor manera la concurrencia.

<div align="center">

![fl-dist-design](https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/fcb3d8cdcdf5fbcfdcf4a4699e9d48dd42a4d4f9/sys-design-dist-fl.png)

_Fig 2: Dise√±o de sistema distribuido para simulaciones FL._

</div>

El dise√±o est√° muy simplificado, hay muchos detalles t√©cnicos que no mencionar√©. Sin embargo, para un caso de uso importante, logramos superar la meta y throughput de `100k users/min` a `250k users/min`, que es bastante bueno para simulaciones a gran escala. Tambi√©n logramos mejorar la carga de datos para soportar billones de entradas. Yo dise√±√© el sistema y los sub-sistemas, hice algunas implementaciones m√°s complejas y el _boilerplate_. Luego otros ingenieros y researchers tomaron mi dise√±o y lo completaron. B√°sicamente lider√© m√∫ltiples proyectos.

# Reflexiones

No tengo mucho m√°s que contar. S√≥lo para agregar, yo tambi√©n me estreso y no tengo la respuesta para todo. Sin embargo, en situaciones extremas se activa mi _modo de supervivencia_. Muchas veces estuve a contra-reloj con problemas que parec√≠an no tener soluci√≥n y de alguna forma logr√© **hackear el universo y hacer aparecer una soluci√≥n**. Lo que he podido notar, y que me han comentado algunas personas, es que no toda la gente tiene ese _modo_ (aunque para mi sea algo natural).

Por otro lado, vi muchos casos de ingenieros que fueron etiquetados como NRA (_Non-Regrettable Attrition_). Algunos se memorizaron mucho el proceso de entrevistas, quedaron en niveles m√°s altos del que deber√≠an haber estado y lamentablemente _los dejaron ir_. Otros, nunca fueron promovidos en los l√≠mites de tiempo establecidos y despu√©s de un par de semestres, tambi√©n _los dejaron ir_. En fin, no todos son un buen ajuste para todos lados. Incluso yo no he sido buen ajuste en algunas empresas (por suerte no he quedado en dichos procesos). Sin embargo, tambi√©n presenci√© casos en que el ingeniero tuvo muy buen desempe√±o, pero una mala mitad. Siempre hay externalidades como: problemas familiares, enfermedades, etc.

Nadie _est√° a salvo_, definitivamente **nadie es imprescindible**. Me tiene con dolor de est√≥mago pensar en el futuro, en el sentido de que yo igual podr√≠a tener un _mal periodo en la chamba_. Sin embargo, el hecho de que **existe una alta probabilidad de ser despedido** en la vida laboral, me deja menos amargura y tampoco es el fin del mundo. Creo que lo m√°s importante es cuidar la salud y las relaciones personales. Lamentablemente, por ahora yo soy un trabaj√≥lico üòÖ, pero estoy intentando definir un l√≠mite entre lo laboral y lo personal...

# Cierre

Casos anecd√≥ticos, he recibido comentarios como: "se presenta como experto en ML" o "c√≥mo te contrataron en Meta", etc. Yo **nunca me he autoproclamado experto**, pueden revisar mi LinkedIn de pies a cabeza y no van a encontrar ese adjetivo (lo uso muy rara vez).

Creo de todas maneras que hago cosas que no son tan comunes:

* He contribuido al open-source en proyectos grandes
* he contribuido al estado del arte en la literatura (en ML y ling√º√≠stica computacional), en la figura 3 muestro un pantallazo a mi google scholar. Puedo ser un pelagato, pero el hecho de haber publicado en revistas donde la revisi√≥n es rigurosa, me imagino que me da algunos puntos.

<div align="center">

![dpalma-google-scholar](https://gist.githubusercontent.com/dpalmasan/103d61ae06cfd3e7dee7888b391c1792/raw/0431d1bb37ebb4690d5bf8571646104b0d4b48fa/citations.png)

_Fig 3: Citas en google scholar._

</div>

* Nunca he tomado el _atajo_ de ir a copiar y pegar tutoriales, o revisar art√≠culos que no hayan sido revisados y contrastados.

Para el mito _los ingenieros de FAANG no saben tal tecnolog√≠a, o memorizan leetcode, blah blah_. Existe una **bi-direccionalidad**. Me ha tocado ver ingenieros considerados _senior_ en algunas empresas (con todo el stack + cloud, etc.) que han echado a los 6 meses porque no cumplieron con las expectativas.

En mi opini√≥n se cumplen 3 axiomas:

$$\text{Saber } N \text{ "tecnolog√≠as"}\nRightarrow \text{ser buen ingeniero} \quad (1)$$

Hace unos a√±os se salpicoteaban bastante los t√©rminos "data pipeline" _"big data" "spark" "cloud"_. Ahora es _"DB vectoriales" "agentes" "LLM"_ (generalmente autoproclamados expertos).

$$ \text{Llegar a una FAANG} \nRightarrow \text{ser buen ingeniero} \quad (2)$$

Lamentablemente he visto ingenieros que no tuvieron buen desempe√±o en sus primeros 6 meses - 2 a√±os.

$$\text{No trabajar en FAANGs} \nRightarrow \text{no ser bueno/top} \quad (3)$$

He conocido ingenieros _No FAANGs_ excelentes a lo largo de mi carrera.
